% !TeX TXS-program:compile = txs:///pdflatex/[--shell-escape]
%
% acm templates v1.57 (sigconf template)
%
%\documentclass[sigconf, screen, review, anonymous, natbib=false]{acmart}
\documentclass[sigconf, screen, natbib=false, dvipsnames, table]{acmart}
\settopmatter{printacmref=true}
% mandatory for CCS'19
\usepackage{balance}
\usepackage{mathtools}
% for creating a balanced last page (usually last page with references)

% defining the \BibTeX command - from Oren Patashnik's original BibTeX documentation.
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08emT\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

% Rights management information. 
% This information is sent to you when you complete the rights form.
% These commands have SAMPLE values in them; it is your responsibility as an author to replace
% the commands and values with those provided to you when you complete the rights form.
%
% These commands are for a PROCEEDINGS abstract or paper.

\copyrightyear{2019} 
\acmYear{2019} 
\setcopyright{acmcopyright}
\acmConference[CCS '19]{2019 ACM SIGSAC Conference on Computer and Communications Security}{November 11--15, 2019}{London, United Kingdom}
\acmBooktitle{2019 ACM SIGSAC Conference on Computer and Communications Security (CCS '19), November 11--15, 2019, London, United Kingdom}
\acmPrice{15.00}
\acmDOI{10.1145/3319535.3339818}
\acmISBN{978-1-4503-6747-9/19/11}

%
% These commands are for a JOURNAL article.
%\setcopyright{acmcopyright}
%\acmJournal{TOG}
%\acmYear{2018}\acmVolume{37}\acmNumber{4}\acmArticle{111}\acmMonth{8}
%\acmDOI{10.1145/1122445.1122456}

%
% Submission ID. 
% Use this when submitting an article to a sponsored event. You'll receive a unique submission ID from the organizers
% of the event, and this ID should be used as the parameter to this command.
%\acmSubmissionID{123-A56-BU3}

%
% The majority of ACM publications use numbered citations and references. If you are preparing content for an event
% sponsored by ACM SIGGRAPH, you must use the "author year" style of citations and references. Uncommenting
% the next command will enable that style.
%\citestyle{acmauthoryear}


 \makeatletter
 % \renewcommand{\section}{\abovedisplayskip 10\p@ \@plus3\p@ \@minus1\p@%
 %                       \belowdisplayskip 5\p@ \@plus3\p@ \@minus1\p@%
 %                       \abovedisplayshortskip 0pt \@plus2\p@%
 %                       \belowdisplayshortskip 0pt \@plus2\p@ \@minus0\p@%
 %                       \@startsection{section}{1}{\z@}%
 %                        {-17\p@ \@plus -4\p@ \@minus -4\p@}%
 %                        {6\p@ \@plus 4\p@ \@minus 4\p@}%
 %                        {\normalfont\large\bfseries\boldmath
 %                         \rightskip=\z@ \@plus 8em\pretolerance=10000 }}
 \renewcommand{\subsection}{\@startsection{subsection}{2}{\z@}%
                        {-8\p@ \@plus -4\p@ \@minus -4\p@}%
                        {5\p@ \@plus 2\p@ \@minus 2\p@}%
                        {\normalfont\Large\bfseries\boldmath
                         \rightskip=\z@ \@plus 3em\pretolerance=10000 }}
  \renewcommand{\subsubsection}{\@startsection{subsubsection}{3}{\z@}%
                        {-6\p@ \@plus -4\p@ \@minus -4\p@}%
                        {1\p@ \@plus 1\p@ \@minus 0\p@}%
                        {\normalfont\normalsize\bfseries\boldmath}}
% \renewcommand{\paragraph}{\@startsection{paragraph}{4}{\z@}%
%                       {-8\p@ \@plus -4\p@ \@minus -4\p@}%
%                       {-2\p@ \@plus -0.22em \@minus -0.1em}%
%                       {\normalfont\normalsize\bfseries}}
 \makeatother



% *** GRAPHICS RELATED PACKAGES ***
\usepackage{graphicx}
\usepackage{comment}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{listings}
% declare the path(s) where your graphic files are
\graphicspath{{../figures/}}
% and their extensions so you won't have to specify these with
% every instance of \includegraphics
\DeclareGraphicsExtensions{.pdf,.jpeg,.png}

%\usepackage[outputdir=/Volumes/ramdisk/]{minted}
\usepackage{minted}
% *** MATH PACKAGES ***
\usepackage{amsmath}



% *** SPECIALIZED LIST PACKAGES ***
\usepackage{algorithmic}




% *** ALIGNMENT PACKAGES ***
\usepackage{array}

\usepackage{url}

\usepackage[utf8]{inputenc}
\usepackage[american]{babel}
\usepackage[backend=biber,style=ACM-Reference-Format]{biblatex}
\addbibresource{../library.bib} 
\addbibresource{../cryptobib/abbrev2.bib}
\addbibresource{../cryptobib/crypto_crossref.bib}

% Used for Theorems and Definitions
\usepackage{amsthm}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\theoremstyle{definition}
\newtheorem{remark}{Remark}
\newtheorem{assumption}{Assumption}

\usepackage{xcolor} 
\usepackage{xspace}
\usepackage{xstring} % required by IfEqCase

\usepackage{booktabs} % better tables
\usepackage{algorithm}
\usepackage{algorithmic}


% ishaq: adding our macros
\input{macros.tex}

\sloppy
\begin{document}
\fancyhead{}
% do not delete this code.    

%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title[Scheduling and Amortization for MPC]{Scheduling and Amortization for MPC}
 
%
% The "author" command and its associated commands are used to define the authors and their affiliations.
% Of note is the shared affiliation of the first two authors, and the "authornote" and "authornotemark" commands
% used to denote shared contribution to the research.
\author{Muhammad Ishaq}
\authornote{This work was done in part while the author was at RPI.}
\email{m.ishaq@ed.ac.uk}
%\orcid{1234-5678-9012}
%\author{G.K.M. Tobin}
%\authornotemark[1]
%\email{webmaster@marysville-ohio.com}
\affiliation{%
    \institution{University of Edinburgh}
    %\streetaddress{P.O. Box 1212}
    \city{Edinburgh}
    \state{Scotland}
%    \postcode{43017-6221}
}

\author{Lindsey Kennard}
\email{kennal@rpi.edu}
\affiliation{%
    \institution{Rensselaer Polytechnic Institute}
    %\streetaddress{1 Th{\o}rv{\"a}ld Circle}
    \city{Troy}
    \state{New York}
    %\country{Iceland}
}

\author{Ana L. Milanova}
\email{milanova@cs.rpi.edu}
\affiliation{%
    \institution{Rensselaer Polytechnic Institute}
    %\streetaddress{1 Th{\o}rv{\"a}ld Circle}
    \city{Troy}
    \state{New York}
    %\country{Iceland}
}

\author{Vassilis Zikas}
\authornote{This work was done in part while the author was visiting UCLA and supported in part by DARPA and SPAWAR under contract N66001-15-C-4065 and by a SICSA Cyber Nexus Research Exchanges grant.}
\email{vzikas@inf.ed.ac.uk}
%\orcid{1234-5678-9012}
%\author{G.K.M. Tobin}
%\authornotemark[1]
%\email{webmaster@marysville-ohio.com}
\affiliation{%
    \institution{University of Edinburgh} 
    %\streetaddress{P.O. Box 1212}
    \city{Edinburgh}
    \state{Scotland}
    %    \postcode{43017-6221}
}


%
% By default, the full list of authors will be used in the page headers. Often, this list is too long, and will overlap
% other information printed in the page headers. This command allows the author to define a more concise list
% of authors' names for this purpose.
%\renewcommand{\shortauthors}{Trovato and Tobin, et al.}

\renewcommand{\A}{{\sf A}}
\renewcommand{\B}{{\sf B}}
\renewcommand{\C}{{\sf C}}
\renewcommand{\D}{{\sf D}}


% As a general rule, do not put math, special symbols or citations
% in the abstract
\begin{abstract}


\end{abstract}


%
% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
% Please copy and paste the code instead of the example below.
%
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10003752.10010124.10010138.10010143</concept_id>
<concept_desc>Theory of computation~Program analysis</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003752.10003777.10003789</concept_id>
<concept_desc>Theory of computation~Cryptographic protocols</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10002978.10002979</concept_id>
<concept_desc>Security and privacy~Cryptography</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Theory of computation~Program analysis}
\ccsdesc[500]{Theory of computation~Cryptographic protocols}
\ccsdesc[300]{Security and privacy~Cryptography}

%
% Keywords. The author(s) should pick words that accurately describe the work being
% presented. Separate the keywords with commas.
\keywords{protocol mixing; linear programming; multiparty computation; program analysis; cryptography}


\begin{comment}
%
% A "teaser" image appears between the author and affiliation information and the body 
% of the document, and typically spans the page. 
\begin{teaserfigure}
    \includegraphics[width=\textwidth]{sampleteaser}
    \caption{Seattle Mariners at Spring Training, 2010.}
    \Description{Enjoying the baseball game from the third-base seats. Ichiro Suzuki preparing to bat.}
    \label{fig:teaser}
\end{teaserfigure}
\end{comment}
%
% This command processes the author and affiliation and title information and builds
% the first part of the formatted document.
\maketitle


\section{Introduction}
\label{sec:introduction}

In this short paper we define the problem of \emph{optimal parallelization} for Multi-party Computation (MPC), 
set it apart from classical work on parallelization for High-performance Computing (HPC), present preliminary 
results, and set directions for future research. 

\ana{1. Intro to MPC (from a PL point of view). Define the problem.}

\ana{2. Difference with HPC. Why "optimal HPC" = "minimal delay" is NOT "optimal MPC"}

\ana{3. Results statement.}

\ana{4. Future directions.}

\ana{Scope of paper: Should we expand towards 1) nested loops, 2) conversions, 3) implementation (what will we be saying with an implementation?)}

% no \IEEEPARstart

\section{Background and Problem Statement}
\label{sec:background}

\subsection{Scheduling in MPC}

\ana{Here we need more on MPC before jumping to scheduling. MPC-source, basic assumptions about static loop bounds, etc.}

For this treatment we make the following simplifying assumptions:

\begin{enumerate}
\item All statements in the program execute using the same protocol (sharing). That is, there is no share conversion.
\item All MPC instructions have the same unit cost, 1 unit.
\item There is unlimited bandwidth---i.e., a single MPC-instruction costs as much as $N$ amortized instructions, namely 1 unit.
\item MPC instructions scheduled in parallel benefit from amortization \emph{only if} they are the same instruction. Given our previous assumption, 
2 MUL instructions scheduled in parallel benefit from amortization and cost 1, however a MUL and a MUX instructions scheduled 
in parallel still cost 2.
\end{enumerate}

\paragraph{Problem 1:} Given a dependence graph of MPC instructions, find the \emph{loop-body} schedule 
with \emph{minimal cost}.

%\begin{figure*}[tbhp]
\begin{figure*}[tbhp]
\begin{tabular}{llll}
\begin{minipage}[b]{4.25cm}

\begin{minted}[fontsize=\footnotesize, linenos, numbersep=5pt, escapeinside=||]{java}
for (int i=1; i<=N; i++) {
  A: A[i] = f_1(B[i]);
  B: B[i] = f_2(A[i],D[i-1]);
  C: C[i] = f_3(A[i],D[i-1]);
  D: D[i] = f_4(B[i],C[i]);
}
\end{minted}
\end{minipage} 

&

\begin{minipage}[b]{4.25cm}
\includegraphics[width=0.5\textwidth]{figs/dependenceGraph.pdf}
\end{minipage}


&

\begin{minipage}[b]{4.25cm}
\includegraphics[height=0.15\textheight]{figs/MPCloop.pdf}
\end{minipage}

&

\begin{minipage}[b]{4.25cm}
\includegraphics[height=0.20\textheight]{figs/MPCaccrossLoop.pdf}
\end{minipage}
\\


(a) Source 
&
(b) Dependence graph
&
(c) Loop-body schedule
&
(d) Across-loop schedule

\end{tabular}
\caption{(a) shows the source code, taken from Aiken and Nicolau~\cite{Aiken:1988}, 
(b) shows the dependence graph. The solid edges denote within-iteration ordering constraints, e.g., A must run before B
because B depends on A. The dashed edges denote across-iteration ordering constraints, e.g., B(2), i.e., B in iteration 2
depends on D(1), i.e., D in iteration 1; in the HPC literature these are known as loop-carried dependencies. 
(c) shows the optimal loop-body schedule, and (d) shows the optimal across-loop schedule. A(1), B(1), etc. denote 
instruction A in iteration 1, etc.}
\label{fig:MPCexample}\vspace{-2ex}
\end{figure*}

\paragraph{Problem 2:} Given a dependence graph of MPC instructions representing a loop body (or given a loop-body schedule), 
find the \emph{across-loop} schedule with  \emph{minimal cost}.

\figref{fig:MPCexample} illustrates the problem with a code example from the classical high-performance computing (HPC) literature. 
\figref{fig:MPCexample}(c) shows the optimal loop-body schedule (answer to Problem 1). Instructions B and C can be scheduled in parallel, 
however, the schedule does not necessarily benefit form parallelization/amortization. If B and C (functions $f_1$ and $f_2$) are the \emph{same}
MPC instruction (e.g., both are MUX, MUL, ADD, or CMP, etc.), then they \emph{can} benefit from parallelization/amortization. Given
our assumptions stated above, the cost of running the loop-body schedule is 3. However, if B and C are different MPC-instructions,
e.g., B is MUL, but C is MUX, then the cost of running the schedule is 4. 

\figref{fig:MPCexample}(d) shows the optimal across-loop schedule (answer to Problem 2). We can schedule all A-instructions, across all iterations, 
in parallel, as A depends only on the initial value of B. We cannot do better but schedule B, C, and D sequentially, as they each depend on values
computed in the previous iteration. Again, if B and C are the same instruction, the optimal across-loop schedule will have cost of $1 + 2N$, 
and if B and C are NOT the same instruction, then it will have cost $1+3N$.


\ana{Mention difficulties. We start from IMP-like general-purpose PL syntax with array reads and writes. We translate the program into a dependence 
graph of MPC instructions. Then we proceed to compute the schedule.}






\subsection{Scheduling in HPC}
\label{sec:hpc}

In this section, we state the classical HPC scheduling problem, and argue the MPC scheduling problem poses unique challenges.

Similar problems arise in the HPC setting.

%\begin{figure*}[tbhp]
\begin{figure*}[tbhp]
\begin{tabular}{lll}


\begin{minipage}[b]{4.25cm}
\includegraphics[width=0.4\textwidth]{figs/HPCloop.pdf}
\end{minipage}

&

\begin{minipage}[b]{4.25cm}
\includegraphics[width=0.4\textwidth]{figs/HPCdoacrossLoop.pdf}
\end{minipage}

&

\begin{minipage}[b]{4.25cm}
\includegraphics[width=0.6\textwidth]{figs/HPCgreedyLoop.pdf}
\end{minipage}

\\

(a) Loop-body schedule
&
(b) Doacross across-loop schedule
& 
(c) Greedy across-loop schedule

\end{tabular}
\caption{Optimal HPC schedules.}
\label{fig:HPCexample}\vspace{-2ex}
\end{figure*}


\paragraph{Problem 1:} Given a loop body (i.e., dependence graph), find the loop-body schedule with \emph{minimal delay}. 

\paragraph{Problem 2:} Given a loop body (or a loop-body schedule), find the \emph{doacross} schedule with minimal delay.

\paragraph{Problem 3:} Given a loop body (or a loop-body schedule), find the \emph{greedy schedule} with minimal delay.

\figref{fig:HPCexample} illustrates the problem in HPC. \figref{fig:HPCexample}(a) shows the optimal loop-body schedule
which results in cost of 3. Again, we assume that all instructions have the same cost, a unit of 1. The key difference with the 
MPC schedule is that regardless of whether B and C are the same instruction opcode or not, B and C can be scheduled 
to run in parallel and the overall running time benefits from parallelization. 

The HPC literature has considered different kinds of across-loop scheduling. One scheduling, called \emph{doacross}~\cite{aiken,cytron},
requires that all instructions in an iteration are scheduled on the same processor. The optimal doacross schedule for our example
is shown in \figref{fig:HPCexample}(b) (taken directly from~\cite{aiken}). Aiken and Nicolau proposed a new schedule,
which they called \emph{greedy} schedule, where instructions in an iteration can be scheduled on different processors. 
The optimal greedy schedule for our example, which achieves better minimal delay than the optimal doaccross schedule, 
is shown in \figref{fig:HPCexample}(c) (again, taken directly from~\cite{aiken}). 

\ana{Here we have to make the argument that MPC is different from HPC.}
The example illustrates that optimal MPC scheduling and optimal HPC scheduling are different problems.
To summarize, scheduling and amortization in MPC is a different problem due to two key differences: (1) there 
is unlimited bandwidth while in HPC, we typically have a limited number of processors we can use to 
schedule instructions in parallel, and (2) we benefit from amortization only if the set of instructions scheduled
in parallel are the same; in contrast, in HPC any two instructions can be scheduled in parallel. 

\ana{Have to make the argument that in MPC all stmts are executed. Thus, the vectorization problem is
immediately simpler!}



%\section{\bf Preliminaries}
%\label{sec:preliminaries}

\ana{Relevant papers/books: 

\begin{enumerate}

\item Book: "Scheduling and automatic parallelization", Springer 2000, by Alain Darte, Yves Robert and Frederic Vivien. 
This book describes scheduling and parallelization in HPC: given a dependence graph and unlimited 
number of processors, one can compute an optimal (minimal delay) schedule in polynomial time. 
Given a finite number of processors, computing an optimal schedule becomes NP-hard.

\item https://theory.stanford.edu/~aiken/publications/papers/pldi88.pdf. "Optimal loop parallelization", PLDI 1988, by
Alex Aiken and Alex Nicolau. 
Given a dependence graph of the loop body, computes an optimal parallelization across loop iterations. 
The optimality metric is minimal delay. E.g., assuming 2 iterations, the delay is measured by the number 
of instructions in iteration 2 that are lagging behind iteration 1. 

\item https://www.cs.indiana.edu/~achauhan/Teaching/B629/2006-Fall/CourseMaterial/1998-popl-knobe-arrayssa.pdf.
"Array SSA", POPL 1998, by Kathleen Knobe and Vivek Sarkar. This paper defines an SSA form for arrays which I think 
is crucial for parallelization across loop iterations.

\end{enumerate}
}

\subsection{Precise Problem Statement}
\ana{TODO}

\section{Loop Body Parallelization}
\label{sec:parallelization_within_loop}
%\input{../sections/analysis.tex}

We first consider the answer to Problem 1 (in MPC). 
We argue that optimal parallelization within a loop body is NP-complete (under the above stated assumptions). 
Therefore, compilers must resort to heuristics to compute a schedule for the instructions within a loop body.

We consider two operations, call them $A$ and $M$. Each instruction in the program is either an $A$-instruction or
an $M$-instruction. In order to benefit from parallelization/amortization, we must schedule two or more 
$A$-instructions in the same parallel node (or two or more $M$-instructions in the same parallel node). 
Scheduling $A$-instructions in parallel with $M$-instruction does not benefit from amortization.
It incurs the exact same cost as scheduling the $A$-instructions in a node $P_A$, scheduling the $M$-instructions 
in a node $P_M$, and having $P_A$ precede $P_M$ in the parallel schedule. This is the difference 
between classical scheduling, as studied in parallel computing, and MPC scheduling. 

We make the following assumptions:

\begin{enumerate}

\item $A$ and $M$ are of equal cost, 1 unit.
\item There is unlimited bandwidth---i.e., a single $A$-instrution (or $M$-instruction) costs as much as $N$ amortized $A$-instructions 
(or $M$-instructions), namely 1 unit.
 
\end{enumerate}

Consider a loop body that consists of $n$ sequences: $S_1$, ... $S_n$ of $A$ and $M$ instructions. 
More precisely, the loop body is such that its instructions can be grouped into such sequences. 
$S_1$, ... $S_n$ can execute in parallel, however, all instructions within a sequence must 
execute sequentially. For example, consider the three sequences (the right arrow indicates a \emph{dependence},
meaning that the source node must execute before the target node): 
\begin{enumerate}
\item $A \rightarrow M \rightarrow A$
\item $A \rightarrow A \rightarrow A$
\item $M \rightarrow A \rightarrow M$
\end{enumerate} 

A \emph{schedule} $P: P_1 \rightarrow P_2 \dots \rightarrow P_k$ is such that for each sequence 
$S_i$ in the set, if $S_i[k]$ precedes $S_i[k']$ in $S_i$ then $S_i[k]$ is scheduled in node $P_l$, $S_i[k]$ 
is scheduled in node $P_{l'}$, and $P_l$ precedes $P_{l'}$ in $P$. 

The cost of a schedule $P$ is 
\[\mathit{cost}(P) = \sum_{i=1}^k \mathit{cost}(P_i)\]
where $\mathit{cost}(P_i) = 1$ if $P_i$ consists of $A$-instructions only, or $M$-instructions only, 
and $\mathit{cost}(P_i) = 2$ if $P_i$ mixes $A$-instructions and $M$-instructions. 

The problem is to find a schedule $P$ with \emph{minimal cost}. For example, 
a schedule with minimal cost for the sequences above is
\[ A(1), A(2) \rightarrow M(1), A(2), M(3) \rightarrow A(1), A(2), A(3) \rightarrow M(3) \]
(The parentheses above indicate the sequence where the instruction comes from: (1), (2), or (3).)
The cost of this schedule is 5. 

The problem of finding a schedule with minimal cost 
easily reduces to the problem of finding a \emph{shortest common supersequence}, 
a known NP-complete problem \ana{citation needed}. To see the reduction, 
suppose $P$ is a schedule with minimal cost (computed by a black-box algorithm). 
We can derive a schedule $P'$ with the same cost as $P$, by mapping each mixed node $P_i \in P$ 
to two consecutive nodes in $P'$: an $A$-instruction node followed by an $M$-instruction node.
Clearly, $P'$, which now is a sequence of $A$'s and $M$'s, is a supersequence of each sequence 
$S_i$, i.e., $P'$ is a common supersequence 
of $S_1 \dots S_n$. It is also a shortest common supersequence. (To see this, suppose, a 
shorter common supersequence, $P''$, exists. $P''$ is a schedule of $S_1 \dots S_n$
and the $\mathit{cost}(P'')$ equals the length of $P''$. Since $P'$ is longer than
$P''$, and $\mathit{cost}(P') = \mathit{cost}(P)$, that means $\mathit{cost}(P'') < \mathit{cost}(P)$, 
which is a contradiction since $P$ is a schedule with minimal cost.)

\ana{Question: are these two assumptions too strong?} 

\ana{Assumption 1 can be relaxed --- e.g., if $A$ is 5 times cheaper than $M$, 
we can construct a program where all $A$'s are sequences of five consecutive 
$A$'s, which reduces to the previous problem.}

\ana{Assumption 2, I am not sure if this is acceptable, or maybe it is too strong. 
My intuition is that incorporating into the cost a dependence on the number 
of instructions in each parallel node, is going to make the problem harder, not easier...}

\section{Across-Loop Parallelization} 
\label{sec:optimal_loop_parallelization}
%\input{../sections/optimal_loop_parallelization.tex}

We now consider the answer to Problem 2 (in MPC). 

\ana{We need an intro here to give a roadmap of what we are going to be doing.}

\begin{comment}
\subsection{Overview and Problem Statement} 

The problem is, given a loop-body schedule, compute the across-loop schedule
with minimal cost. The following examples illustrate. The first example is the inner 
product computation, and the second is Aiken and Nicolau's example.

\begin{center}
\begin{lstlisting}[language=Java]
A = ...
B = ...
ip = 0;
for (i=0; i<N; i++) {
  if (i%d(5)==0) para{t[i]=A[i]*B[i],...,t[i+d(5)-1]=A[i+d(5)-1]*B[i+d(5)-1]}
  if (i%d(6)==0) para{ip = ip + t[i]};
}  
\end{lstlisting}
\end{center}

The above notation is a convenient way to specify a schedule. Each statement $s$ in the loop body sequence 
is parallelized at a rate $d(s)$ (we assume that the loop body is a straight-line sequence which is the case in MPC). 
Notation  
\[{\sf if \; (i\%d(s)\!==\!0) \; para\{s(i),s(i+1),...,s(i+d(s)-1)\}}\]
means that the first $d(s)$ iterations of statement $s$, denoted by $s(i),...s(i+d(s)-1)$, are executed in a parallel block; 
then the following $d(s)$ iterations are executed in a parallel block, and so on. The execution of $d(s)$ statements $s$ in 
a block benefits from amortization of the operation at $s$.
If {\sf i\%d(s)==0} evaluates to false, then the $i$-th iteration skips $s$, because $s(i)$ has executed earlier in a parallel block.

In the above example {\sf d(5)} is N, meaning that all N multiplications are executed in parallel.
In contrast, {\sf d(6)} is 1, meaning that the summation statements are executed sequentially.

A more interesting example involves array reads and writes. We return to the Aiken and Nicolau
example:

\begin{lstlisting}[language=Java]
for (i=0; i<N; i++) {
  if (i%N==0) para{A[i]=f1(B[i]),...,A[i+N-1]=f1(B[i+N-1])};
  if (i%1==0) para{B[i]=f2(A[i],D[i-1])};
  if (i%1==0) para{C[i]=f3(A[i],D[i-1])};
  if (i%1==0) para{D[i]=f4(B[i],C[i])};
}	
\end{lstlisting}


The above across-loop schedule entails that the first instruction is parallelized---all
N instructions A can be computed at once because each depends only on {\sf B[i]}, 
which at the point {\sf A[i]} is computed, refers to a value assigned outside of the loop. 
In contrast, subsequent instructions are executed sequentially. Take B, for example. 
There is a dependence ``cycle'' from {\sf B[i]} to {\sf D[i]} then {\sf B[i+1]} in the subsequent 
iteration. (The cycle is shown in~\figref{fig:MPCexample}(b).) {\sf B[i]}'s cannot be computed 
in parallel because each one depends on the {\sf B[i]} value computed in the previous iteration.

Now consider the above code but slightly modified. {\sf B[i]} and {\sf C[i]} are now 
computed based on the value of {\sf D[i-2]} assigned two iterations earlier.

\begin{tabular}{lll}
\begin{lstlisting}[language=Java]
for (i=1; i<=N; i++) {
  A[i]=f1(B[i]);
  B[i]=f2(A[i],D[i-2]);
  C[i]=f3(A[i],D[i-2]);
  D[i]=f4(B[i],C[i]);
}	

\end{lstlisting}
& 
~
&
\begin{lstlisting}[language=Java]
for (i=0; i<N; i++) {
  if (i%N==1) para{A[i]=f1(B[i]),...};
  if (i%2==1) para{B[i]=f2(A[i],D[i-2]),...};
  if (i%2==1) para{C[i]=f3(A[i],D[i-2]),...};
  if (i%2==1) para{D[i]=f4(B[i],C[i]),...};
}	
\end{lstlisting}

\end{tabular}

{\sf B[i]} still depends on a value computed in earlier iterations, i.e., there are loop-carried dependences, 
but the value, D[i-2] is two iterations earlier. Thus, we can take parallelization blocks of 2, e.g., computing 
{\sf B[0],B[1]} in a parallel block, then {\sf B[2],B[3]}, etc.
Note however, that we cannot take a parallelization block larger than 2.
%The value of B will depend on a value being computed in parallel.

The key problem that we address in this paper is computing the maximal rate $d(s)$ allowed by program dependences 
for each statement $s$. Program dependences give rise to a partitioning of the sequence of {\sf para} blocks into a DAG of
strongly connected components. (We elaborate on this and define the partitioning precisely later in the paper.)
In the above example, there are 2 SCCs---one component consists of just the {\sf para} block that computes 
{\sf f1(B[i])} and the other component consists of the remaining three {\sf para} blocks. The three para blocks
are interdependent and hence, they are in the same component. 

It is an invariant of our approach that the rates of all blocks in a SCC are the same, $d(s_1) = d(s_2) = d(\mathit{SCC})$
for each $s_1, s_2 \in \mathit{SCC}$. Unfortunately, as we argued earlier scheduling within a SCC is NP-complete, 
and also, scheduling of the components in the DAG is NP-complete. Assuming that we have an optimal schedule 
for each SCC, the sum of the costs of all SCCs is an upper bound on the optimal cost and the sum of the longest chain
in the DAG is a lower bound on the optimal cost. In the special case when the DAG is a straight line, which is the case 
is the typical case \ana{how many of the actual benchmarks???} the sum the costs of all SCCs is the \emph{minimal} cost.

\ana{Because the results are somewhat negative, i.e., thing is NP-complete, we'd need some experiments, at least 
analysis of loop structure in different benchmarks. I am pretty sure the structure is straight-line DAG with very simple SCCs, 
hence, we do have an optimal schedule anyway.}

\subsection{Preliminaries}

%\begin{figure*}[tbhp]
\begin{figure}[tbhp]
\begin{tabular}{ll}
\begin{minipage}[b]{4.25cm}

\begin{minted}[fontsize=\footnotesize, linenos, numbersep=5pt, escapeinside=||]{java}
// returns val%mod    
int rem(int val, int mod) {
  int rem = 0;
  for (int j = LEN-1; j |$\ge$| 0; j--) 
  {
    rem = rem << 1;
    // rem[0] = val[j]                                                                                                            
    rem = rem + ((val>>j)&1);   
    if (rem |$\ge$| mod) 
    {
      rem = rem - mod;
    }
  }    
  return rem;
}
\end{minted}
\end{minipage} 

&

\begin{minipage}[b]{4.25cm}
\begin{minted}[fontsize=\footnotesize, linenos, numbersep=5pt, escapeinside=||]{java}
// begin inlined rem
int rem0 = 0;
for (int j = LEN-1; j >= 0; j--) 
{
  rem1 = (j==LEN-1) ? rem0 : rem5;
  rem2 = rem1 << 1;
  rem3 = rem2 + (x1>>j)&1; 
  rem4 = rem3 - y1;
  cnd1 = CMP(rem3 >= y1);
  rem5 = MUX(rem3,rem4,cnd1);
}  
// end inline rem        
\end{minted}
\end{minipage}
\\

(a) Source 
&
(c) MPC-source

\end{tabular}
\caption{(a) shows standard (IMP-like) source for an MPC-friendly implementation 
of integer division~\cite{Demmler}, and (b) shows MPC-source. Line 5 {\sf rem1 = (j==LEN-1) ? rem0 : rem5;} 
is what we call a {\em pseudo-$\phi$} node. Note that the {\sf if}-statement on left
becomes straight-line code in MPC. The program \emph{runs both branches}, and 
at the end runs the conditional of the if-statement followed by the multiplexer. 
If {\sf cnd1} is {\sf true}, then {\sf rem} gets assigned the value along the left branch;
otherwise, it gets assigned the value along the right branch.}
    \label{fig:example}\vspace{-2ex}
\end{figure}


\subsubsection{MPC-Source} 

MPC-Source is an SSA-based intermediate representation
of MPC programs~\cite{ccs paper}. MPC-Source is, essentially, a straight-line sequence
of ``components'', where each ``component'' is either a nested for-loop sequence (called for-loop block), 
or a simple MPC-statement. \figref{fig:example} shows an example. MPC-Source can be constructed
in a standard way from an SSA-translation of the source---each branch of an 
{\sf if}-statement is added to the sequence, the conditional becomes an MPC comparison (CMP), 
and the $\phi$-node becomes an MPC multiplexer (MUX). 

MPC-Source uses standard SSA~\cite{Cytron:1991TOPLAS} which treats array writes as scalar writes, 
e.g., {\sf A[i] = f1(B[i])} is a write of a ``scalar'' variable $A$. Each {\sf A[i] = ...} and {\sf A[j] =...} will be treated 
as separate assignments to variable $A$, thus inducing {\sf A1 = ... } and {\sf A2 = ... } static single assignment
nodes. The semantics of these array assignments is different than scalar assignments in
the sense that they are ``vector assignments''; they absorb the write to the corresponding index
and copy the values at the remaining indices. However, from the point of view of analysis, including
our analysis for the purposes of scheduling and amortization, the array and scalar assignments are 
treated the same way.

The assignment to {\sf A[i]} (and to {\sf B[i], C[i]} and {\sf D[i]}) in Aiken and Nicolau's 
example will turn into {\sf A2 = f1(B1,A1)} ({\sf A1} is included in the operation because the
elements of all but index $i$ are used in the assignment) and the loop gives rise to several pseudo-$\phi$ nodes: 

\begin{lstlisting}[language=Java,escapeinside=`']
// initialization of A0,B0,C0, and D0
for (i=1; i<=N; i++) {
  A1 = `$\phi$'(A0,A2);
  B1 = `$\phi$'(B0,B2);
  C1 = `$\phi$'(C0,C2);
  D1 = `$\phi$'(D0,D2);
  A2 = f1(B1,A1) // A[i]=f1(B[i]);
  B2 = f2(A1,D1,B1); // B[i]=f2(A[i],D[i-1]);
  C2 = f3(A1,D1,C1); // C[i]=f3(A[i],D[i-1]);
  D2 = f4(B2,C2,D1); // D[i]=f4(B[i],C[i]);
}	
\end{lstlisting}

The problem with standard SSA is that it looses fine-grain index information that is necessary for parallelization. 
In the above example, the analysis determines that assignment A2 depends on the previous iteration,
which entails parallelization rate of 1. 

\subsubsection{Array SSA} 

Therefore, we make use of Array SSA. 
Originally proposed by Knobe and Sarkar, Array SSA has been used for loop parallelization in HPC.
We adapt Array SSA for MPC-source and build our optimal loop parallelization algorithm
based on this adaptation.


Array SSA introduces a parallel array structure, denoted $@A$, associated to each array $A$. $@A$ is a ``timestamp'' 
that tracks the specific loop iteration when each $A[i]$ was last modified. We can use this information to compute a more
precise parallelization rate. 
Consider Aiken and Nicolau's example, now using Array SSA:

\begin{figure}
\begin{lstlisting}[language=Java,escapeinside=`']
for (i=1; i<=N; i++) {

  Invariant: @A1[j] == j if `$j < i$', @A1[j] == 0 otherwise

  A1 = `$\phi$'(A3,A0); @A1 = max(A3,A0);  
  B1 = `$\phi$'(B3,B0); @B1 = max(B3,B0);
  C1 = `$\phi$'(C3,C0); @C1 = max(C3,C0);
  D1 = `$\phi$'(D3,D0); @D1 = max(D3,D0);

  A2[i] = f1(B1[i]); @A2[i] = i;
  A3 = `$\phi$'(A2,A1); @A3 = max(A2, A1);
  B2[i] = f2(A3[i],D1[i-1]); @B2[i] = i;
  B3 = `$\phi$'(B2,B1); @B3 = max(B2, B1);
  C3[i] = f3(A3[i],D1[i-1]); @C2[i] = i;
  C3 = `$\phi$'(C2,C1); @C3 = max(C2, C1);
  D3[i] = f4(B3[i],C3[i]); @D2[i] = i;
  D3 = `$\phi$'(D2,D1); @D3 = max(D2, D1); 
}
\end{lstlisting}
\caption{Aiken and Nicolau's example using Array SSA.}
\label{fig:ArraySSAAikenNicolau}
\end{figure}

There are three kinds of statements added by Array SSA. First, 
\[
{\sf A2[i] = f1(B1[i]); @A2[i] = i;}
\]
Array SSA statement {\sf @A2[i] = i;} records the iteration, $i$ when {\sf A2[i]} is written.
The index is not always $i$, it can be any $f(i)$, function of $i$, however, we assume
that the loop always iterates from 1 to $N$ with step 1. Second and third, there are
the \emph{define} $\phi$ statement  and corresponding timestamp recording statement:
\[ 
{\sf A3 = }\phi{\sf (A2,A1); @A3 = max(A2, A1);}
\]
Statement ${\sf A3 = }\phi{\sf (A2,A1);}$ is a \emph{define} $\phi$ node that merges arrays 
{\sf A2} and {\sf A1}---the semantics of the define $\phi$ is that the value at the index that is
modified is taken from ${\sf A2}$ and the values at indeces other than $i$ 
are taken from array {\sf A1}. Statement 
{\sf @A3 = max(A2, A1);} is a timestamp recording statement; it picks the latest iteration 
to assign for each index $i$---in this case, when the phi- and max- statements 
appear immediately under an array write, it assigns {\sf @A3[j] = i} if $j=i$, 
and {\sf @A3[j] = @A2[j]} otherwise.

Array SSA allows for the standard \emph{merge} $\phi$ statement at if-then-else statements. 
We may have 
\[ 
{\sf A3 = }\phi{\sf (A2,A1); @A3 = max(A2, A1);}
\]
in which case ${\sf A2}$ is the array long the true branch and ${\sf A1}$ is the array
along the false branch. 
%\ana{Add merge $\phi$}

\subsubsection{MPC-Source with Array SSA}

Merge phi nodes  e.g., ${\sf A3 = \phi(A2,A1), @A3 = max(A2, A1);}$ 
can be added to MPC-source without privacy leaks. ${\sf A3 = \phi(A2,A1)}$ is naturally translated as 
point-wise MUX for each index $i$. The timestamp statement ${\sf @A3 = max(A2, A1);}$ 
has the same meaning as in standard Array SSA---{\sf @A3[i] = max(@A2[i],@A1[i])}.
MPC-source expands and executes each arm of the if-then-else statement.
If only one arm modified the array at index $i$ {\sf @A3[i] = max(@A2[i],@A1[i]) = i}. 
Similarly, if both arms modified the array at $i$, the timestamp index again will be again $i$. 
%We note that in MPC-source the timestamp arrays {\sf @A} are known \emph{statically}, 
%unlike in standard Array SSA, where they are inherently \emph{dynamic}. 
%\ana{Double check? Make a statement that an adversary monitoring execution does not
%infer anything from SSA phi nodes.}

\subsection{Analysis Algorithm}

\subsubsection{Assumptions on MPC-Source}

To make the problem tractable we state several assumption about the loop body.
These assumptions are natural and they have been adopted in classical works as 
well~\cite{Aiken:PLDI1988}. 
These assumptions are natural and hold for all loop body sequences we have examined,
both in MPC and HPC. This is because loops that violate these assumptions would be
very difficult to understand and maintain. Moreover, if loops use arrays in readonly way, 
which is the case in the vast majority of cases particularly in MPC, the assumptions automatically 
hold true.
~\ana{This statement is true for all loops I have seen but we do need 
a more systematic way of studying loops and reporting on structure.}

%Array writes.~\ana{We have to see what the distinction was, regular vs. irregular loops}:
\begin{enumerate}
\item For each array read of $A$: $... = g(A[f(i)])$ and corresponding write to $A$: $A[f'(i)] = ...$
we require that $f(i) = f'(i)$ for every $0 \le i < N$. Here $i$ is the induction variable and $N$ is
the loop bound. 

\item Let $A[f_1(i)]...A[f_k(i)]$ be a sequence of writes to $A$ in the loop body sequence. 
%\ana{How is the sequence determined?} with $A[f_k(i)]$ being the most recent one. 
As usual, here $i$ denotes the induction variable. We require that for every $0 \le i < N, k,l$, $f_k(i) \neq f_l(i)$, 
or in other words, those writes access different elements of the array. Furthermore, we require 
that $f_k(i) \neq f_l(j)$, or in other words, writes across different iterations access different array 
elements. %\ana{Needs rewording. Can be simplified.}

\item Our last assumption is the ``constant rate'' assumption. It states that a statement 
$s$ in the loop body sequence depends on itself at a ``constant rate'', i.e., there cannot be a 
case where $s(i)$ depends on $s(j), j<i$ and on $s(k), k<i$ s.t. $i \neq j$. (Here $s(i)$
denotes the execution of $s$ in iteration $i$.)
More formally, let $s(j) \dashrightarrow \cdot \longrightarrow s(i)$ be a dependence chain,
where the dashed arrow denotes the loop carried dependence. For every 
$s(j) \dashrightarrow \cdot \longrightarrow s(i)$ we have $i = j+m$ for some constant $m$.

\end{enumerate}

%Constant loop schedule. Let $S$ be a loop schedule, i.e., a directed acyclic graph that defines "executes before"
%scheduling constraints among the statements of the loop body. We require that the 
%parallelization of the loop schedule obeys the constant loop schedule constraint: each instance of $S$
%in the loop linearization obeys the scheduling constraints defined by the DAG of $S$. \ana{Justify why!}

\subsubsection{Index Invariant} 

The \emph{index invariant} makes an assertion about when {\sf A[i]} is written as a function of $i$.
It is essential in computing the rate of parallelization $d(s)$. \figref{fig:ArraySSAMPCAikenNicolau}
shows the index invariant on ${\sf @A1}$ (all other arrays have the exact same index invariant). 
The index invariant can be specified by the programmer, as it is a form of a loop invariant or it can 
be inferred. \ana{Can we infer the invariant???}

%\ana{Can we compute this index easily: A[f(j)] = i, if j>=i, A[f(j)] = 0 otherwise?
%Under what assumptions this is true???}. \ana{We will use the Array SSA stuff to compute index; 
%can get rid of it once we.}

\subsubsection{Computing $d(s)$}

We assume a loop body that consists of three-address MPC statements:
\[ v1 = v2 \oplus v3 \]
MUX statements:
\[ v1 = MUX(v2, v3, v4) \]
and $\phi$-nodes:
\[ v1 = \phi(v2, v3) \]
where $v1,v2$, $v3$, and $v4$ are either scalar variables, e.g., {\sf x} or array elements {\sf A[f(i)]}.
Define phi- and max- statements are elided from the representation, as
their only purpose is to compute the invariant. Merge phi-statements are translated
into point-wise MUX statements, as is standard in MPC. 

\ana{Pseudo phi nodes!}

\begin{figure}
\begin{lstlisting}[language=Java,escapeinside=`']
for (i=1; i<=N; i++) {

  // Index Invariant: @A1[j] == j if `$j < i$', @A1[j] == 0 otherwise

  A1 = `$\phi$'(A3,A0); 
  B1 = `$\phi$'(B3,B0); 
  C1 = `$\phi$'(C3,C0);
  D1 = `$\phi$'(D3,D0); 

  A2[i] = f1(B1[i]); 
  B2[i] = f2(A3[i],D1[i-1]); 
  C3[i] = f3(A3[i],D1[i-1]); 
  D3[i] = f4(B3[i],C3[i]); 
}
\end{lstlisting}
\caption{Aiken and Nicolau's example using Array SSA.}
\label{fig:ArraySSAMPCAikenNicolau}
\end{figure}
 
%\ana{Figure out how to reason about cycles based on Array SSA.}

Recall that the loop body is a linear sequence of statements. To compute $d(s)$ of statement $s$, 
we follow def-use chains backwards collecting all reachable pseudo-phi node. If there is a psudo-phi 
node of a scalar, then $d(s) = 1$; for an array we retrieve the value $A[f(i)]$ from the invariant. \ana{formalize, polish!}

\ana{Define Schedule $S$.}

\ana{Add Algorithm}

\ana{Prove main theorem, that this schedule is of minimal cost. I.e., under the restriction of "constant loop body schedule", there
does not exist a schedule $S'$}

for a statement x = f(y,z), follow the reverse def-use link.
\end{comment}

\subsection{High-level CFG to MPC $G$}
\label{CFG}

\subsubsection{From $\phi$-nodes to MUX-nodes}

\ana{Difficulties: Translate to MUX nodes, adapt classical SSA algorithm, arrays, reads and writes!}

\begin{figure}
\small
\[
\begin{array}{l@{~~~~~}l}
  \begin{array}{l@{~}l@{~~~}l}
  s & ::= s ; s \\ 
  & \mid \x = \y \; \mid \x=\y \; \op \; \z \mid {\sf A[f(i)] = x} \; \mid {\sf x = A[f(i)]} & \mathit{assignment} \\
%  & \mid \x = \phi(\y,\z) \\
  & \mid {\sf for} \; (i = 0; i \le \mathit{Const}; \mathit{i\!+\!+}) \; \{ \; s \; \} \\
  & \mid {\sf if} \; (\x \; \cop \; \y) \; {\sf then} \; \{ \; s \; \} \; {\sf else} \; \{ \; s \; \} \\
 % \bool &::= \x \; \cop \; \y & \mathit{comparison} \\
  \op &::= + \mid - \mid * \mid / & \mathit{arithmetic} \; \mathit{operator} \\
  \cop &::=  \; == \; \mid \; != \; \mid \; < \; \mid \; \le & \mathit{comparison} \; \mathit{operator}

  \end{array}
\end{array}
\]
%\vspace{-0.2in}
\caption{IMP syntax as defined in \cite{Ishaq2019}: $s$ is a sequence of statements. 
\code{x}, \code{y}, \code{z}, and $i$, are variables.
} 
\label{fig:syntax}
\end{figure}


We consider a standard IMP-like imperative language. The syntax is given in~\figref{fig:syntax}. 
Without loss of generality, we assume that the syntax gives rise to a CFG and we can apply the 
Cytron et al.'s Algorithm for the efficient computation of SSA over this CFG~\cite{Cytron:1998}. 

In particular, we are interested in a sequence of statements that form a loop body, i.e., while 
the outermost statement is a {\sf for} the remaining statements are assignments and {\sf if}s. 
There are two principal hurdles. One is to translate the CFG into SSA form, where $\phi$ nodes 
are turned into MUX nodes. One cannot simply reuse the classical algorithm by Cytron et. al. 
because $V_3 = \phi(V_1,V_2)$ nodes do not retain information about the predicate that triggers 
$V_1$ vs. $V_2$; all $\phi$ nodes represent is conditional control flow, i.e., that $V_3$ is either 
$V_1$ or $V_2$. Another issue is that SSA $\phi$ nodes can combine multiple conditionals. 
To illustrate, consider the code

\begin{minted}[fontsize=\footnotesize, linenos, numbersep=5pt, escapeinside=||]{java}
z = 0;
...
if (x > 0) {
  if (y > 0) {
    z = 1;
  }  else {
    z = 2;
  }
}
print z
\end{minted}
Line 10 is the dominance frontier of the assignments to \z, and Cytron et. al.'s algorithm
creates a $\phi$ node at 10: $z_3 = \phi(z_0, z_1, z_2)$. There is no information retained
that $z_0$ is triggered under path condition $x \le 0$, $z_1$ is triggered under path condition 
$x > 0 \; \wedge \; y > 0$, and $z_2$ is triggered when $x > 0 \; \wedge \; y \le 0$. The 
Multiplexer at the join point needs this information however in order to assign the correct 
value to $z_3$ at runtime.

We propose a simple extension to the classical algorithm. Recall from Cytron et. al.'s 
that efficient static single assignment computation has two phases, phase one is the 
placement of phi-nodes at dominance frontiers of assignments, and phase two is the 
renaming of variables $V$ into $V_1$, $V_2$, etc.

\ana{Here we need an explanation for lines 23-45. Turning n-ary phi-nodes into binary MUX nodes, 
just the same classical algorithm with minor extension.}

\ana{Example of CFGs for above example.}

Once we have the graph in SSA form with \ana{MORE}

\begin{algorithm}
\caption{From $\phi$-nodes to MUX nodes}
\begin{algorithmic}[1]
%\REQUIRE $c \neq null$
%\STATE $L \leftarrow get\_nodes(c)$
%\FORALL{$n$ in $L$}
%\STATE $...$
%\ENDFOR
\FORALL {variables $V$}
\STATE $C(V) \leftarrow 0$
\STATE $S(V) \leftarrow \mathit{EmptyStack}$
\STATE $P \leftarrow \mathit{EmptyStack}$
\ENDFOR
\STATE call SEARCH($\mathit{Entry}$) \\
\STATE ... \\
SEARCH(X) : \\
\FORALL {statements $A$ in $X$} 
\IF {$A$ is a $\phi$-assignment}
   \STATE {remove $A$ and continue}
\ENDIF
\FORALL {variables $V$ in $\mathit{RHS}(A)$}
   \STATE {replace $V$ with $V_i$ where $i = \mathit{Top}(S(V))$}
\ENDFOR

\FORALL {variable $V$ in $\mathit{LHS}(A)$}
   \STATE { $i \gets C(V)$} 
   \STATE {replace $V$ with $V_i$ in $\mathit{LHS}(A)$}
   \STATE {push $i$ onto $S(V)$}
   \STATE {$C(V) \gets i+1$}
\ENDFOR
\ENDFOR

\FORALL {$Y \in Succ(X)$}
\IF {$X$ is a conditional node}
   \STATE {push $\mathit{Cond}, \mathit{Branch}$ onto $P$ // $\mathit{Branch}$ is $T$ if $X \rightarrow Y$ is the True branch, $F$ otherwise}     
\ENDIF   
     \STATE{// $Y$ is not done if $Y$ has an incomplete MUX predecessor or an original CFG predecessor}
      \IF {$Y$ has $\phi$-assignments and $Y$ is not done} 
          \STATE {$\mathit{Cond}, \mathit{Branch} \gets$ pop $P$}
          \FORALL {$\phi$-assignments in $Y$}
               \IF {$Z\!: V = \mathit{MUX}(Cond, ..., ...) \in \mathit{Pred}(Y)$}
                  %\STATE {replace $V$ in $RHS(Z)$ with $V_i$, where $i = Top(S(V)$}
                  \STATE {remove edge $X\rightarrow Y$, add edge $X\rightarrow Z$ to $\mathit{CFG}$}
                  \STATE {call SEARCH($Z$) // updates $V$'s in LHS and RHS} 
               \ELSE
                   \STATE {$i = Top(S(V))$}
                   \IF {$\mathit{Branch} == T$}
                      \STATE {create new node $Z\!: V = \mathit{MUX}(\mathit{Cond}, V_i, V)$}
                   \ELSE 
                      \STATE {create new node $Z\!: V = \mathit{MUX}(\mathit{Cond}, V, V_i)$}
                   \ENDIF   
                   \STATE {remove edge $X\rightarrow Y$, add edge $X\rightarrow Z$ to $\mathit{CFG}$} 
               \ENDIF
          \ENDFOR 
      \ENDIF
\ENDFOR
\FORALL {$Y \in \mathit{Children}(X)$}
   \STATE {call SEARCH($Y$)}
\ENDFOR
\FORALL {assignments $A$ in $X$}
   \FORALL {variables $V$ in oldLHS($A$)}
       \STATE {pop S(V)}
   \ENDFOR
\ENDFOR
\end{algorithmic}
\label{alg:algorithm1}
\end{algorithm}


\subsubsection{Handling of Arrays}
\label{???}

So far we focused on the classical SSA analysis and the extension necessary to create MUX nodes. 
Classical SSA treats arrays as scalars, i.e., an array write, e.g., {\sf A[i] = x+y} is considered
a modification of {\sf A} and warrants its own indexed variable ${\sf A}_k$. A subsequent use of {\sf A}, 
even one such as {\sf x = A[i+1]} where there is no def-use link from {\sf A[i] = x+y}, will be 
considered a use of ${\sf A}_k$. This hinders parallelization. To illustrate, consider our running
example in~\figref{fig:MPCexample}:
\begin{minted}[fontsize=\footnotesize, numbersep=5pt, escapeinside=||]{java}
for (...) {
  A: A[i] = f_1(B[i]);
  B: B[i] = f_2(A[i]);
  ...
}
\end{minted}
Since {\sf A} and {\sf B} are treated as standard scalars, the dependence analysis will record
a dependence from {\sf B} to {\sf A} via the back edge. As a result, statement {\sf A} wouldn't 
be vectorized because each (i+1)-th iteration depends on {\sf B} in the i-th iteration,
which depends on {\sf A} in the i-th iteration. 

To mitigate against this, we propose a technique, similar to Array-SSA though much simpler, 
which breaks certain dependence edges and allows for better vectorization. 
\ana{Have to make a claim how 
often this technique resolves dependences perfectly, and how often it defaults to standard SSA.}

\ana{TODO: Summary of the technique}

\paragraph {Equivalence and Non-equivalence} Let $f(i)$ and $f'(i)$ be two index functions on induction variable $i$, 
e.g., we have array accesses ${\A}[f(i)]$ and ${\A}[f'(i)]$. We say that $f(i) \cong f'(i)$ iff for every $1 \le i \le N$,
$f(i) = f'(i)$. We say that $f(i) \ncong f'(i)$ iff for every $1 \le i \le N$, $f(i) \neq f'(i)$. 

\ana{This needs explanation and examples. The context is single loops where multidimensional arrays are turned 
into one dimensional ones. The index function becomes complex.}

\paragraph{Array Well-formedness Conditions} Let ${\A}$ be an array mentioned in the loop body. 
We treat array accesses ${\A}[f(i)]$ as distinct scalar variables if we can show that the loop body is
well-formed with respect to \A. Otherwise, we treat array {\A} as a single variable, thus defaulting to the 
case of standard SSA. The well-formedness conditions are as follows: \ana{This needs some work!}

\begin{enumerate}
\item For each pair of array writes to \A, $n_1\!: A[f(i)] = ... $ and $n_2\!: A[f'(i)] = ... $, we have either $f(i) \cong f'(i)$ or 
$f(i) \ncong f'(i)$. 

\item For each pair $n_1\!: A[f(i)] = ... $ and $n_2\!: ... = A[f'(i)]$ such that $n_1$ reaches $n_2$ on a forward path, 
we have either $f(i) \cong f'(i)$ or $f(i) \ncong f'(i)$. 

%\item For each pair $n_1\!: A[f(i)] = ... $ and $n_2\!: A[f'(i)] = ... $ either $f(i-d) \cong f'(i)$ for some unique $d > 0$, 
%or $f(i-d) \ncong f'(i)$ for every $d > 1$. 

\item For each pair $n_1\!: A[f(i)] = ... $ and $n_2\!: ... = A[f'(i)]$ %such that $n_1$ reaches the loop exit (we assume that there is
%a unique loop exit node) on a forward path, and there is  $n_2$ on a forward path, 
we have $f(i-d) \cong f'(i)$ for at most one $d$ such that $1 \le d \le N-1$ and 
we have $f(i-d') \ncong f'(i)$ for every $d' \neq d$. 

\end{enumerate}

To see the intuition behind these rules, consider rule (1). 
In other words, the two array writes are either equivalent, i.e., at each iteration they modify the same
location, or they are non-equivalent, i.e., at each iteration they modify distinct locations. Note that the two array writes
``clash'' in one way or another. If $n_1$ reaches $n_2$ (or vice versa, $n_2$ reaches $n_1$), then if $f(i)$ and $f'(i)$ 
are neither equivalent nor non-equivalent, there would be a kill in some iterations and not in other; in contrast, if
they are equivalent, there is always a kill, and if they are non-equivalent, there is never a kill. If neither $n_1$ reaches
$n_2$ nor the other way around, then the two array writes will ''clash'' at a join node. If $f(i)$ and $f'(i)$ are neither 
equivalent nor non-equivalent, then there would be one kind of MUX for certain iterations and a different kind of MUX 
for the rest; if $f(i)$ is equivalent to $f'(i)$, then the MUX will be $... = \mathit{MUX}(\mathit{cond}, {\A}[f(i)], {\A[f'(i)]})$, and 
$f(i)$ and $f'(i)$ are non-equivalent then there will be two MUX nodes: $... = \mathit{MUX}(\mathit{cond}, {\A}[f(i)], {\A'[f(i)]})$
and $... = \mathit{MUX}(..., {\A}[f'(i)], {\A'[f'(i)]})$. (Note that after SSA, the A's will be properly indexed.)
\ana{I need explanations of (2) and (3).}
Now consider rule (3). If there exist a $d$ such that $f(i-d) \cong f'(i)$, that means that the array write $j: \A[f(i)] = ... $ that
happened $d$ iterations before array read $k: ... = \A[f'(i)]$ is being used at that read. In addition, this holds for every $i$, 
i.e., for every iteration, the array read at $k$ references the array write at $j$ that happened $d$ iterations ago. Also,
since for every other $d'$ the array accesses are non-equivalent, this means, that the read at $k$ never references  
the write at $j$ in a different iteration.
%any other previous iteration, just $I-d$, where $I$ is the current iteration.

Consider our running example in~\figref{fig:MPCexample}(a). There is a single write to each array in the loop body, 
so there are no write-write pairs and no tests for (1). There are the following write-read pairs: 2 and 3 (access of \A), 
2 and 4 (access of \A), 3 and 5 (access of \B), 4 and 5 (access of \C), 3 and 2 (access of \B), 5 and 3 (access of \D) and 5 and 4 (access of \D).
We apply the forward test, (2), only on the first three pairs, as for the remaining ones, there is no forward path from the write to the read. 
Test (2) clearly passes because $i$ is obviously equivalent to $i$. For the remaining pairs, we only apply the backward test, test (3). 
Pair 3 and 2 passes as well because $i-1$ and $i$ are nonequivalent for every $d > 0$. 5 and 3, and analogously 5 and 4, pass test (3). 
In these two cases, the unique $d = 1$ makes $i - d$ and $i-1$ equivalent. 


\subsubsection{Constructing MPC G}

Construction proceeds as follows: 

\begin{enumerate}

\item We consider the forward flow graph, and group array accesses $\A[f(i)]$ into equivalence classes. If $f(i) \cong f'(i)$
then accesses $\A[f(i)]$ and $\A[f'(i)]$ are in the same equivalence class, i.e., they are equivalent accesses. We write $\A[f(i)]_k$ 
(just as $V_k$) to denote the SSA-indexed versions of the equivalent accesses. (Although we give a general treatment, the reader 
may just think of the equivalence accesses as just one $\A[f(i)]$, e.g., $\A[i]$). 

\item We run Algorithm~\ref{alg:algorithm1} to compute SSA of the loop body with MUX nodes. Equivalent accesses get their own indexed versions.

\item Constructing the ``forward'' portion of the graph: add a forward edge $n_1 \rightarrow n_2$ if for some $V_k$, 
$V_k \in LHS(n_1)$ and $V_k \in RHS(n_2)$.  

\item For each scalar $V$, let $n_1$ be the node such that $V_\mathit{max} \in LHS(n_1)$, 
i.e., this is the node that defines the $V$ exposed at the exit of the loop. Add an edge $n_1 \stackrel{-1}{\dasharrow} n_2$ 
for each $n_2$ such that $V_0 \in RHS(n_2)$. In other words, $n_2$ has an upward exposed use of $V$, i.e., one that comes
from. For each array write equivalence class, let $n_1$ be the node such that $A[f(i)]_\mathit{max} \in LHS(n_1)$. Add an edge 
$n_1 \stackrel{-d}{\dasharrow} n_2$ for each $n_2$ such that $A[f'(i)]_0 \in RHS(n_2)$ and $f(i-d) \cong f'(i)$.

\end{enumerate}

As an example of these, return to~\figref{fig:MPCexample}(a). Phase (1) groups the array accesses into equivalence classes:
$\A[i], \B[i], \C[i], \D[i-1], \D[i]$. Treating the above array accesses as scalars, phase (2) transforms the code into the following:

\begin{minted}[fontsize=\footnotesize, linenos, numbersep=5pt, escapeinside=||]{java}
for (int i=1; i<=N; i++) {
  A[i]|$_1$| = f|$_1$|(B[i]|$_0$|);
  B[i]|$_1$| = f|$_2$|(A[i]|$_1$|,D[i-1]|$_0$|);
  C[i]|$_1$| = f|$_3$|(A[i]|$_1$|,D[i-1]|$_0$|);
  D[i]|$_1$| = f|$_4$|(B[i]|$_1$|,C[i]|$_1$|);
}
\end{minted}

There are no MUX-nodes due as there are no conditionals in the loop body. Phase (3) adds the forward edges:
$2 \rightarrow 3$, $2 \rightarrow 3$, $3 \rightarrow 5$, and $4 \rightarrow 5$. Phase (4) adds the backward edges:
$5 \stackrel{-1}{\dasharrow} 3$ and $5 \stackrel{-1}{\dasharrow} 4$. The graph is shown in~\figref{fig:MPCexample}(b).

\ana{Another example, with conditional?}

\ana{Here we need a theorem: program equivalent to transformed one in which every A[f(i)] is replaced with scalar. 
Prove that original def-use graph and one with scalars are the same?} 

\subsection{SCCs and Amortized Schedule}
\label{sec:scc}

The next phase is the actual scheduling algorithm. Recall that backward edges had
the negative weight $-1$ in all our examples, however, the weight on backward edges can be any value from $-1$ 
to $-N+1$. Forward edges have weight 0.

Consider a cycle $c \in G$. $d(c)$ is the absolute value of the sum of the weights of the edges in $c$. Consider a 
node $n \in G$. We say $n$ has \emph{constant rate} if all cycles $c$ through $n$ have the same $d(c)$. We write 
$d(n) = d(c)$. The $d(c)$ means that the computation at node $n$ at iteration $i$ depends on the computation 
at the same node at iteration $i-d(c)$. If $n$ is constant-rate with value $d(n)$, then for every $i$, $n(i)$
depends on the value computed $d(n)$ iterations ago; but if the $d(c)$'s are not the same, then $n(i)$ depends on 
values computed at $n$ at different earlier iterations. We extend the definition of constant-rate to $G$. We say that 
$G$ is constant-rate if all $n \in G$ are constant-rate. If $n$ is a node, such that there are no cycles through $n$ in $G$, 
then $d(n) = N$, or in other words, $n$ can be vectorized. If a node $n$ is not constant rate, we assign a default $d(n) = 1$ 
for the purpose of amortization. For the rest of the text, we are interested in constant-rate $G$'s and consider optimality 
results on constant-rate $G$'s. In practice, nodes have $d(n)$ values of either $N$ or $1$ even though other values of 
$d(n)$ are possible in theory. \ana{HERE HAVE TO GIVE empirical evidence, how good/bad it is.}

%We will consider Strongly Connected Components (SCCs) in $G$. In the running example in~\figref{fig:MPCexample}(b), 
%we have two SCCs, $SCC_1$ consists of node 2, and $SCC_2$ consists of nodes $3,4,5$. 
Without loss of generality, we may assume that each cycle has the form $n_1 \rightarrow n_2 \rightarrow ... \rightarrow n_k \stackrel{-d}{\dasharrow} n_1$, 
or in other words, there is a single backward edge in the entire cycle. Even though cycles with more than $2$ backward 
edges are possible, such cycles can be transformed into $n$ disjoint cycles of the above form. The $-d$ on the
single backward edge in each of the $n$ cycles, is the sum of the $-d$'s of all backward edges in the original cycle. 
\ana{We probably need more here.}

We now compute the amortized schedule $\mathcal{A}$. 

\begin{enumerate}

\item We begin by decomposing $G$ into Strongly Connected Components (SCCs). It is a theorem, that if $G$ is constant-rate, 
then for each $\mathit{SCC}$, and each pair of nodes $n_1, n_2 \in \mathit{SCC}, d(n_1) = d(n_2)$. We write $d(\mathit{SCC})$.
For the running example in~\figref{fig:MPCexample}(b), we have two SCCs, $SCC_1$ consists of node 2, and $SCC_2$ 
consists of nodes $3,4,5$. $d(\mathit{SCC}_1) = N$ and $d(\mathit{SCC}_2) = 1$.

\item For each SCC, assume that there is a schedule $S: P_1 \rightarrow P_2 ... \rightarrow P_k$ given 
as input. $S$ takes into account only the forward edges in $G$: if $n_1, n_2 \in SCC$ and $n_1 \rightarrow n_2 \in G$, 
then $S(n_1)$ precedes $S(n_2)$ in the linear schedule. Note that computing an optimal schedule is NP-complete, 
as we showed earlier, however, given a small SCC, one can brute force an optimal $S$. For the running example in 
~\figref{fig:MPCexample}(b), assuming that nodes 3 and 4 perform the same operation, we work with schedule 
$S: \{3,4\} \rightarrow \{5\}$. Importantly, due to our treatment of arrays we have the same schedule for 
each iteration of the loop, i.e., for each iteration, we either have a dependence edge or we do not have a dependence.

\item Given $S$ for a given SCC, we then compute the amortized schedule $\mathcal{A}_{\mathit{SCC}}$; 
this is the schedule across all iterations of the loop. For each $P_i$ in $S$, there are $\lceil{\frac{N}{d(SCC)}}\rceil$
nodes in $\mathcal{A}_{\mathit{SCC}}$:
\begin{itemize}
\item[] $P_i(1),P_i(2),...P_i(d(SCC))$ go into node $P^1_i$, 
\item[] $P_i(d(SCC)+1),...P_i(2\cdot d(SCC))$ go into node $P^2_i$, etc. 
\end{itemize}
The parenthesized number denotes the iteration, e.g., $P_i(1)$ denotes $P_i$ at the first iteration 
of the loop. 

There are dependence edges as follows:
\begin{enumerate}
\item $P^j_i \rightarrow P^j_{i'}$ if there is an edge $P_i \rightarrow P_{i'}$ in $S$ (intra-loop edges).
\item $P^{\lceil{\frac{N}{d(SCC)}}\rceil}_i \rightarrow P^1_{i+1}$ for each $1 \le i < \lceil{\frac{N}{d(SCC)}}\rceil$ (across-loop edges).
\end{enumerate}
In the running example, $SCC_1$'s schedule is just the single vectorized node that executes all A's at once.
$SCC_2$'s schedule repeats $S: \{3,4\} \rightarrow \{5\}$ $N$ times: we have $\{3,4\}(1) \rightarrow \{5\}(1) \rightarrow \{3,4\}(2) \rightarrow \{5\}(2) ... \{3,4\}(N) \rightarrow \{5\}(N)$, 
as each iteration depends on the previous-iteration value computed at the same node.
This is illustrated graphically in~\figref{fig:MPCexample}(d).


\item Computing an optimal schedule for the loop, even when we assume optimal schedules 
for the SCCs, remains NP-complete. 
One possible schedule can be computed by ordering the strongly connected components 
in a straight line: $SCC_1 \rightarrow SCC_2 \rightarrow ... \rightarrow SCC_m$, such that
if $SCC_i$ precedes $SCC_j$ in the SCC DAG, then $SCC_i$ precedes $SCC_j$ in the
above straight line. The final schedule is $\mathcal{A} = \mathcal{A}_{\mathit{SCC}_1} 
\rightarrow \mathcal{A}_{\mathit{SCC}_2} ... \rightarrow \mathcal{A}_{\mathit{SCC}_m}$.
In our running example, there is only one possible ordering of the two components, and 
the final schedule is as depicted in~\figref{fig:MPCexample}(d).

\end{enumerate}

%We assign a parallelization factor of $N$ to $n$, meaning that 
%$n$ can be fully vectorized. A more interesting case is a non-singleton $SCC$. Then there is at least one cycle 
%from $n$ to itself. We consider \emph{cycles} $c: n \rightsquigarrow n \in SCC$
%such that there is no repeated node in $c$, and sum up the edge weights along the edges in $c$. If all 
%cycles including $n$ have the same value $-d$, then we assign a parallelization factor of $d$ to $n$. That 
%means that $n$ depends on the value computed at $n$ exactly $d$ iterations earlier, and it does not depend 
%on node $n$ of iterations in-between. In contrast, if there are two distinct cycles with two different weights, 
%then we assign the default value of 1 to $n$. Intuitively, two distinct weights on cycles, say $-d_1$ and $-d_2$ 
%means that $n$ depends on the value computed at $n$ $d_1$ iterations ago and on the value computed 
%$d_2$ iterations ago. Taking all nodes in the SCC, if all nodes have the same parallelization factor $d$, 
%then we do nothing, otherwise we assign to all nodes factor -1. \ana{More intuition here, why is this important etc}

\subsection{Theoretical Guarantees on Correctness and Optimality}
\label{sec:results}

Unfortunately, finding an optimal across-loop amortized schedule is NP-complete, just as finding an optimal loop-body schedule is.
Our key premise is that the schedule we compute in~\secref{sec:scc} (1) improves upon the original schedule $\mathcal{S}$, and 
(2) is an optimal across-loop amortized schedule in many cases of real-world loop examples. \ana{Talk about decomposition.} 

The first theorem below establishes correctness, i.e., that $\mathcal{A}$ computes the same result as $\mathcal{S}$ where
$\mathcal{S}$ is the standard sequential schedule of the loop. 

\begin{theorem}(Correctness)
Let $\mathcal{A}$ be the amortized schedule (computed as in~\secref{sec:scc}) and let $\mathcal{S}$ be the standard sequential 
schedule of the loop. $\mathcal{A}$ preserves dependences, i.e., for every def-use chain in $(d,u)$ in $\mathcal{S}$, we have that
$\mathcal{A}(d)$ precedes $\mathcal{A}(u)$ in $\mathcal{A}$.
\end{theorem}

\begin{proof}
The proof is straight-forward by case analysis. Case 1 considers when the variable in the def-use chain is a scalar, and Case 2 considers when 
it is an array location. 
\end{proof}

Correctness of execution of $\mathcal{A}$ is a simple corollary of the theorem. This follows by induction. Assume that all statements that 
execute before a given statement $s$ in $\mathcal{A}$ compute the same result in $\mathcal{A}$ as in $\mathcal{S}$. We will consider 
the execution of $s$ and show that $s$ in $\mathcal{A}$ computes the same result as $s$ in $\mathcal{S}$. This is obvious from the 
theorem: the computation of the operands of $s$ precedes $s$ in $\mathcal{A}$ and by the inductive hypothesis, they compute the
same value as in $\mathcal{S}$; therefore, $s$ computes the same result.

\ana{1. Theorem: Each SCC schedule is optimal}

\ana{2. Theorem: An optimal across-loop schedule (even under assumptions about optimality of individual SCC schedules) is NP-complete.}

\ana{Conditions under which schedule is optimal. Exploit the fact that all SCCs are either d=1 or d=N. Scheduling SCCs in parallel and computing the schedule.
Also, ???}

%\ana{Correctness theorem should come here...}

%\begin{theorem}(Optimality)
%Let $G$ be a constant-rate graph that entails a DAG $D$, where the nodes of $D$ are the strongly connected components of $G$. 
%If $D$ is linear, and each $SCC \in D$ entails a loop-body schedule $S: P_1 \rightarrow P_2 ... P_k$, s.t. (1) $S$ is optimal 
%and (2) for every $P_i, i<k$, for every $n_1 \in P_i, \exists n_2 \in P_{i+1}$, s.t. $n_1 \rightarrow n_2 \in G$, then $\mathcal{A}$ is optimal.
%\end{theorem}

%\begin{proof} (Sketch)
%Each SCC schedule is optimal because 1) dependences are the same across the loop iterations, and 2) there is dependence between 
%iteration $i$ and iteration $i+1$, no node in $i+1$ can be computed before the last node, i.e., $P_k(i)$ has been computed, as all 
%nodes in $i+1$ depend on $P_k(i)$. \ana{Expand here.}
%\end{proof}

One can also use Aiken's result to compute an optimal greedy schedule using $n^2$ iterations, where $n$ is the number of nodes 
in the loop-body schedule. \ana{Add citations.}

\section{Divide and Conquer Parallelization}
\label{sec:divide}

\ana{BIG TODO...}

\section{Nested Loops}
\ana{Wish list :)}

\section{Implementation and Evaluation}
\label{sec:implementation}


\section{Future Work}
\label{sec:implementation_and_benchmarks}
%\input{../sections/implementation_and_benchmarks.tex}
%\input{../sections/evaluation.tex}

\section{Conclusions}
\label{sec:conclusion}
%\input{../sections/conclusion.tex}

%\begin{acks}
%    \ishaq{TODO}
%\end{acks}

\printbibliography

% that's all folks
\end{document}


