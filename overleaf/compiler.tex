

\section{\bf Compiler Front End}
\label{sec:compiler}

%\ana{Convention: use \texttt{shared, plain}, {\sf code}, $i$ and $I$ for counters outside of code.}

%We assume arbitrarily nested loops in the MPC-source IR and read-only arrays. We assume that loops range from 0 to some constant N. Arrays are linearized (row-major order as in MOTION) and accesses are via functions of the induction variables of the enclosing loops.

\begin{figure*}
  \includegraphics[width=0.9\linewidth]{figs_paper_SIMD/compiler_framework.png}
  \caption{Compiler Framework.}
  \label{fig:compiler_framework}
\end{figure*}

\figref{fig:compiler_framework} presents an overview of our compiler.
We start the section with a brief description of the top-level syntax and semantic restrictions in~\secref{sec:syntax}.
We proceed to describe the front end of the compiler:~\secref{sec:imp_to_ssa}
describes translation from IMP Source to SSA, and~\secref{sec:ssa_to_MPC_Source}
describes translation form SSA into MPC Source.

We describe analysis on MPC Source and backend-independent vectorization in~\secref{sec:vectorization}
and translation into MOTION code in~\secref{sec:backend}.
%\ana{Need to state this more precisely.}

\subsection{Syntax and Semantic Restrictions}
\label{sec:syntax}

Source syntax is essentially standard IMP syntax but with for-loops:
%\begin{figure}[t]
{\small
\[
\begin{array}{l@{~~~~~}l}
  \begin{array}{l@{~}l@{~~~}l}
 e & ::= e \; \mathit{op} \; e \mid \x \mid  \texttt{const} \mid \texttt{A[$e$]} & \mathit{expression} \\
 % s &::= t \;\f & \mathit{field} \\
 %\md &::= t\;{\m}(t \;{\this}, \; t\;\x) \; \{\; \ol{t\;\y}\;\s;\;\return\;\y \; \}
 %                 & \mathit{method} \\
  s & ::= s;s \mid  & \mathit{sequence} \\
  & \x = e \mid \texttt{A[$e$]} = e \mid & \mathit{assignment \; stmt} \\
  & \texttt{for $i$ in range($I$)}: s \mid & \mathit{for \; stmt} \\
  & \texttt{if $e$: $s$ else: $s$} & \mathit{if \; stmt} \\
%   t &::= q \; {\sf C} & \mathit{qualified \; type}\\
%   q &::= \high \mid \poly \mid \low & \mathit{FlowCFL \; qualifier}\\
%    t' &::= q' \; \C & \mathit{field \; qualified \; type}\\
%   q' &::= \tainted \mid \poly & \mathit{field \; qualifier}\\

  \end{array}
\end{array}
\]
}
%\end{figure}

The syntax allows for array accesses, arbitrarily nested loops, and if-then-else control flow.
Expressions are typed $\langle q \; \tau\rangle$, where qualifier $q$ and type $\tau$ are:

{\small
\[
\begin{array}{l@{~~~~~}l}
  \begin{array}{l@{~}l@{~~~}l}
 \tau & ::= \texttt{int}  \mid \texttt{bool} \mid \texttt{list[int]} \mid  \texttt{list[bool]} & \mathit{base \; types} \\
  q & ::= \texttt{shared} \mid \texttt{plain} & \mathit{qualifiers} \\
  \end{array}
\end{array}
\]
}

The type system is mostly standard, and in our experience, a sweet spot between readability and expressivity.
The \texttt{shared} qualifier denotes shared values, i.e., ones shared among the parties and computed upon
under secure computation protocols; the \texttt{plain} qualifier denotes plaintext values.
Subtyping is $\texttt{plain} <: \texttt{shared}$, meaning that we can convert a plaintext value into a shared one,
but not vice versa. Subtyping on qualified types is again as expected, it is covariant in the qualifier
and invariant in the type: $\langle q_1 \; \tau_1 \rangle <: \langle q_2 \; \tau_2 \rangle$
iff $q_1 <: q_2$ and  $\tau_1 = \tau_2$.

Our compiler imposes certain semantic restrictions that it enforces throughout the various
phases of compilation. We note that in some cases, the restrictions
can be easily lifted and we plan to do so in future iterations of the work.

\begin{enumerate}
\item Loops are of the form $0 <= i < I$ and bounds are fixed at compile time.
It is a standard restriction in MPC that the bounds must be known at circuit-generation time.
\item Arrays are one-dimensional. $N$-dimensional arrays are linearized and accessed
in row-major order and at this point the programmer is responsible for linearization
and access. (This restriction can be easily lifted.)
\item Array subscrpts are plaintext values as specified by the rule:
\begin{semantics}
    \ntyperule{Array Access}{
%  \Gamma(\y) =  q_\y   \quad\quad \sigma(\f) = q_\f  \quad\quad \Gamma(\x) = q_\x \\
  \Gamma \vdash e : \langle \texttt{plain int} \rangle \quad \Gamma \vdash \texttt{A} : \langle q \; \texttt{list}[\tau] \rangle \quad \tau \in \{ \texttt{int}, \texttt{bool} \}
}{
  \Gamma \vdash \texttt{A[$e$]} : \langle q \; \tau \rangle
}
\end{semantics}
The subscript $e$ is a function of the indices of the enclosing loops.
For read access, the compiler allows an arbitrary such function.
However, it restricts write access to \emph{canonical writes}, i.e., {\sf A[$i,j,k$] = ...}
where $i$, $j$ and $k$ loop over the three dimensions of {\sf A}.
Write access such as for example {\sf A[$i,j+2$] = ...} is not allowed. (This is again a restriction we imposed for convenience in our current implementation; we plan to extend the compiler with arbitrary write access.)
%\item \ana{Add rules for logical ops}
%\item \ana{Add rules for arithmetic ops}
\item The final restriction involves MUX as expressed by the rule:
\begin{semantics}
    \ntyperule{MUX}{
%  \Gamma(\y) =  q_\y   \quad\quad \sigma(\f) = q_\f  \quad\quad \Gamma(\x) = q_\x \\
  \Gamma \vdash e_1 : \langle q_1 \; \texttt{bool} \rangle \quad \Gamma \vdash e_2 : \langle q_2 \; \tau \rangle \quad \Gamma \vdash e_2 : \langle q_2 \; \tau \rangle \quad \tau \in \{ \texttt{int}, \texttt{bool} \}
}{
  \Gamma \vdash \texttt{MUX($e_1$,$e_2$,$e_3$)} : \langle q_1 \vee q_2 \vee q_3  \; \tau \rangle
}
\end{semantics}
\end{enumerate}
The arguments of MUX are restricted to base types. 
(Again, this is just a restriction of our current implementation that will be lifted.)
This causes an inconvenience as we could not write
\begin{pythonn}
if e: A[i] = val
\end{pythonn}
Instead we had to write
\begin{pythonn}
if not(e): val = A[i]
A[i] = val
\end{pythonn}

We note that while the programmer writes
annotations at the level of IMP Source (as in Listing~\ref{tab:source_and_MPC_source_and_optimized_MPC_source}(a)), the
annotations propagate through the transformations; annotations are inferred and checked with a taint analysis at the 
level of MPC Source. Tthe programmer annotates only inputs.

%\ana{Disadvantage of MUX}

For the rest of this section we write $i,j,k$ to denote the loop nest: $i$ is the outermost loop, $j$, is immediately nested in $i$, and so on until $k$
and we use $I,J,K$ to denote the corresponding upper bounds. We write $A[i,j,k]$ to denote canonical access
to an array element. In the program, canonical access is achieved via the standard row-major order formula: $(J*K)*i + K*j + k$.
To simplify the presentation we describe our algorithms in terms of three-element tuples $i,j,k$, however, discussion easily generalizes to
arbitrarily large loop nests.



\subsection{From IMP Source to SSA}
\label{sec:imp_to_ssa}


Our compiler translates from Source to SSA as outlined below. Full details are in the extended version~\cite{Anon_TR}.

%\begin{enumerate}
%  \item
        \paragraph{Parsing:}
        Use Python's \texttt{ast} module to parse the input source code to a Python AST.
%  \item
        \paragraph{Syntax checking:}
        Ensure that the AST matches the restricted subset defined in Section~\secref{sec:syntax}.
        %This step outputs an instance of the \texttt{restricted\_ast.Function} class, which represents our restricted subset of the Python AST.
%  \item
        \paragraph{3-address CFG conversion:}
        %\benjamin{TODO: Is this a good amount of detail?} \ana{This is good amount of detail for the Tech report. In the actual paper we'll shorten a lot and add pointers to the Tech report.}

        Convert the restricted-syntax AST to a three-address control-flow graph. The step processes for-loops, if-statements and assignments as restricted by the syntax.
\begin{comment}
        To do this, first,
        add an empty basic block to the CFG and mark it as current.
        Next, for each statement in the restricted AST's function body,
        process the statement.
        Statements can either be for-loops, if-statements, or assignments (as in~\secref{sec:syntax}).
        Rules for processing each kind of statement are given below:
        \begin{enumerate}
          \item
                \textbf{For-loops}:
                Create new basic blocks for
                the loop condition
                (the \emph{condition-block}),
                the loop body
                (the \emph{body-block}),
                and the code after the loop
                (the \emph{after-block}).
                Insert a jump from the end of the current block to the condition-block.
                Then, mark the condition-block as the current block.
                Insert a for-instruction at the end of the current block with the loop counter variable and bounds from the AST.
                Next, add an edge from the current block to the after-block labeled ``FALSE'' and
                an edge from the current block to the
                body-block labeled ``TRUE''.
                Then, set the body-block to be the current block
                and process all statements in the AST's loop body.
                Finally, insert a jump to the condition-block and set the after-block as current.
          \item
                \textbf{If-statements}:
                Create new basic blocks for
                the ``then'' statements of the if-statement
                (the \emph{then-block}),
                the ``else'' statements of the if-statement
                (the \emph{else-block}),
                and the code after the if-statement
                (the \emph{after-block}).
                At the end of the current block,
                insert a conditional jump to the then-block or else-block
                depending on the if-statement condition in the AST.
                Next,
                mark the then-block as current,
                process all then-statements,
                and add a jump to the after-block.
                Similarly,
                mark the else-block as current,
                process all else-statements,
                and add a jump to the after-block.
                Finally, set the after-block to be the current block,
                and give it a \emph{merge condition} property equal to the condition of the if-statement.
          \item
                \textbf{Assignments}:
                In the restricted-syntax AST,
                the left-hand side of assignments
                can be a variable or an array subscript.
                If it is an array subscript, e.g., {\sf A[i] = x},
                change the statement to {\sf A = Update(A, i, x)}.
                If the statement is not already three-address code,
                for each sub-expression in the right-hand side of the assignment,
                insert an assignment to a temporary variable.
        \end{enumerate}
\end{comment}        
  %\item
        \paragraph{SSA conversion:}
        Convert 3-address CFG to SSA with Cytron's algorithm.
%\end{enumerate}

\subsection{From SSA to MPC Source} %: MUX Nodes and Pseudo $\phi$-nodes}
\label{sec:ssa_to_MPC_Source}

Once the compiler converts the code to SSA,
it transforms $\phi$-nodes that correspond to if-statements into MUX nodes.
From the 3-address CFG conversion step,
$\phi$-nodes corresponding to if-statements will be in a basic block
with the merge condition property.
For example, if {\sf X!3 = $\phi$(X!1,X!2)} is in a block with merge condition {\sf C},
the compiler transforms it into {\sf X!3 = MUX(C, X!1, X!2)}.
Next, the compiler runs the dead code elimination algorithm from Cytron's SSA paper.

Next, the control-flow graph is \emph{linearized} into MPC Source,
which has loops but no if-then-else-statements.
This means that both branches of all if-statements are executed,
and the MUX nodes determine whether to use results from the then-block or from the else-block.
The compiler linearizes the control-flow graph with a variation of breadth-first search.
Blocks with the ``merge condition'' property are only considered
the second time they are visited,
since that will be after both branches of the if-statement are visited.
(The Python AST naturally gives rise to a translation where each conditional has exactly two targets,
and each ``merge condition'' block has exactly two incoming edges, a TRUE and a FALSE edge.
Thus, each $\phi$-node has exactly two multiplexer arguments, which dovetails into MUX.
This is in contrast with Cytron's algorithm which operates at the level of the CFG and allows for
$\phi$-nodes with multiple arguments.)
Each time the compiler visits a block,
it adds the block's statements to the MPC source.
If the block ends in a for-instruction,
the compiler recursively converts the body and code after the loop to MPC source
and adds the for-loop and code after the loop to the main MPC source.
If the block does not end in a for-instruction,
the compiler recursively converts all successor branches to MPC source and
appends these to the main MPC source.

Now, the remaining $\phi$-nodes in MPC source are the loop header nodes. We call these nodes \emph{pseudo} $\phi$-nodes
and we write {\sf PHI} in MPC Source. A pseudo $\phi$-node {\sf X!1 = PHI(X!0,X!2)} in a loop header is evaluated
during circuit generation. If it is the 0-th iteration, then the $\phi$-node evaluates to {\sf X!0}, otherwise, it evaluates to {\sf X!2}.

%\ana{We need to double check that the following captures all cases of def-use edges.}

\begin{comment}
\subsection{From (Optimized) MPC Source to MOTION}
\label{sec:MOTION}

MOTION supports FOR loops and SIMD operations, so translation from MPC source to MOTION C++ code is relatively straightforward.
% Variable naming
\paragraph{Variable declarations:}
Our compiler performs taint analysis on MPC Source based on the type system in~\secref{sec:syntax}. The analysis is described in the following section;
for the most part, it is a standard taint analysis that propagates the declared \texttt{shared} qualifiers throughout the routine.
Taint analysis assigns \texttt{shared} or \texttt{plain} qualifiers to all local variables, which is important for code generation.
Our generated C++ uses the following variable-naming scheme: shared variables are named the same as in the MPC Source with the {\sf !} replaced with an underscore (e.g. {\sf sum!2} would be translated to {\sf sum\_2}). Plaintext variables follow the same naming convention as shared variables but are prefixed with {\sf \_MPC\_PLAINTEXT\_}.  The shared representation of constants are named {\sf \_MPC\_CONSTANT\_} followed by the literal constant (e.g. the shared constant 0 would be named {\sf \_MPC\_CONSTANT\_0}).

% Function preamble
\paragraph{Code generation:}
The generated MOTION code begins with the declaration of all variables used in the function, including loop counters.  If a variable is a vectorized array, it is initialized to a correctly-sized array of empty MOTION shares.  Additionally, each plaintext variable and parameter has a shared counterpart declared.  Next, all constant values which are used as part of shared expressions are initialized as a shared input from party 0.  Finally, plaintext parameters are converted used as shared inputs from party 0 to initialize their shared counterparts. (Importantly, as we mention, they are converted only if they are needed as an argument to a shared operation; one can think of it as an upcast from \texttt{plain} to \texttt{share}.)

% Non-vectorized assignments and returns
Once the function preamble is complete, the MPC Source is translated into C++ one statement at a time. The linear structure of MPC Source enables translation. If there is no vectorization present in a statement, translation to C++ is straightforward: outside of MUX statements and array updates, non-vectorized assignments, expressions, and returns directly translate into their C++ equivalents.  Non-vectorized MUX statements are converted to MOTION's MUX member function on the condition variable.  Array updates are translated into two C++ assignments: one to update the value in the original array and one to assign the new array as shown in Listing~\ref{tab:motion_translation_array_updates}.

\begin{table*}
\begin{tabular}{ccc}
\begin{minipage}{0.33\textwidth}
{\small
\begin{pythonn}
A[i] = val
\end{pythonn}
}
\end{minipage}

&

\begin{minipage}{0.33\textwidth}
{\small
\begin{pythonn}
A!2 = update(A!1, i, val)
\end{pythonn}
}
\end{minipage}

&

\begin{minipage}{0.33\textwidth}
{\small
\begin{cppp}
A_1[i] = val;
A_2 = A_1;
\end{cppp}
}
\end{minipage}

\\

IMP Source & MPC Source & MOTION Code
\end{tabular}
\caption{MOTION Translation: Array Updates}
\label{tab:motion_translation_array_updates}
\end{table*}

% Phi nodes and FOR loops
Pseudo PHI nodes are broken into two components: the ``FALSE'' branch which assigns the initial value of the PHI node and the ``TRUE'' branch which assigns the PHI node's back-edge.  The assignment of the false branch occurs right before the PHI node's enclosing loop.  Inside of the PHI node's enclosing loop, a C++ \texttt{if} statement is inserted to only assign the true branch of the PHI node after the first iteration. MPC FOR loops are converted to C++ FOR loops which iterate the loop counter over the specified range.  Listing~\ref{tab:motion_translation_for_loop} illustrates. The loop counter is initialized before any PHI nodes in the loop as they could rely on it; there is no other special handling of FOR loops. %\ana{Add the reference to the corresponding figure somewhere in this paragraph.}

\begin{table*}
\begin{tabular}{cc}
\begin{minipage}{0.33\textwidth}
{\small
\begin{pythonn}
for i in range(N):
   tmp = PHI(arr[i], val!0)
	 ...
\end{pythonn}
}
\end{minipage}

&

\begin{minipage}{0.66\textwidth}
{\small
\begin{cppp}
_MPC_PLAINTEXT_i = 0;
tmp = arr[_MPC_PLAINTEXT_i];
for (; _MPC_PLAINTEXT_i < _MPC_PLAINTEXT_N; _MPC_PLAINTEXT_i++) {
   if (_MPC_PLAINTEXT_i != 0) {
      tmp = val_0;
	 }
	 ...
}
\end{cppp}
}
\end{minipage}

\\

MPC Source & MOTION Code
\end{tabular}
\caption{MOTION Translation: FOR loop with Phi nodes}
\label{tab:motion_translation_for_loop}
\end{table*}

% SIMD representation
Vectorization is handled with utility functions to manage accessing and updating slices of arrays.  All SIMD values are stored in non-vectorized form as 1-dimensional {\sf std::vector}s in row-major order. %\ana{Does MOTION support just 1-dim SIMD arrays? If yes, mention it here.} \ben{MOTION does only support 1-dim SIMD arrays, but since we use helper functions to create and access SIMD arrays this restriction doesn't apply to our representation. There is no reason why these arrays need to be 1-dimensional other than that it slightly simplifies the code generation and avoids some nasty templates on the utility functions.} \ana{Ok! Leave as is.}
Whenever a SIMD value is used in an expression, the utility function {\sf vectorized\_access()} takes the multi-dimentional representation of a SIMD value, along with the size of each dimension and the requested slice's indices, and converts that slice to a MOTION SIMD value. Because MOTION supports SIMD operations using the same C++ operators as non-SIMD operations, we do not need to perform any other transformations to the expression.
%\ana{Is it correct to say that the operators are overloaded? If yes, use that term?} \ben{I don't think that's the right term since SIMD and scalar MOTION values use the same C++ class, so the operator is the same.} \ana{Ok, leave as is.}
Therefore, the translation of an expression containing SIMD values is identical to that of expressions without SIMD values.

Similarly, the {\sf vectorized\_assign()} function assigns a (potentially SIMD) value to a slice of a vectorized array.  This operation cannot be done with a simple subscript as SIMD assignments will update a range of values in the non-vectorized representation.
%\ben{Is the next sentence needed?  They can always check the implementation of vectorized\_assign() if they want to see specifics.}
%The function takes the array being assigned to as a reference to update it in place so that any existing values are not lost.  SIMD values are never directly assigned to non-SIMD values. \ana{Yes, this is implementation-specific, you can remove.}

\begin{table*}
\begin{tabular}{cc}
\begin{minipage}{0.33\textwidth}
{\small
\begin{pythonn}
sum!4[I] = ADD_SIMD(sum!3[I], p[I, j])
\end{pythonn}
}
\end{minipage}

&

\begin{minipage}{0.66\textwidth}
{\small
% Ben: This line is too long but I don't know how to break it well
\begin{cppp}
vectorized_assign(sum_4, {_MPC_PLAINTEXT_N}, {true}, {},
      vectorized_access(sum_3, {_MPC_PLAINTEXT_N}, {true}, {}) +
      vectorized_access(p, {_MPC_PLAINTEXT_N, _MPC_PLAINTEXT_D}, {true, false},
           {_MPC_PLAINTEXT_j}));
\end{cppp}
}
\end{minipage}

\\

MPC Source & MOTION Code
\end{tabular}
\caption{MOTION Translation: Assignment to SIMD value}
\label{tab:motion_translation_simd_assignment}
\end{table*}

% vectorized_update()
%\ben{Technically this is semantically the same as non-vectorized update but we use a utility function to combine the steps into a single C++ statement - should it still be included?}
%\ana{I would leave this in the TR but it will go from the paper. Lots of stuff in Secs. 4 and 5 will go from the paper.} \ana{Leaving in TR, will shorten in paper.}
Updating SIMD arrays is also implemented differently from updating non-vectorized arrays.  Instead of separating the array update from the assignment of the new array, these steps are combined with the {\sf vectorized\_update()} utility function.  This function operates identically to {\sf vectorized\_assign()}, however it additionally returns the array after the assignment occurs.  This value is then used for the assignment to the new variable. Listing~\ref{tab:motion_translation_simd_assignment} illustrates {\sf vectorized\_assign()} and {\sf vectorized\_update()} on the Biometric example.

% raise_dim() implementation

\ben{The compiler and C++ internally uses ``lift'' as the terminology for raise\_dim(), but the paper does not :(...} \ana{True. To make matters worse, most of the explanation on this comes in the next section. But I'll leave as is for now but leave the comments too because it needs work.}
\paragraph{Reshaping and raising dimensions:}
Raising the dimensions of a scalar or array uses the {\sf lift()} utility function which takes a lambda for the raised expression and the dimensions of the output.  This function evaluates the expression for each permutation of indices along the dimensions and returns the resulting array in row-major order.  The lambda accepts an array of integers representing the index along each of the dimensions being raised, and the translation of the expression which is being raised replaces each of the dimension index variables with the relevant subscript of this array.  There is also a special case of the {\sf lift()} function which occurs when we are raising an array.  In this case, instead of concatenating the array for each index, we extend the array along all dimensions being raised which are not present in the array already.  For example, when raising an array with dimensions $N \times M$ to an array with dimensions $N \times M \times D$, the input array will simply be extended along the $D$ dimension: {\sf A'[n,m,d] = A[n,m]} for every $d$.  If the input array is already correctly sized it will be returned as-is.
%This case only occurs when the dimensionality of the array is equal to the first dimensions of the array (any dimension which is being lifted to which is not in the array is after every dimension in the array) \ben{I don't know how to phrase the previous sentence more concisely}.  In this case, the array is simply extended along the new dimensions (if the array is already correctly sized it is returned as is).
%\ana{Add the ref. to the figure. Also, try to rewrite. I understand what the paragraph is saying but it is too technical and does not convey the higher-level goal of these. Try first to state what the goal is, and then talk about the details such as the lambda funcs.} \ben{Rewrote the above paragraph to be less confusing/implementation-specific, please review.} \ana{Better, removing comment.}

% Ben (note as comment since tables aren't fixed placement): I only include the translation of the expression itself (instead of an assignment) since the assignment includes the extra junk from a vectorized_assign.  Also none of the raise_dims in biometric use the dimension index which I think is the most interesting/important part of the lift expression translation so I made up a toy example.
\begin{table*}
\begin{tabular}{cc}
\begin{minipage}{0.33\textwidth}
{\small
\begin{pythonn}
raise_dim(i + j, (i:N, j:M))
\end{pythonn}
}
\end{minipage}

&

\begin{minipage}{0.66\textwidth}
{\small
\begin{cppp}
lift(std::function([&](const std::vector<std::uint32_t > &idxs) {return idxs[0] + idxs[1];}),
      {_MPC_PLAINTEXT_N, _MPX_PLAINTEXT_M})
\end{cppp}
}
\end{minipage}

\\

MPC Source & MOTION Code
\end{tabular}
\caption{MOTION Translation: Raising dimensions}
\label{tab:motion_translation_raise_dim}
\end{table*}

% drop_dim() implementation
\paragraph{Dropping dimensions:}
Dropping dimensions use the {\sf drop\_dim()} and {\sf drop\_dim\_monoreturn()} utility functions.  They function identically but the latter returns a scalar for the case when the final dimension of an array is dropped.  These functions take the non-vectorized representation of an array, along with the dimensions of that array, and return the array with the final dimension dropped.

% Shared/plaintext conversions
\ben{Ishaq or Vassilis: please check over this paragraph... I don't want to make some mistake about MOTION's capabilities.}
Currently, our compiler only supports the \texttt{Bmr} and \texttt{BooleanGMW} protocols as MOTION does not implement all operations for other protocols.  MOTION does not support publicly-known constants for these protocols, so all conversions from plaintext values to shares are performed by providing the plaintext value as a shared input from party 0.  Due to this limitation, our translation to MOTION code attempts to minimize the number of conversions from a plaintext value. This is accomplished by creating a shared copy of each plaintext variable and updating that copy in lock-step with the plaintext variable.  Since variables are often initialized to a common constant value (e.g. 0), this approach decreases the number of input gates by only creating a shared input for each initialization constant.  Loop counters must still be converted to a shared value on each iteration that they are used, however we only generate this conversion when necessary, i.e., when the counter flows to a shared computation. This is to prevent unnecessary increase in the number of input gates.

% Tons of copies != runtime costs
Due to the SSA translation phase as well as the conversions to and from SIMD values which our utility functions perform, our generated vectorized MOTION code often includes multiple copies of arrays and scalar values.  These copies do not incur a runtime cost as the arrays simply hold \emph{pointers} to the underlying shares, so no new shares or gates are created as a result of this copying. Cost in MPC programs is dominated by shares and computation on shares. %\ben{Is there anything else to say here?  Should this be placed somewhere else?} \ana{It is clear to me! Will stay in the TR but likely will be cut from the paper.}
\end{comment}
