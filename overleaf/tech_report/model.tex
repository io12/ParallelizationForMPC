\section{Analytical Model}
\label{sec:model}

%\ana{We need an intro to section here.}
%\ana{Terminology: "operation" or "instruction" or "gate"?}

This section presents a model to reason about the cost of execution of MPC programs, including accounting for amortization.
We define the assumptions and setting in~\secref{sec:mpc}. We proceed to define the scheduling problem in~\secref{sec:problem}, 
which we expected to be able to solve optimally. \secref{sec:np} shows that the problem is NP-hard via a reduction to the 
Shortest Common Supersequence (SCS) problem. Despite the negative general result, we expect the formulation in terms of SCS to 
be useful as sequences are short and few in practice.



\subsection{Scheduling in MPC}
\label{sec:mpc}

%\ana{Here we need more on MPC before jumping to scheduling. MPC-source, basic assumptions about static loop bounds, etc.}

For this treatment we make the following simplifying assumptions:

\begin{enumerate}
\item All statements in the program execute using the same protocol (sharing). That is, there is no share conversion.
%\ishaq{This is not an assumption, this is our setting. We work in the single protocol world.}
\item There are two tiers of MPC instructions, local and remote. A local instruction (e.g., ADD in Arithmetic, XOR in Boolean) 
has cost $\beta$ and a remote instruction (e.g., MUX, MUL, SHL, etc.) has cost $\alpha$, where $\alpha >> \beta$. We assume that all remote
instructions have the same cost.
%\ishaq{Don't we need to distinguish between local (cheap) vs. interactive (expensive) instructions? I don't see how we could assume this. -- Past suggestion from Vassilis: Ideally we should assume cost to be a convex function.}\ana{After discussion 1/12: replace single costs 1 with two levels of costs: $\alpha$ for non-local operations, e.g., MUL, and $\beta$ for local ops, e.g., ADD.}
\item  In MPC frameworks, executing $n$ operations ``at once'' in a single SIMD operation costs a lot less than executing those $n$ operations one by one.
Following Amdahl's law, we write $\alpha = \frac{1}{s}p\alpha + (1-p)\alpha$, where $p$ is the fraction of execution time that benefits from amortization and $(1-p)$
is the fraction that does not, and $s$ is the available resource. Thus, $n\alpha = \frac{n}{s}p\alpha + n(1-p)\alpha$.
For the purpose of the model we assume that $s$ is large enough and the term $\frac{n}{s}p\alpha$ amounts to a \emph{fixed cost} incurred regardless of
whether $n$ is $10,000$ or just $1$. (This models the cost of preparing and sending a packet from party A to party B for example.) Therefore, amortized execution
of $n$ operations is $f(n) = \alpha_\mathit{fix} + n\alpha_{var}$ in contrast to unamortized execution $g(n) = n\alpha_\mathit{fix} + n\alpha_{var}$.
We have $\alpha_\mathit{fix} << n\alpha_\mathit{fix}$ and since fixed cost dominates variable cost (particularly for remote operations), we have $f(n) << g(n)$.
%We assume infinite parallel capacity---i.e., a single MPC-instruction costs as much as $N$ amortized instructions, namely $\alpha$ or $\beta$.
%This is a standard assumption in Cryptographic Parallel RAM. ABY presents empirical support for this assumption~\ana{Add citations. PRAM, ABY.}
%\ishaq{Comment from Vassilis: We assume there are infinite parallel capacities, this is the standard assumption in PRAM (Cryptographic Parallel RAM).}\ana{PRAM assumption stays. We have to replace the unit cost of 1 with a suitable amortization function $f(n)$, which I don't think changes much in the cost modeling and analysis.}
\item MPC instructions scheduled in parallel benefit from amortization \emph{only if} they are the same instruction. Given our previous assumption,
2 MUL instructions can be amortized in a single SIMD instruction that costs $\alpha_\mathit{fix} + 2\alpha_\mathit{var}$, however a MUL and a MUX instruction
still cost $2\alpha_\mathit{fix} + 2\alpha_\mathit{var}$ even when scheduled ``in parallel''.\footnote{This is not strictly true, but assuming it, e.g. as in 
\cite{Ishaq:2019, Demmler:2015, Mohassel:2018}, helps simplify the problem.}
%MPC instructions scheduled in parallel benefit from amortization \emph{only if} they are the same instruction. Given our previous assumption,
%2 MUL instructions scheduled in parallel benefit from amortization and cost $\alpha$, however a MUL and a MUX instructions scheduled
%in parallel still cost $2\alpha$.
%\ishaq{We need to reword this assumption to something like "$K$ parallel MUL costs much less than $K$ (because they get amortized), but any mix of $K$  MUL and MUX still cost roughly $K$. Specifically, we should take away the low constants (2 and 1) because we know for low constants this is not true.} \ana{Again, core assumption that MUL and MUX don't benefit from amortization stays. We have to replace constant costs with functions, as in (3).}
\end{enumerate}

\input{prob_stmt_np_hardness.tex}
