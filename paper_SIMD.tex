% !TeX TXS-program:compile = txs:///pdflatex/[--shell-escape]
%
% acm templates v1.57 (sigconf template)
%
%\documentclass[sigconf, screen, review, anonymous, natbib=false]{acmart}
\documentclass[sigconf, screen, natbib=false, dvipsnames, table]{acmart}
\settopmatter{printacmref=true}
% mandatory for CCS'19
\usepackage{balance}
\usepackage{mathtools}
% for creating a balanced last page (usually last page with references)

% defining the \BibTeX command - from Oren Patashnik's original BibTeX documentation.
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08emT\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

% Rights management information.
% This information is sent to you when you complete the rights form.
% These commands have SAMPLE values in them; it is your responsibility as an author to replace
% the commands and values with those provided to you when you complete the rights form.
%
% These commands are for a PROCEEDINGS abstract or paper.

\copyrightyear{2019}
\acmYear{2019}
\setcopyright{acmcopyright}
\acmConference[CCS '19]{2019 ACM SIGSAC Conference on Computer and Communications Security}{November 11--15, 2019}{London, United Kingdom}
\acmBooktitle{2019 ACM SIGSAC Conference on Computer and Communications Security (CCS '19), November 11--15, 2019, London, United Kingdom}
\acmPrice{15.00}
\acmDOI{10.1145/3319535.3339818}
\acmISBN{978-1-4503-6747-9/19/11}

%
% These commands are for a JOURNAL article.
%\setcopyright{acmcopyright}
%\acmJournal{TOG}
%\acmYear{2018}\acmVolume{37}\acmNumber{4}\acmArticle{111}\acmMonth{8}
%\acmDOI{10.1145/1122445.1122456}

%
% Submission ID.
% Use this when submitting an article to a sponsored event. You'll receive a unique submission ID from the organizers
% of the event, and this ID should be used as the parameter to this command.
%\acmSubmissionID{123-A56-BU3}

%
% The majority of ACM publications use numbered citations and references. If you are preparing content for an event
% sponsored by ACM SIGGRAPH, you must use the "author year" style of citations and references. Uncommenting
% the next command will enable that style.
%\citestyle{acmauthoryear}


 \makeatletter
 % \renewcommand{\section}{\abovedisplayskip 10\p@ \@plus3\p@ \@minus1\p@%
 %                       \belowdisplayskip 5\p@ \@plus3\p@ \@minus1\p@%
 %                       \abovedisplayshortskip 0pt \@plus2\p@%
 %                       \belowdisplayshortskip 0pt \@plus2\p@ \@minus0\p@%
 %                       \@startsection{section}{1}{\z@}%
 %                        {-17\p@ \@plus -4\p@ \@minus -4\p@}%
 %                        {6\p@ \@plus 4\p@ \@minus 4\p@}%
 %                        {\normalfont\large\bfseries\boldmath
 %                         \rightskip=\z@ \@plus 8em\pretolerance=10000 }}
 \renewcommand{\subsection}{\@startsection{subsection}{2}{\z@}%
                        {-8\p@ \@plus -4\p@ \@minus -4\p@}%
                        {5\p@ \@plus 2\p@ \@minus 2\p@}%
                        {\normalfont\Large\bfseries\boldmath
                         \rightskip=\z@ \@plus 3em\pretolerance=10000 }}
  \renewcommand{\subsubsection}{\@startsection{subsubsection}{3}{\z@}%
                        {-6\p@ \@plus -4\p@ \@minus -4\p@}%
                        {1\p@ \@plus 1\p@ \@minus 0\p@}%
                        {\normalfont\normalsize\bfseries\boldmath}}
% \renewcommand{\paragraph}{\@startsection{paragraph}{4}{\z@}%
%                       {-8\p@ \@plus -4\p@ \@minus -4\p@}%
%                       {-2\p@ \@plus -0.22em \@minus -0.1em}%
%                       {\normalfont\normalsize\bfseries}}
 \makeatother



% *** GRAPHICS RELATED PACKAGES ***
\usepackage{graphicx}
\usepackage{comment}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{listings}
% declare the path(s) where your graphic files are
\graphicspath{{../figures/}}
% and their extensions so you won't have to specify these with
% every instance of \includegraphics
\DeclareGraphicsExtensions{.pdf,.jpeg,.png}

%\usepackage[outputdir=/Volumes/ramdisk/]{minted}
\usepackage{minted}
% *** MATH PACKAGES ***
\usepackage{amsmath}



% *** SPECIALIZED LIST PACKAGES ***
%\usepackage{algorithm2e}
\usepackage{algorithmic}



% *** ALIGNMENT PACKAGES ***
\usepackage{array}

\usepackage{url}

\usepackage[utf8]{inputenc}
\usepackage[american]{babel}
\usepackage[backend=biber,style=ACM-Reference-Format]{biblatex}
\addbibresource{../library.bib}
\addbibresource{../cryptobib/abbrev2.bib}
\addbibresource{../cryptobib/crypto_crossref.bib}

% Used for Theorems and Definitions
\usepackage{amsthm}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\theoremstyle{definition}
\newtheorem{remark}{Remark}
\newtheorem{assumption}{Assumption}

\usepackage{xcolor}
\usepackage{xspace}
\usepackage{xstring} % required by IfEqCase

\usepackage{booktabs} % better tables
\usepackage{algorithm}
\usepackage{algorithmic}


% ishaq: adding our macros
\input{macros.tex}

\sloppy
\begin{document}
\fancyhead{}
% do not delete this code.

%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title[Scheduling and Amortization for MPC]{Scheduling and Amortization for MPC}

%
% The "author" command and its associated commands are used to define the authors and their affiliations.
% Of note is the shared affiliation of the first two authors, and the "authornote" and "authornotemark" commands
% used to denote shared contribution to the research.

\author{Benjamin Levy}
\email{levyb3@rpi.edu}
\affiliation{%
    \institution{Rensselaer Polytechnic Institute}
    %\streetaddress{1 Th{\o}rv{\"a}ld Circle}
    \city{Troy}
    \state{New York}
    %\country{Iceland}
}

\author{Benjamin Sherman}
\email{shermb@rpi.edu}
\affiliation{%
    \institution{Rensselaer Polytechnic Institute}
    %\streetaddress{1 Th{\o}rv{\"a}ld Circle}
    \city{Troy}
    \state{New York}
    %\country{Iceland}
}


\author{Lindsey Kennard}
\email{kennal@rpi.edu}
\affiliation{%
    \institution{Rensselaer Polytechnic Institute}
    %\streetaddress{1 Th{\o}rv{\"a}ld Circle}
    \city{Troy}
    \state{New York}
    %\country{Iceland}
}

\author{Ana L. Milanova}
\email{milanova@cs.rpi.edu}
\affiliation{%
    \institution{Rensselaer Polytechnic Institute}
    %\streetaddress{1 Th{\o}rv{\"a}ld Circle}
    \city{Troy}
    \state{New York}
    %\country{Iceland}
}

\author{Muhammad Ishaq}
\authornote{This work was done in part while the author was at RPI.}
\email{m.ishaq@ed.ac.uk}
%\orcid{1234-5678-9012}
%\author{G.K.M. Tobin}
%\authornotemark[1]
%\email{webmaster@marysville-ohio.com}
\affiliation{%
    \institution{University of Edinburgh}
    %\streetaddress{P.O. Box 1212}
    \city{Edinburgh}
    \state{Scotland}
%    \postcode{43017-6221}
}

\author{Vassilis Zikas}
\authornote{This work was done in part while the author was visiting UCLA and supported in part by DARPA and SPAWAR under contract N66001-15-C-4065 and by a SICSA Cyber Nexus Research Exchanges grant.}
\email{vzikas@inf.ed.ac.uk}
%\orcid{1234-5678-9012}
%\author{G.K.M. Tobin}
%\authornotemark[1]
%\email{webmaster@marysville-ohio.com}
\affiliation{%
    \institution{University of Edinburgh}
    %\streetaddress{P.O. Box 1212}
    \city{Edinburgh}
    \state{Scotland}
    %    \postcode{43017-6221}
}


%
% By default, the full list of authors will be used in the page headers. Often, this list is too long, and will overlap
% other information printed in the page headers. This command allows the author to define a more concise list
% of authors' names for this purpose.
%\renewcommand{\shortauthors}{Trovato and Tobin, et al.}

\renewcommand{\A}{{\sf A}}
\renewcommand{\B}{{\sf B}}
\renewcommand{\C}{{\sf C}}
\renewcommand{\D}{{\sf D}}


% As a general rule, do not put math, special symbols or citations
% in the abstract
\begin{abstract}


\end{abstract}


%
% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
% Please copy and paste the code instead of the example below.
%
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10003752.10010124.10010138.10010143</concept_id>
<concept_desc>Theory of computation~Program analysis</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003752.10003777.10003789</concept_id>
<concept_desc>Theory of computation~Cryptographic protocols</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10002978.10002979</concept_id>
<concept_desc>Security and privacy~Cryptography</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Theory of computation~Program analysis}
\ccsdesc[500]{Theory of computation~Cryptographic protocols}
\ccsdesc[300]{Security and privacy~Cryptography}

%
% Keywords. The author(s) should pick words that accurately describe the work being
% presented. Separate the keywords with commas.
\keywords{protocol mixing; linear programming; multiparty computation; program analysis; cryptography}


\begin{comment}
%
% A "teaser" image appears between the author and affiliation information and the body
% of the document, and typically spans the page.
\begin{teaserfigure}
    \includegraphics[width=\textwidth]{sampleteaser}
    \caption{Seattle Mariners at Spring Training, 2010.}
    \Description{Enjoying the baseball game from the third-base seats. Ichiro Suzuki preparing to bat.}
    \label{fig:teaser}
\end{teaserfigure}
\end{comment}
%
% This command processes the author and affiliation and title information and builds
% the first part of the formatted document.
\maketitle


\section{Introduction}
\label{sec:introduction}


\section{Background and Problem Statement}
\label{sec:background}

\subsection{Scheduling in MPC}

\ana{Here we need more on MPC before jumping to scheduling. MPC-source, basic assumptions about static loop bounds, etc.}

For this treatment we make the following simplifying assumptions:

\begin{enumerate}
\item All statements in the program execute using the same protocol (sharing). That is, there is no share conversion. \ishaq{This is not an assumption, this is our setting. We work in the single protocol world.}
\item All MPC instructions have the same unit cost, 1 unit. \ishaq{Don't we need to distinguish between local (cheap) vs. interactive (expensive) instructions? I don't see how we could assume this. -- Past suggestion from Vassilis: Ideally we should assume cost to be a convex function.}\ana{After discussion 1/12: replace single costs 1 with two levels of costs: $\alpha$ for non-local operations, e.g., MUL, and $\beta$ for local ops, e.g., ADD.}
\item There is unlimited bandwidth---i.e., a single MPC-instruction costs as much as $N$ amortized instructions, namely 1 unit.\ishaq{Comment from Vassilis: We assume there are infinite parallel capacities, this is the standard assumption in PRAM (Cryptographic Parallel RAM).}\ana{PRAM assumption stays. We have to replace the unit cost of 1 with a suitable amortization function $f(n)$, which I don't think changes much in the cost modeling and analysis.}
\item MPC instructions scheduled in parallel benefit from amortization \emph{only if} they are the same instruction. Given our previous assumption,
2 MUL instructions scheduled in parallel benefit from amortization and cost 1, however a MUL and a MUX instructions scheduled
in parallel still cost 2. \ishaq{We need to reword this assumption to something like "$K$ parallel MUL costs much less than $K$ (because they get amortized), but any mix of $K$  MUL and MUX still cost roughly $K$. Specifically, we should take away the low constants (2 and 1) because we know for low constants this is not true.} \ana{Again, core assumption that MUL and MUX don't benefit from amortization stays. We have to replace constant costs with functions, as in (3).}
\end{enumerate}


\subsection{Scheduling in HPC}
\label{sec:hpc}



\section{\bf Preliminaries}
\label{sec:preliminaries}

We assume arbitrarily nested loops in the MPC-source IR and read-only arrays. We assume that loops range from 0 to some constant N. Arrays are linearized (row-major order as in MOTION) and accesses are via functions of the induction variables of the enclosing loops. We write $i_1,i_2,...i_k$ to denote the loop nest: $i_1$ is the outermost loop, $i_2$, is immediately nested in $i_1$, and so on until $i_k$. As an example, a statement nested in $i_1,i_2,...i_k$ can access array $A[f(i_1,i_2,...i_k)]$. We write $A[i_1,i_2,...i_k]$ interchangeably. \ana{Need to state this more precisely.}

\subsection{Pseudo $\phi$-nodes}

A pseudo $\phi$-node $X_1 = \phi(X_0,X_2)$ in a loop header is evaluated during circuit generation. If it is the 0-th iteration, then the $\phi$-node evaluates to $X_0$, otherwise, it evaluates to $X_2$.

%\ana{We need to double check that the following captures all cases of def-use edges.}

\subsection{Def-use Edges}

The dependence graph has the following def-use edges:

\begin{itemize}
\item same-level forward $X\rightarrow Y$ where $X$ and $Y$ are in the same loop nest $i_1,i_2,...i_k$. E.g., $\texttt{d} = \mathit{SUM}(\texttt{S}[i,j], \texttt{C}[j])$ to $\texttt{p} = \mathit{MUL}(\texttt{d},\texttt{d})$ in Biometric is a same-level edge. A $\phi$ node can be a source of a same-level forward edge but not a target.
\item outer-to-inner forward $X\rightarrow Y$ where $X$ is in an outer loop nest, $i_1,i_2,...i_j$, and $Y$ is in an inner one, $i_1,i_2,...i_j,...,i_k$. A $\phi$-node can be a source or a target of an outer-to-inner forward edge.
\item inner-to-outer forward $X\rightarrow Y$ where $X$ is a $phi$-node in an inner loop nest, $i_1,i_2,...i_k,i_{k+1}$, and $Y$ is in the enclosing loop nest $i_1,i_2,...i_k$. E.g. $\texttt{sum}_0 = \phi(\texttt{sum}_1, 0)$ to $\texttt{c} = \mathit{CMP}(\texttt{sum}_0,\texttt{min}_0)$ is an inner-to-outer forward edge. Note that the source is \emph{always} a $\phi$-node in the immediately enclosing loop. The interpretation of this edge is that the use node $Y$ uses the definition made in the last iteration of the inner loop.
\ben{The current representation of pseudo $\phi$-nodes shows them attached to the loop header (i.e. in the loop).  We may want to clarify that they are also evaluated at the loop's termination.}
\item same-level back-edge $X\rightarrow Y$. $Y$ is a phi-node in the header of the loop and $X$ is a definition of the variable in the loop body. E.g., $\texttt{min}_1 = \mathit{MUX}(\texttt{c},\texttt{sum}_1,\texttt{min}_1)$ to $\texttt{min}_0 = \phi(\texttt{min}_1, 10000)$ in Biometric is a same-level back-edge.
\item inner-to-outer back-edge $X\rightarrow Y$: $X$ and $Y$ are both $\phi$-nodes for some variable. The source $X$ is in a loop nested into $Y$'s loop (not necessarily immediately).

\item mixed forward edge $X\rightarrow Y$. $X$ is a $phi$-node in some loop $i_1,i_2,...i_k,i_{k+1}$ and $Y$ is a node in a loop nested into $i_1,i_2,...i_k$. We transform mixed forward edges as follows. Let $\x_j$ be the variable defined at the phi-node $X$. We add a variable and assignment $\x'_j = \x_j$ immediately after the $i_1,i_2,...i_k$ loop. Then we replace the use of $\x_j$ at $Y$ with $\x'_j$. This transforms a mixed forward edge into an "inner-to-outer" forward edge followed by an outer-to-inner forward edge. Thus Basic Vectorization handles one of "same-level", "inner-to-outer", or "outer-to-inner" def-use edges.
 \end{itemize}

\subsection{Helper Functions}

We define $\mathit{closure}(n)$ where $n$ is a phi-node. Intuitively, it computes the set of nodes (i.e., statements) that form a dependence cycle with $n$. \ana{Cycle(n) is probably a better name.} The closure of $n$ is defined as follows:
\begin{itemize}
\item $n$ is in $\mathit{closure}(n)$
\item $X$ is in $\mathit{closure}(n)$ if there is a same-level path from $n$ to $X$, and $X \rightarrow n$ is a same-level back-edge.
\item $Y$ is in $\mathit{closure}(n)$ if there is a same-level path from $n$ to $Y$ and there is a same-level path from $Y$ to some $X$ in $\mathit{closure}(n)$.
\end{itemize}

We define the $\mathit{raise\_dim}$ (raise dimensions) and $\mathit{drop\_dim}$ (drop dimension) functions. Raise dimension "lifts" a lower-dimension array (\ana{The right term here is tensor, I am pretty sure!}) into a higher dimension one. This is necessary when a lower-dimensional array is used in a higher dimensional loop and, essentially, is just copying of values. For example, Biometric contains the statement $d = \mathit{SUB}(S[i, j], C[j])$, in the $j$-loop which is nested into the $i$-loop. Here $C$ is a one-dimensional array, however, to vectorize across both loops it is necessary to turn it into a two-dimensional array: $C[i,j]$ becomes $[C[0],C[1],...C[J],C[0],C[1],...C[J], ... C[0],C[1],...C[J]]$, which turns the row into a matrix of $I$ identical rows. (We use capital letters to denote the upper bounds of loops, e.g., $J$ is the upper bound of the $j$-loop and $I$ is the upper bound of the $i$-loop.)

$\mathit{raise\_dim}(A[i_1,...,i_k],i_j)$ is defined as follows.  It results in a new {k+1}-dimensional array $A'$ where for every $0 \le i_{k} < I_{k+1}$, $A'[i_1, \ldots, i_j, \ldots, i_k] = A[i_1, \ldots, i_k]$. Adding $n$ dimensions is trivially extended as a composition of $n$ $\mathit{raise\_dim}$ that each adds a single dimension.

As expected, drop dimension turns a higher-dimensional array into a lower-dimensional one. The key use case is an inner-to-outer def-use edge. The code may define a variable, e.g., $\x$ in an inner loop, say $j$, then use this variable in an enclosing loop, say $i$. Our algorithm may vectorize the computation of $\x$ in the $j$-loop thus producing a vector $\x[j]$ where $\x[1]$ is the value of \x after the 1st iteration and so on. Drop dimension states that the outer loop will use the value of the variable at the last iteration.

$\mathit{drop\_dim}(A[i_1,\ldots, i_j, \ldots,i_k], i_j)$ produces a k-dimensional array $A'$ where $A'[i_1,\ldots,i_k] = A'[i_1,\ldots, I_j-1, \ldots,i_k]$. In our analysis, dimensions are always dropped at the end, and again, one can define dropping $n$ dimensions as a composition of $n$ $\mathit{drop\_dim}$.

\ben{I'm not sure if I wrote up the above paragraphs correctly -- the idea is that we're just copying values to extend over dimension $j$ or only retain its last elements.  The current writeup implies that $1 < j < k$ though, which isn't always true.  Python implementations of $\mathit{raise\_dim}()$ and $\mathit{drop\_dim}()$ can be found here: \url{https://github.com/milana2/ParallelizationForMPC/blob/master/compiler/compiler/motion_backend/reference_implementations.py}}

\ana{This section is still informal. Needs work to make more precise.}

\section{Vectorization}

\ana{Add back-edges into Phase 1. A back-edge from a non-phi-node in loop $i$ to a phi-node in loop $i$'s header is a same-level edge. The only difference with the handling of normal same-level forward def-use is that the operand index will become $i-1$. A back edge from a phi-node in loop $j$ to a phi-node in loop $i$, where $j$ is nested in $i$ is an inner-to-outer edge and will require dropping dimension. We can show these are the only kinds of back-edges that may occur.}

%\subsection{Algorithm (Still work in progress.)}

\subsection{Basic Vectorization}

\begin{algorithmic}

\STATE \COMMENT {Phase 1: Raise dimension of scalar variables to corresponding loop nest. We may assume linear traversal of the MPC-source.}

\FOR {each MPC $\mathit{stmt}: X = \mathit{Op}(Y_1,Y_2)$ in loop $i_1,...,i_k$}
\FOR {each $Y_i$}
\STATE {case def-use edge $\mathit{stmt}' (\mbox{def of } Y_i) \rightarrow \mathit{stmt} (\mbox{def of } X)$ of} \\
\STATE \hspace{0.25cm} {same-level $\rightarrow$ add $Y'_i = Y_i$} \\
\STATE \hspace{0.25cm} {outer-to-inner $\rightarrow$ add $Y'_i[i_1,...,i_k] = \mathit{raise\_dim}(Y_i)$}
\STATE \hspace{0.25cm} {inner-to-outer $\rightarrow$ add $Y'_i[i_1,...,i_k] = \mathit{drop\_dim}(Y_i)$}
\ENDFOR

\COMMENT {Optimistically vectorize all. $\stackrel{\rightarrow}{i}$ means vectorized dimension.}
\STATE {change to $X[\stackrel{\rightarrow}{i_1},...\stackrel{\rightarrow}{i_k}] = \mathit{Op}(Y'_1[\stackrel{\rightarrow}{i_1},...,\stackrel{\rightarrow}{i_k}],Y'_2[\stackrel{\rightarrow}{i_1},...,\stackrel{\rightarrow}{i_k}])$ }
\ENDFOR

\COMMENT {Phase 2: Recreating FOR loops for cycles; vectorizable statements hoisted up.}

\FOR {each dimension $d$ from highest to 0}
\FOR {each $\phi$-node $n$ in loop $i_1,...,i_d$}
\STATE {compute $\mathit{closure}(n)$}
\ENDFOR

\COMMENT {{\color{red} $cl_1$ and $cl_2$ intersect if they have common statement, or update same array; "intersect" definition can be expanded}}

\WHILE {there are closure $cl_1$ and $cl_2$ that intersect}
\STATE {merge $cl_1$ and $cl_2$}
\ENDWHILE
\FOR {each closure $cl$ (after merge)}
\STATE {create FOR $i_d = 0; ...$ loop}
\STATE {add $\phi$-nodes in $cl$ to header block}
\STATE {{\color{red}{add target-less $\phi$-node for A if $cl$ updates array A}}}
\STATE {add statements in $cl$ to loop body in some order of dependences}
\STATE \COMMENT {Dimension is not vectorizable: }
\STATE {change $\stackrel{\rightarrow}{i_d}$ to $i_d$ in all statements in loop}
\STATE {treat FOR loop as monolith node: change def-use edges accordingly. Some edges become same-level.}
\ENDFOR
{
\color{red}
\FOR {each target-less $\phi$-node $A_1 = \phi(A_0,A_k)$}
\STATE {in vectorizable stmts, replace use of $A_1$ with $A_0$}
\STATE {discard $\phi$-node if not used in any $cl$}
\ENDFOR
}
\ENDFOR

\COMMENT {Phase 3:}
\STATE {add SIMD for simdified dimensions}

\COMMENT {Phase 4: Dimensionality reduction: remove unnecessary dimensionality. \ana{Draft. Needs work.}}
\FOR {each FOR i = 0; ... loop from innermost to outermost}
\FOR {each stmt v[...i...] = ..., including in nested loops}
\STATE {if def-use from stmt v[...i...] to a non drop\_dim(v,i) use outside of loop, mark "live dimension i"}
\STATE {otherwise, mark "dead dimension i"}
\STATE {for all variables v[...i...] (defs and uses) that are "dead dimension i", remove dimension i}
\COMMENT {Two cases: forward edge will use i, backward edge will use i-1}
\ENDFOR

\COMMENT {Now clean up drop\_dim and raise\_dim}
\FOR {each "dead dimension i" def: v[...i...] in loop to use: v' =  drop\_dim(v,i) }
\STATE {replace v' = drop\_dim(v,i) with v' = v in use}
\ENDFOR
\FOR {each "def: v' = raise\_dim(v,i) in outer loop to use: v'[...i...] in loop}
\STATE {replace v' with v in use statement}
\ENDFOR
\ENDFOR
\STATE {do copy propagation and dead code elimination to get rid of redundant variables and raise dimension statements}

\end{algorithmic}

\ishaq{We need to think of a way to handle 4th case for def-use, when a nested block B def is followed by another, different, nested block B' use. Note: The handwritten notes say we can break it into 2 edges. One idea to this end is to insert a def' node which is a copy of the original def. The def' should be placed in a block that contains both B and B'.}
\ishaq{THE ABOVE COMMENT IS RESOLVED. After transformation to SSA, there should be an intermediate variable (phi node) that is assigned a value depending on whether control branched or not. Should we put this into the writeup?}

\input{biometric_vectorization_example.tex}

\begin{comment}
\subsection{Example: Biometric}

\subsubsection{MPC-source}

Below is the MPC-source resulting from Benjamin's analysis. It gives rise to a corresponding dependence graph. (Not shown.)

\begin{algorithmic}

\STATE \COMMENT {Begin of outer loop $i$.}
\STATE {$\texttt{index}_0 = \phi(-1, \texttt{index}_1)$}
\STATE {$\texttt{min}_0 = \phi(10000,\texttt{min}_1)$}

\STATE \COMMENT {Begin of inner loop $j$.}
\STATE {$\texttt{sum}_0 = \phi(0, \texttt{sum}_1)$}
\STATE {$\texttt{d} = \mathit{SUB}(\texttt{S}[i,j], \texttt{C}[j])$}
\STATE {$\texttt{p} = \mathit{MUL}(\texttt{d},\texttt{d})$}
\STATE {$\texttt{sum}_1 = \texttt{ADD}(\texttt{sum}_0,\texttt{p})$}
\STATE \COMMENT {End of inner loop $j$.}
\STATE {$\texttt{c} = \mathit{CMP}(\texttt{sum}_0,\texttt{min}_0)$}
\STATE {$\texttt{index}_1 = \mathit{MUX}(\texttt{c},\texttt{index}_0,i)$}
\STATE {$\texttt{min}_1 = \mathit{MUX}(\texttt{c},\texttt{min}_0,\texttt{sum}_0)$}
\STATE \COMMENT {End of outer loop $i$.}

\end{algorithmic}

\subsubsection{Phase 1 of Basic Vectorization:}

The transformation preserves the dependence edges. It raises the dimensions of scalars and optimistically vectorizes all operations. The next phase discovers loop-carried dependences and removes affected vectorization.

\begin{algorithmic}

\STATE \COMMENT {Begin of outer loop $i$.}
\STATE {$\texttt{index}_0[i] = \phi(-1,\texttt{index}_1[i-1])$}
\STATE {$\texttt{min}_0[i] = \phi(10000, \texttt{min}_1[i-1])$}

\STATE \COMMENT {Begin of inner loop $j$.}
\STATE {$\texttt{sum}_0[i,j] = \phi([0,0,...], \texttt{sum}_1[i,j-1])$}
\STATE {$\texttt{C}'[i,j] = \mathit{raise\_dim}(\texttt{C}[j],i)$}
\STATE {$\texttt{d}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}] = \mathit{SUB}(\texttt{S}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}], \texttt{C}'[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}])$}
\STATE {$\texttt{p}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}] = \mathit{MUL}(\texttt{d}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}],\texttt{d}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}])$}
\STATE {$\texttt{sum}_1[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}] = \mathit{ADD}(\texttt{sum}_0[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}],\texttt{p}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}])$}
\STATE \COMMENT {End of inner loop $j$.}
\STATE {$\texttt{sum}'_0[i] = \mathit{drop\_dim}(\texttt{sum}_0[i,j],j)$}
\STATE {$\texttt{c}[\stackrel{\rightarrow}{i}] = \mathit{CMP}(\texttt{sum}'_0[\stackrel{\rightarrow}{i}],\texttt{min}_0[\stackrel{\rightarrow}{i}])$}
\STATE {$\texttt{index}_1[\stackrel{\rightarrow}{i}] = \mathit{MUX}(\texttt{c}[\stackrel{\rightarrow}{i}],\texttt{index}_0[\stackrel{\rightarrow}{i}],[0,1,...N])$}
\STATE {$\texttt{min}_1[\stackrel{\rightarrow}{i}] = \mathit{MUX}(\texttt{c}[\stackrel{\rightarrow}{i}],\texttt{min}_0[\stackrel{\rightarrow}{i}],\texttt{sum}'_0[\stackrel{\rightarrow}{i}])$}
\STATE \COMMENT {End of outer loop $i$.}

\end{algorithmic}

\ishaq{At least for input variables: when raising dimensions, we should keep some meta data around so we can later write code that could use 1 share if it knows the other N shares are just duplicates of it.}

\subsubsection{Phase 2}

This phase analyzes statements from the innermost loop to the outermost. The key point is to discover loop-carried dependencies and re-introduce loops whenever dependencies make this necessary.

Starting at the inner phi-node $\texttt{sum}_0[i,j] = \phi([0,0,...],\texttt{sum}_1[i,j-1])$, the algorithm first computes its closure. The closure amounts to the phi-node itself and $\texttt{sum}_1[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}] = \mathit{ADD}(\texttt{sum}_0[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}],\texttt{p}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}])$, accounting for the loop-carried dependency of the computation of \texttt{sum}. The algorithm replaces this closure with a FOR loop on $j$ removing vectoriaztion on $j$. Note that the SUB and MUL computations remain outside of the loop as they do not depend on phi-nodes that are part of cycles. The algorithm adds same-level edges, one from $\texttt{p}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}] = ...$ to the monolithic FOR-loop node, and one from the FOR-loop node to $\texttt{c}[\stackrel{\rightarrow}{i}] = ...$.

\ishaq{For our radar: Such dependencies will not involve phi nodes only. e.g. $a[i] = a[i] + a[i-1]$}

\begin{algorithmic}

\STATE \COMMENT {Begin of outer loop $i$.}
\STATE {$\texttt{index}_0[i] = \phi(-1, \texttt{index}_1[i-1])$}
\STATE {$\texttt{min}_0[i] = \phi(10000, \texttt{min}_1[i-1])$}



\STATE {$\texttt{C}'[i,j] = \mathit{raise\_dim}(\texttt{C}[j],i)$}
\STATE {$\texttt{d}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}] = \mathit{SUB}(\texttt{S}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}], \texttt{C}'[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}])$}
\STATE {$\texttt{p}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}] = \mathit{MUL}(\texttt{d}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}],\texttt{d}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}])$}

\STATE \COMMENT {Begin of inner loop $j$. Loop is now much "shorter"!}
\STATE {$\texttt{sum}_0[i,j] = \phi([0,0,...], \texttt{sum}_1[i,j-1])$}
\STATE {FOR j=0; j<D; j++} \COMMENT{ Will turn into a MOTION loop.}
\STATE \hspace{0.25cm}{$\texttt{sum}_1[\stackrel{\rightarrow}{i},{j}] = \mathit{ADD}(\texttt{sum}_0[\stackrel{\rightarrow}{i},{j}],\texttt{p}[\stackrel{\rightarrow}{i},{j}])$}
\STATE \COMMENT {End of inner loop $j$.}

\STATE {$\texttt{sum}'_0[i] = \mathit{drop\_dim}(\texttt{sum}_0[i,j],j)$}
\STATE {$\texttt{c}[\stackrel{\rightarrow}{i}] = \mathit{CMP}(\texttt{sum}'_0[\stackrel{\rightarrow}{i}],\texttt{min}_0[\stackrel{\rightarrow}{i}])$}
\STATE {$\texttt{index}_1[\stackrel{\rightarrow}{i}] = \mathit{MUX}(\texttt{c}[\stackrel{\rightarrow}{i}],\texttt{index}_0[\stackrel{\rightarrow}{i}],[0,1,...N])$}
\STATE {$\texttt{min}_1[\stackrel{\rightarrow}{i}] = \mathit{MUX}(\texttt{c}[\stackrel{\rightarrow}{i}],\texttt{min}_0[\stackrel{\rightarrow}{i}],\texttt{sum}'_0[\stackrel{\rightarrow}{i}])$}
\STATE \COMMENT {End of outer loop $i$.}

\end{algorithmic}

Next, analysis moves to outer dimension $i$. There are two phi-nodes, $\texttt{min}_0[i] = \phi(10000,\texttt{min}_1[i-1])$ and $\texttt{index}_0[i] = \phi(-1,\texttt{index}_1[i-1])$.
The closure of the first is
\[
\begin{array}{l}
\texttt{min}_0[i] = \phi(10000,\texttt{min}_1[i-1]) \\
\texttt{c}[\stackrel{\rightarrow}{i}] = \mathit{CMP}(\texttt{sum}'_0[\stackrel{\rightarrow}{i}],\texttt{min}_0[\stackrel{\rightarrow}{i}]), \\
\texttt{min}_1[\stackrel{\rightarrow}{i}] = \mathit{MUX}(\texttt{c}[\stackrel{\rightarrow}{i}],\texttt{min}_0[\stackrel{\rightarrow}{i}],\texttt{sum}'_0[\stackrel{\rightarrow}{i}])
\end{array}
\]
and the closure of the second one is
\[
\begin{array}{l}
\texttt{index}_0[i] = \phi(-1,\texttt{index}_1[i-1]), \\
%\texttt{c}[\stackrel{\rightarrow}{i}] = \mathit{CMP}(\texttt{sum}'_1[\stackrel{\rightarrow}{i}],\texttt{min}_0[\stackrel{\rightarrow}{i}]), \\
\texttt{index}_1[\stackrel{\rightarrow}{i}] = \mathit{MUX}(\texttt{c}[\stackrel{\rightarrow}{i}],\texttt{index}_0[\stackrel{\rightarrow}{i}],[0,1,...N])
\end{array}
\]

Since the two closures \emph{do not} intersect, we have two distinct FOR-loops on $i$. The first FOR loop (on \texttt{min}) is scheduled first, because of the dependence edge from $\texttt{c}[\stackrel{\rightarrow}{i}] = \mathit{CMP}(\texttt{sum}'_0[\stackrel{\rightarrow}{i}],\texttt{min}_0[\stackrel{\rightarrow}{i}])$ to
$\texttt{index}_1[\stackrel{\rightarrow}{i}] = \mathit{MUX}(\texttt{c}[\stackrel{\rightarrow}{i}],\texttt{index}_0[\stackrel{\rightarrow}{i}],[0,1,...N])$. We can now rewrite those statements, getting rid of the vectorization on $i$ in the two FOR loops. Notably, the SUB and MUL computations are fully vectorizable and the ADD computation is vectorizable across the $i$-dimension.

\begin{algorithmic}

\STATE
\STATE {$\texttt{C}'[i,j] = \mathit{raise\_dim}(\texttt{C}[j],i)$}
\STATE {$\texttt{d}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}] = \mathit{SUB\_SIMD}(\texttt{S}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}], \texttt{C}'[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}])$}
\STATE {$\texttt{p}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}] = \mathit{MUL\_SIMD}(\texttt{d}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}],\texttt{d}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}])$} \\
\STATE {}
\STATE {$\texttt{sum}_0[i,j] = \phi([0,0,...],\texttt{sum}_1[i,j-1])$}
\STATE {FOR j=0; j<D; j++} \COMMENT{ Turns into a MOTION loop, was $j$-loop.}
\STATE \hspace{0.25cm}{$\texttt{sum}_1[\stackrel{\rightarrow}{i},{j}] = \mathit{ADD\_SIMD}(\texttt{sum}_0[\stackrel{\rightarrow}{i},{j}],\texttt{p}[\stackrel{\rightarrow}{i},{j}])$}
\STATE {}
\STATE {$\texttt{sum}'_0[i] = \mathit{drop\_dim}(\texttt{sum}_0[i,j],j)$}
\STATE {}
\STATE {$\texttt{min}_0[i] = \phi(10000,\texttt{min}_1[i-1])$}
\STATE {FOR i=0; i<N; i++} \COMMENT{ Turns into a MOTION loop, was $i$-loop.}
\STATE \hspace{0.25cm}{$\texttt{c}[{i}] = \mathit{CMP}(\texttt{sum}'_0[{i}],\texttt{min}_0[{i}])$}
\STATE \hspace{0.25cm}{$\texttt{min}_1[{i}] = \mathit{MUX}(\texttt{c}[{i}],\texttt{min}_0[{i}],\texttt{sum}'_1[{i}])$}
\STATE {}
\STATE {$\texttt{index}_0[i] = \phi(-1,\texttt{index}_1[i-1])$}
\STATE {FOR i=0; i<N; i++} \COMMENT{ Turns into a MOTION loop, was $i$-loop.}
\STATE \hspace{0.25cm}{$\texttt{index}_1[{i}] = \mathit{MUX}(\texttt{c}[{i}],\texttt{index}_0[{i}],i)$}

\ben{The above code implicitly stores the final values of min\_0 and index\_0 in their last indices, but there is no primitive like drop\_dim to make it clear.  This will have to be added in the SSA code generation (though it might not be necessary to include in the paper?).  It also is pretty wishy-washy about the size and layout of each vector (again more of an implementation issue), but maybe we should have a different syntax for array accesses for read/write (e.g. the ADD\_SIMD steps) vs the array definitions (e.g. the SUB\_SIMD and raise/drop\_dim statements)}

\end{algorithmic}
\end{comment}

\subsection{Correctness Argument}

\subsection{Towards Extension of Basic Vectorization}

\subsubsection{Removal of Infeasible Edges}

Array writes limit vectorization as they sometimes introduce infeasible loop-carried dependencies. Consider the following example: \ana{Have to add citation to Aiken's paper}

\begin{algorithmic}
\STATE for i in range(N):
\STATE \hspace{0.25cm} A[i] = B[i] + 10;
\STATE \hspace{0.25cm} B[i] = A[i] * D[i-1];
\STATE \hspace{0.25cm} C[i] = A[i] * D[i-1];
\STATE \hspace{0.25cm} D[i] = B[i] * C[i];
\end{algorithmic}

In Cytron's SSA this code (roughly) translates into

\begin{algorithmic}
\STATE for i in range(N):
\STATE 1. $\texttt{A}_0$ = $\phi(\texttt{A},\texttt{A}_1)$
\STATE 2. $\texttt{B}_0$ = $\phi(\texttt{B},\texttt{B}_1)$
\STATE 3. $\texttt{C}_0$ = $\phi(\texttt{C},\texttt{C}_1)$
\STATE 4. $\texttt{D}_0$ = $\phi(\texttt{D},\texttt{D}_1)$
\STATE 5. $\texttt{A}_1$ = $\texttt{A}_0$; $\texttt{A}_1$[i] = $\texttt{B}_0$[i] + 10; \COMMENT{equiv. to Update}
\STATE 6. $\texttt{B}_1$ = $\texttt{B}_0$; $\texttt{B}_1$[i] = $\texttt{A}_1$[i] * $\texttt{D}_0$[i-1];
\STATE 7. $\texttt{C}_1$ = $\texttt{C}_0$; $\texttt{C}_1$[i] = $\texttt{A}_1$[i] * $\texttt{D}_0$[i-1];
\STATE 8. $\texttt{D}_1$ = $\texttt{D}_0$; $\texttt{D}_1$[i] = $\texttt{B}_1$[i] * $\texttt{C}_1$[i];
\end{algorithmic}

There is a cycle around $\texttt{B}_0$ = $\phi(\texttt{B},\texttt{B}_1)$ that includes statement $\texttt{A}_1$[i] = $\texttt{B}_0$[i] + 10;
and that statement won't be vectorized even though in fact there is no loop-carried dependency from the write of $\texttt{B}_1$[i] at 8 to the
read of $ ... = \texttt{B}_0$[i] at 6.

The following algorithm removes certain infeasible loop-carried dependencies that are due to array writes. Consider a loop with index $0 \le j < J$
nested at $i,j,k$. Here $i$ represents the enclosing loops of $j$ and $k$ represents the enclosed loops in $j$.

\begin{algorithmic}
\FOR {each array $\texttt{A}$ written in loop $j$}
\STATE \COMMENT { including enclosed loops in $j$ }
\STATE dep = False
\FOR {each pair def: $\texttt{A}_m[f(i,j,k)] = ... $, and use: $ ... = \texttt{A}_n[f'(i,j,k)]$ in loop $j$}
\IF {$\exists \underline{i}, \underline{j}, \underline{j}', \underline{k}, \underline{k}'$, s.t. $0\! \le\! \underline{i}\! <\! I,\: 0\! \le\! \underline{j}, \underline{j}' \! <\! J,\: 0\! \le\! \underline{k}, \underline{k}' \! <\! K,\: \underline{j}<\underline{j}'$, and $f(\underline{i},\underline{j},\underline{k}) = f'(\underline{i},\underline{j}',\underline{k}')$}
\STATE dep = True
\ENDIF
\ENDFOR
\IF {dep == False}
\STATE remove back edge into $\texttt{A}$'s $\phi$-node in loop $j$.
\ENDIF
\ENDFOR
\end{algorithmic}

\ishaq{Note to self: This algorithm is an instantiation for $j$ loop, the one for $k$ loop will be exactly the same, modulo variable name.}.

Consider a loop $j$ enclosed in some fixed $\underline{i}$. Only if an update (definition) $\texttt{A}_m[f(i,j,k)] = ... $ at some iteration $\underline{j}$
references the \emph{same} array element as a use $ ... = \texttt{A}_n[f'(i,j,k)]$ at some later iteration $\underline{j}'$,
we may have a loop-carried dependence for $\texttt{A}$ due to this def-use pair. (In contrast, Cytron's algorithm inserts a loop-carried dependency every time there is an array update.)
The algorithm above examines all def-use pairs in loop $j$, including defs and uses in nested loops, searching for values $\underline{i}, \underline{j}, \underline{j}', \underline{k}, \underline{k}'$ that satisfy
$f(\underline{i},\underline{j},\underline{k}) = f'(\underline{i},\underline{j}',\underline{k}')$. If such values exist for some def-use pair, then there is a potential
loop-carried dependence on $\texttt{A}$; otherwise there is not and we can remove the spurious backward edge thus ``freeing up'' statements for vectorization. %\ana{Double check this!!!}

Consider the earlier example. There is a single loop, $i$. Clearly, there is no pair $\underline{i}$ and $\underline{i}'$, where $\underline{i} < \underline{i}'$ that make $\underline{i} = \underline{i}'$ (due to the def-use pairs of \texttt{A} 6-8 and 6-10).
Therefore, we remove the back edge from 6 to 1. Analogously, we remove the back edges from 8 to 2 and 10 to 3. However, there are many values $\underline{i} < \underline{i'}$ that make $\underline{i} = \underline{i'}-1$ and the back edge from 12 to 4 remains (def-use pairs for \texttt{D}). As a result of removing these spurious edges, Basic Vectorization will find that statement 6 is vectorizable. Statements 8, 10 and 12 will correctly appear in the FOR loop.

%\ana{Commented out previous writeup. Removal/handling of targetless phi-nodes will go into the Extension to Basic vectorization.}

\begin{comment}
The final step is to remove array phi-nodes that are left without incoming back edges after removal of infeasible edges.
Such a phi-node is redundant when there are no loop-carried dependences that are due to writes to the corresponding array.
In our running example, the phi-nodes for \texttt{A}, \texttt{B}, and \texttt{C}, are redundant.

Removing redundant phi-nodes proceeds from \emph{innermost to outermost} loops as follows.
Denote a redundant phi-node by $\texttt{A}_1 = \phi(\texttt{A}_0,\texttt{A}_k)$. $\texttt{A}_0$ is the array at the beginning of the loop
and $\texttt{A}_k$ is the array at the end of an iteration (including the last iteration). We consider two cases:
\begin{enumerate}
\item[Case 1] Inner-to-outer or same-level def-use edge
\begin{itemize}
\item If use is an array read $ ... = \texttt{A}_1[f(i)]$, then replace $\texttt{A}_1$ with $\texttt{A}_0$. This is correct, i.e., it is guaranteed that the use
references $\texttt{A}_0$; had the use been referencing an array modified in an earlier iteration, the back-edge to the phi-node would
not have been removed and the phi-node would not have been classified as redundant.
\item If use is an array write (update) $\texttt{A}_2 = \texttt{A}_1; \texttt{A}_2[i] = ... $ equiv. to $\texttt{A}_2 = \mathit{update}(\texttt{A}_1, i, ...)$ then handling becomes more tricky.
The semantics of this update is that when $i$ is 0, then $\texttt{A}_0$ is being read. But when $i > 0$, then $\texttt{A}_k$ is being read. If we are at this case, this means that the def-use edge is same-level and we are removing a redundant node in the loop enclosing the update. The removal of the original phi-node entails pushing the phi-node at the update:
$\texttt{A}_2 = \phi(\texttt{A}_0,\texttt{A}_k); \texttt{A}_2[i] = ... $ equiv. to $\texttt{A}_2 = \mathit{update}(\phi(\texttt{A}_0,\texttt{A}_k), i, ...)$.
\item If use is a phi-node $... = \phi(\texttt{A}_1,...)$, that means we have an outer-to-inner edge. The

\end{itemize}
\end{enumerate}
For each outer-to-inner or same-level def-use edge
that originates at the node, replace $\texttt{A}_1$ at the use node by $\texttt{A}_0$.
For each inner-to-outer def-use edge, replace $\texttt{A}_1$ by $\texttt{A}_k$. In this case, the use references the array
that results from the computation in the loop.

Our running example is transformed as follows. Removing the phi-nodes for \texttt{A}, \texttt{B}, and \texttt{C} transforms the
replaces the references to $\texttt{A}_0$, $\texttt{B}_0$, and $\texttt{C}_0$, with references to $\texttt{A}$, $\texttt{B}$, and $\texttt{C}$
respectively, i.e., the arrays before the loop.

\begin{algorithmic}
\STATE for i in range(N):
\STATE 1. $\texttt{D}_0$ = $\phi(\texttt{D},\texttt{D}_1)$
\STATE 2. $\texttt{A}_1$ = $\texttt{A}$; $\texttt{A}_1$[i] = $\texttt{B}$[i] + 10;
\STATE 3. $\texttt{B}_1$ = $\texttt{B}$; $\texttt{B}_1$[i] = $\texttt{A}_1$[i] * $\texttt{D}_0$[i-1];
\STATE 4. $\texttt{C}_1$ = $\texttt{C}$; $\texttt{C}_1$[i] = $\texttt{A}_1$[i] * $\texttt{D}_0$[i-1];
\STATE 5. $\texttt{D}_1$ = $\texttt{D}_0$; $\texttt{D}_1$[i] = $\texttt{B}_1$[i] * $\texttt{C}_1$[i];
\end{algorithmic}
\end{comment}

\subsubsection{Array MUX refinement}

\ana{TODO: I think we should implement this.}

Next, the algorithm refines array MUX statements.
MPC-source after Cytron's SSA may result in statements $\texttt{A}_j = \emph{MUX}(..., \texttt{A}_k, \texttt{A}_l)$, which imply that any index
of A can be written at this point and therefore there is a loop-carried dependency. In some cases the MUX can be refined to just a single
index or a pair of indices, e.g., $\texttt{A}_j[i] = \emph{MUX}(c, \texttt{A}_k[i], \texttt{A}_l[i])$.

%\ana{Clarify why this helps. Still work in progress.}
This is to reduce the dimensionality of simd-ified computation. Technically, $\texttt{A}_j = \emph{MUX}(..., \texttt{A}_k, \texttt{A}_l)$ is
a simdified operation that can be carried out in parallel "in one round". However, particularly when \texttt{A} is a multi-dimensional array, there is
substantial increase in the size of the arrays (vectors) we send to SIMD operations. Refining to an update to a specific index would reduce
the size of those vectors. Note that this is a heuristic that handles a common case, but not all cases of array updates.
\ana{TODO: Simplify this algorithm, taking into account the restriction to canonical updates. It should be handling \_all\_ cases.}


\begin{algorithmic}
\FOR {each $\mathit{stmt}$: $\texttt{A}_j = \emph{MUX}(c, \texttt{A}_k, \texttt{A}_l)$ in the MPC-source seq.}
\STATE $i_1 = \mathit{find\_update}(A_k)$ \COMMENT { Is null when $A_k = \phi(...)$ }
\STATE $i_2 = \mathit{find\_update}(A_l)$ \COMMENT { Is null when $A_l = \phi(...)$ }
\IF {$i_1 == i_2$ or $i_1$ is null or $i_2$ is null} \STATE \COMMENT{ With our restrictions on writes we must have $i_1 = i_2$. }
\STATE replace $\mathit{stmt}$ with \\
\STATE $\texttt{A}_j = \texttt{A}_{j-1}$; $\texttt{A}_j[i_1] = \emph{MUX}(c, \texttt{A}_k[i_1], \texttt{A}_l[i_1])$
%\ELSIF {$i_1 \ncong i_2$}
%\STATE replace $\mathit{stmt}$ with \\
%\STATE $\texttt{A}_j = \texttt{A}_k$; $\texttt{A}_j[i_1] = \emph{MUX}(c, \texttt{A}_k[i_1], \texttt{A}_l[i_1])$
\ELSE
\STATE $\mathit{stmt}$ stays as is
\ENDIF
\ENDFOR
\end{algorithmic}

\subsection{Extension of Basic Vectorization with Array Writes}

\subsubsection{Restricting Array Writes}

For now, we restrict array updates to \emph{canonical updates}. Assume (for simplicity) a two-dimensional array $\texttt{A}[I,J]$. A canonical update is the following:
\begin{algorithmic}
\STATE for i in range(I):
\STATE \hspace{0.25cm} for j in range(J):
\STATE \hspace{0.55cm} ...
\STATE \hspace{0.55cm} A[i,j] = ...
\STATE \hspace{0.55cm} ...
\end{algorithmic}

The update $\texttt{A}[i,j]$ can be nested into an inner loop and there may be multiple updates, i.e., writes to $\texttt{A}[i,j]$. However, update such as $\texttt{A}[i-1,j] = ...$ or $\texttt{A}[i-1,j-1] = ...$, etc., is not allowed. Additionally, while there could be several different loops that perform canonical updates, they must be of the same dimensionality, i.e., an update of higher or lower dimension, e.g., $A[i,j,k] = ...$ is not allowed. We compute the \emph{canonical dimensionality} of each write array in the obvious way \emph{before basic vectorization}. This restriction simplifies reasoning in this early stage of the compiler; we will look to relax the restriction in future work.

Another restriction/assumption is that we assume the output array is given as input with initial values, and it is of size consistent with its canonical dimensionality. \ana{This restriction will require that we update our benchmarks that come with output arrays.}

Reads through an arbitrary formula, such as $\texttt{A}[i-1]$ for example, are allowed; currently, our projection function returns dummy values if the read formula is out of bounds; we assume the programmer ensures that the program still computes correct output in this case.

\subsubsection{Changes to Basic Vectorization}

There are two changes to Basic Vectorization to account for write arrays. We can account for them during processing of raise dimension/drop dimension in Phase 1 of Basic Vectorization.

One change to Basic vectorization is the expansion of dimension if the array write or read occurs in a nested loop. That is, if there is an update $\texttt{A}[i,j] = ...$ that occurs in loop dimensionality $i,j,k$, $\texttt{A}[i,j]$ will be rewritten into $\texttt{A}[i,j,k]$. Similarly, a read $\texttt{A}[f(i,j)]$ will be rewritten into $\texttt{A}[f(i,j),k]$. ($\texttt{A}[f(i,j),k]$ will be reshaped as $f(i,j)*I*J+k$ during Phase 1 of Basic Vectorization. \ana{TODO: Double check.}) 

The other change concerns def-use edges $X \rightarrow Y$ where $X$ defines and $Y$ uses an array variable. The definition can be an update $A_2 = update(A_1,...)$ or a pseudo $\phi$-node $A_2 = \phi(A_0,A_1)$. Note that $\phi$ nodes for arrays are no subscript operations on those $\phi$-nodes the way there are in scalar arrays. These edges are not handled in the same way as in Basic Vectorization, specifically, we do not raise and drop dimension as we do for scalars in Basic Vectorization. A key invariant is that the dimension of an array $A$ cannot go above or drop below $A$'s canonical dimensionality. We enumerate the cases of def-use edges.

\begin{enumerate}

\item same-level $X \rightarrow Y$. We do nothing, just propagate the array, which happens to be of the right dimension. \ana{There might be some opportunities to do copy propagation optimization and save some cycles, but let's leave this for later.}

\item inner-to-outer $X \rightarrow Y$. If dimensionality of the loop enclosure of $X$ is greater than the canonical dimensionality of the array, then add \emph{drop\_dim(...)} at $Y$, as in Basic Vectorization. Otherwise, do nothing.

\item outer-to-inner $X \rightarrow Y$. If dimensionality of loop enclosure of $Y$ is greater than the canonical dimensionality of the array, then add \emph{raise\_dim(...)} (at $X$) as in Basic Vectorization. Otherwise, do nothing.

\item "mixed" $X \rightarrow Y$. We assume that the mixed edge is transformed into an inner-to-outer followed by outer-to-inner edge before we perform vectorization, just as with Basic vectorization.

\end{enumerate}

\subsubsection{Examples with Array Writes}

\paragraph{Example 1}

First, the canonical dimensionality of all \texttt{A,B,C} and \texttt{D} is 1. 
Thus, there is no addition of extra dimension for inner loops. After Phase 1 
of Basic Vectorization the Aiken's array write example will be (roughly) as follows:

\begin{algorithmic}
\STATE for i in range(N):
\STATE 1. $\texttt{A}_1$ = $\phi(\texttt{A}_0,\texttt{A}_2)$
\STATE 2. $\texttt{B}_1$ = $\phi(\texttt{B}_0,\texttt{B}_2)$
\STATE 3. $\texttt{C}_1$ = $\phi(\texttt{C}_0,\texttt{C}_2)$
\STATE 4. $\texttt{D}_1$ = $\phi(\texttt{D}_0,\texttt{D}_2)$
\STATE 5. $\texttt{A}_2 = update(\texttt{A}_1, \stackrel{\rightarrow}{i}, \texttt{B}_1[\stackrel{\rightarrow}{i}] + 10)$;
\STATE 6. $\texttt{B}_2 = update(\texttt{B}_1, \stackrel{\rightarrow}{i}, \texttt{A}_2[\stackrel{\rightarrow}{i}] * \texttt{D}_1[\stackrel{\rightarrow}{i-1}])$;
\STATE 7. $\texttt{C}_2 = update(\texttt{C}_1, \stackrel{\rightarrow}{i}, \texttt{A}_2[\stackrel{\rightarrow}{i}] * \texttt{D}_1[\stackrel{\rightarrow}{i-1}])$;
\STATE 8. $\texttt{D}_2 = update(\texttt{D}_1; \stackrel{\rightarrow}{i}, \texttt{B}_2[\stackrel{\rightarrow}{i}] * \texttt{C}_2[\stackrel{\rightarrow}{i}])$;
\end{algorithmic}

Phase 2 computes the closure of 4; $cl = \{4,6,7, 8\}$ 
while 5 is vectorizable. Recall that 1,2, and 3 are targetless phi-nodes. Since the closure $cl$ includes updates to $B$ and $C$,
the corresponding phi-nodes are added to the closure, i.e., the FOR loop. The uses of $A_1$ and $B_1$ in the vectorized statement
turn into uses of $A_0$ and $B_0$ respectively. (But note that $A_0$ is irrelevant; the updates writes into array $A_2$ in parallel.)

\begin{algorithmic}
\STATE 1. $\texttt{A}_2 = update(\texttt{A}_0; \stackrel{\rightarrow}{i}, \mathit{ADD\_SIMD}(\texttt{B}_0[\stackrel{\rightarrow}i],[10,...])$ \COMMENT{Fully vectorized, size N.}
\STATE FOR i=0; i<N; i++; \COMMENT{ MOTION loop }
\STATE 2. $\texttt{B}_1$ = $\phi(\texttt{B}_0,\texttt{B}_2)$
\STATE 3. $\texttt{C}_1$ = $\phi(\texttt{C}_0,\texttt{C}_2)$
\STATE 4. $\texttt{D}_1$ = $\phi(\texttt{D}_0,\texttt{D}_2)$
\STATE 5. $\texttt{B}_2 = update(\texttt{B}_1, i, \mathit{MUL}(\texttt{A}_2[i], \texttt{D}_1[{i-1}])$
\STATE 6. $\texttt{C}_2 = update(\texttt{C}_1, i, \mathit{MUL}(\texttt{A}_2[i], \texttt{D}_1[{i-1}])$
\STATE 7. $\texttt{D}_2 = update(\texttt{D}_1, i, \mathit{MUL}(\texttt{B}_2[i], \texttt{C}_1[i])$
\end{algorithmic}

\ana{TODO: Format either Histogram or Matrix Multiplication. Both are interesting examples that use output arrays.}

\begin{comment}
\paragraph{Example 2}

Consider MPC-source of Histogram after removal of infeasible edges and redundant phi-nodes, and MUX refinement:

\begin{algorithmic}

\STATE res!1 = []
\STATE for i: plaintext in range(0, num\_bins):
\STATE \hspace{0.25cm} res!2 = $\phi$(res!1, res!3)
\STATE  \hspace{0.25cm} ...
\STATE res!4 = res!2 \COMMENT{Added due to the "mixed" def-use edge.}
\STATE for i: plaintext in range(0, num\_bins):
%\STATE \hspace{0.25cm}        result!4 = $\phi$(result!2, result!5)
\STATE \hspace{0.25cm}        for j: plaintext in range(0, N):
\STATE \hspace{0.5cm}            res!5 = $\phi$(res!4, res!7)
\STATE \hspace{0.5cm}            !2!3 = (A[j] == i)
\STATE \hspace{0.5cm}            !3!3 = (res!5[i] + B[j])
\STATE \hspace{0.5cm}            res!6 = res!5; res!6[i] = !3!3
\STATE \hspace{0.5cm}            res!7 = res!6; res!7[i] = MUX(!2!3, res!6[i], res!5[i])

\end{algorithmic}

After Phase 1 of Basic Vectorization:

\begin{algorithmic}
\STATE res!1 = []
\STATE for i: plaintext in range(0, num\_bins):
\STATE \hspace{0.25cm} res!2 = $\phi$(res!1, res!3)
\STATE  \hspace{0.25cm} ...
\STATE res!4 = res!2 \COMMENT{Added due to the "mixed" def-use edge. Because the canonical dimensionality of res is 1, we DO NOT drop dimension of res!2.}
\STATE A[$i,j$] = $\mathit{raise\_dim}$(A[$j$],$i$) \COMMENT{Copying row A num\_bin times. Reusing name.}
\STATE B[$i,j$] = $\mathit{raise\_dim}$(B[$i$],$j$) \COMMENT{Copying column B N times. Reusing name.}
\STATE res!4[$i,j$] = $\mathit{raise\_dim}$(res!4[$i$],$j$) \COMMENT{Reusing name.}
\STATE for i: plaintext in range(0, num\_bins):
%\STATE \hspace{0.25cm}        result!4 = $\phi$(result!2, result!5)
\STATE \hspace{0.25cm}        for j: plaintext in range(0, N):
\STATE \hspace{0.5cm}            res!5 = $\phi$(res!4, res!7) \COMMENT{Do nothing. res!4 has been raised to proper dimension.}
\STATE \hspace{0.5cm}            !2!3[$\stackrel{\rightarrow}i,\stackrel{\rightarrow}j$] = $\mathit{EQ}$(A[$\stackrel{\rightarrow}i,\stackrel{\rightarrow}j$], [[0,0...], [1,1...],...[num\_bins-1,num\_bins-1...]])
\STATE \hspace{0.5cm}            !3!3[$\stackrel{\rightarrow}i,\stackrel{\rightarrow}j$] = $\mathit{ADD}$(res!5[$\stackrel{\rightarrow}i,\stackrel{\rightarrow}j$],B[$\stackrel{\rightarrow}i,\stackrel{\rightarrow}j$])
\STATE \hspace{0.5cm}            res!6 = res!5 \COMMENT{Do nothing, just copy.}
\STATE \hspace{0.5cm}            res!6[$\stackrel{\rightarrow}i,\stackrel{\rightarrow}j$] = !3!3[$\stackrel{\rightarrow}i,\stackrel{\rightarrow}j$]
\STATE \hspace{0.5cm}            res!7 = res!6
\STATE \hspace{0.5cm}            res!7[$\stackrel{\rightarrow}i,\stackrel{\rightarrow}j$] = $\mathit{MUX}$(!2!3[$\stackrel{\rightarrow}i,\stackrel{\rightarrow}j$], res!6[$\stackrel{\rightarrow}i,\stackrel{\rightarrow}j$], res!5[$\stackrel{\rightarrow}i,\stackrel{\rightarrow}j$])
\end{algorithmic}

After Phase 2 and Phase 3. The EQ operation is vectorizable across both dimensions, and the rest of the computation is vectorizable across the $i$-dimension.

\begin{algorithmic}
\STATE ...
\STATE !2!3[$\stackrel{\rightarrow}i,\stackrel{\rightarrow}j$] = $\mathit{EQ\_SIMD}$(A[$\stackrel{\rightarrow}i,\stackrel{\rightarrow}j$], [[0,0...], [1,1...],...[num\_bins-1,num\_bins-1...]])
%\STATE \hspace{0.25cm}        result!4 = $\phi$(result!2, result!5)
\STATE FOR j=0; j<N; j++; \COMMENT{MOTION loop}
\STATE \hspace{0.25cm}            res!5 = $\phi$(res!4, res!7) \COMMENT{Do nothing, just copy.}
\STATE \hspace{0.25cm}            !3!3[$\stackrel{\rightarrow}i,j$] = $\mathit{ADD\_SIMD}$(res!5[$\stackrel{\rightarrow}i,j$],B[$\stackrel{\rightarrow}i,j$])
\STATE \hspace{0.25cm}            res!6 = res!5 \COMMENT{Do nothing, just copy.}
\STATE \hspace{0.25cm}            res!6[$\stackrel{\rightarrow}i,j$] = !3!3[$\stackrel{\rightarrow}i,j$]
\STATE \hspace{0.25cm}            res!7 = res!6
\STATE \hspace{0.25cm}            res!7[$\stackrel{\rightarrow}i,j$] = $\mathit{MUX\_SIMD}$(!2!3[$\stackrel{\rightarrow}i,j$], res!6[$\stackrel{\rightarrow}i,j$], res!5[$\stackrel{\rightarrow}i,j$])
\end{algorithmic}
\end{comment}


\section{Divide-and-Conquer}

\ana{TODO: Now that we have broken FOR loops into smaller chunks, we can add Divide-and-conquer reasoning with Z3 and implement this additional transform.}

\section{Implementation and Evaluation}
\label{sec:implementation}


\section{Future Work}
\label{sec:implementation_and_benchmarks}
%\input{../sections/implementation_and_benchmarks.tex}
%\input{../sections/evaluation.tex}

\section{Conclusions}
\label{sec:conclusion}
%\input{../sections/conclusion.tex}

%\begin{acks}
%    \ishaq{TODO}
%\end{acks}

\printbibliography

% that's all folks
\end{document}


