% !TeX TXS-program:compile = txs:///pdflatex/[--shell-escape]
%
% acm templates v1.57 (sigconf template)
%
%\documentclass[sigconf, screen, review, anonymous, natbib=false]{acmart}
\documentclass[sigconf, screen, natbib=false, dvipsnames, table]{acmart}
\settopmatter{printacmref=true}
% mandatory for CCS'19
\usepackage{balance}
\usepackage{mathtools}
% for creating a balanced last page (usually last page with references)

% defining the \BibTeX command - from Oren Patashnik's original BibTeX documentation.
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08emT\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

% Rights management information. 
% This information is sent to you when you complete the rights form.
% These commands have SAMPLE values in them; it is your responsibility as an author to replace
% the commands and values with those provided to you when you complete the rights form.
%
% These commands are for a PROCEEDINGS abstract or paper.

\copyrightyear{2019} 
\acmYear{2019} 
\setcopyright{acmcopyright}
\acmConference[CCS '19]{2019 ACM SIGSAC Conference on Computer and Communications Security}{November 11--15, 2019}{London, United Kingdom}
\acmBooktitle{2019 ACM SIGSAC Conference on Computer and Communications Security (CCS '19), November 11--15, 2019, London, United Kingdom}
\acmPrice{15.00}
\acmDOI{10.1145/3319535.3339818}
\acmISBN{978-1-4503-6747-9/19/11}

%
% These commands are for a JOURNAL article.
%\setcopyright{acmcopyright}
%\acmJournal{TOG}
%\acmYear{2018}\acmVolume{37}\acmNumber{4}\acmArticle{111}\acmMonth{8}
%\acmDOI{10.1145/1122445.1122456}

%
% Submission ID. 
% Use this when submitting an article to a sponsored event. You'll receive a unique submission ID from the organizers
% of the event, and this ID should be used as the parameter to this command.
%\acmSubmissionID{123-A56-BU3}

%
% The majority of ACM publications use numbered citations and references. If you are preparing content for an event
% sponsored by ACM SIGGRAPH, you must use the "author year" style of citations and references. Uncommenting
% the next command will enable that style.
%\citestyle{acmauthoryear}


 \makeatletter
 % \renewcommand{\section}{\abovedisplayskip 10\p@ \@plus3\p@ \@minus1\p@%
 %                       \belowdisplayskip 5\p@ \@plus3\p@ \@minus1\p@%
 %                       \abovedisplayshortskip 0pt \@plus2\p@%
 %                       \belowdisplayshortskip 0pt \@plus2\p@ \@minus0\p@%
 %                       \@startsection{section}{1}{\z@}%
 %                        {-17\p@ \@plus -4\p@ \@minus -4\p@}%
 %                        {6\p@ \@plus 4\p@ \@minus 4\p@}%
 %                        {\normalfont\large\bfseries\boldmath
 %                         \rightskip=\z@ \@plus 8em\pretolerance=10000 }}
 \renewcommand{\subsection}{\@startsection{subsection}{2}{\z@}%
                        {-8\p@ \@plus -4\p@ \@minus -4\p@}%
                        {5\p@ \@plus 2\p@ \@minus 2\p@}%
                        {\normalfont\Large\bfseries\boldmath
                         \rightskip=\z@ \@plus 3em\pretolerance=10000 }}
  \renewcommand{\subsubsection}{\@startsection{subsubsection}{3}{\z@}%
                        {-6\p@ \@plus -4\p@ \@minus -4\p@}%
                        {1\p@ \@plus 1\p@ \@minus 0\p@}%
                        {\normalfont\normalsize\bfseries\boldmath}}
% \renewcommand{\paragraph}{\@startsection{paragraph}{4}{\z@}%
%                       {-8\p@ \@plus -4\p@ \@minus -4\p@}%
%                       {-2\p@ \@plus -0.22em \@minus -0.1em}%
%                       {\normalfont\normalsize\bfseries}}
 \makeatother



% *** GRAPHICS RELATED PACKAGES ***
\usepackage{graphicx}
\usepackage{comment}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{listings}
% declare the path(s) where your graphic files are
\graphicspath{{../figures/}}
% and their extensions so you won't have to specify these with
% every instance of \includegraphics
\DeclareGraphicsExtensions{.pdf,.jpeg,.png}

%\usepackage[outputdir=/Volumes/ramdisk/]{minted}
\usepackage{minted}
% *** MATH PACKAGES ***
\usepackage{amsmath}



% *** SPECIALIZED LIST PACKAGES ***
%\usepackage{algorithm2e}
\usepackage{algorithmic}



% *** ALIGNMENT PACKAGES ***
\usepackage{array}

\usepackage{url}

\usepackage[utf8]{inputenc}
\usepackage[american]{babel}
\usepackage[backend=biber,style=ACM-Reference-Format]{biblatex}
\addbibresource{../library.bib} 
\addbibresource{../cryptobib/abbrev2.bib}
\addbibresource{../cryptobib/crypto_crossref.bib}

% Used for Theorems and Definitions
\usepackage{amsthm}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\theoremstyle{definition}
\newtheorem{remark}{Remark}
\newtheorem{assumption}{Assumption}

\usepackage{xcolor} 
\usepackage{xspace}
\usepackage{xstring} % required by IfEqCase

\usepackage{booktabs} % better tables
\usepackage{algorithm}
\usepackage{algorithmic}


% ishaq: adding our macros
\input{macros.tex}

\sloppy
\begin{document}
\fancyhead{}
% do not delete this code.    

%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title[Scheduling and Amortization for MPC]{Scheduling and Amortization for MPC}
 
%
% The "author" command and its associated commands are used to define the authors and their affiliations.
% Of note is the shared affiliation of the first two authors, and the "authornote" and "authornotemark" commands
% used to denote shared contribution to the research.

\author{Benjamin Levy}
\email{levyb3@rpi.edu}
\affiliation{%
    \institution{Rensselaer Polytechnic Institute}
    %\streetaddress{1 Th{\o}rv{\"a}ld Circle}
    \city{Troy}
    \state{New York}
    %\country{Iceland}
}

\author{Benjamin Sherman}
\email{shermb@rpi.edu}
\affiliation{%
    \institution{Rensselaer Polytechnic Institute}
    %\streetaddress{1 Th{\o}rv{\"a}ld Circle}
    \city{Troy}
    \state{New York}
    %\country{Iceland}
}


\author{Lindsey Kennard}
\email{kennal@rpi.edu}
\affiliation{%
    \institution{Rensselaer Polytechnic Institute}
    %\streetaddress{1 Th{\o}rv{\"a}ld Circle}
    \city{Troy}
    \state{New York}
    %\country{Iceland}
}

\author{Ana L. Milanova}
\email{milanova@cs.rpi.edu}
\affiliation{%
    \institution{Rensselaer Polytechnic Institute}
    %\streetaddress{1 Th{\o}rv{\"a}ld Circle}
    \city{Troy}
    \state{New York}
    %\country{Iceland}
}

\author{Muhammad Ishaq}
\authornote{This work was done in part while the author was at RPI.}
\email{m.ishaq@ed.ac.uk}
%\orcid{1234-5678-9012}
%\author{G.K.M. Tobin}
%\authornotemark[1]
%\email{webmaster@marysville-ohio.com}
\affiliation{%
    \institution{University of Edinburgh}
    %\streetaddress{P.O. Box 1212}
    \city{Edinburgh}
    \state{Scotland}
%    \postcode{43017-6221}
}

\author{Vassilis Zikas}
\authornote{This work was done in part while the author was visiting UCLA and supported in part by DARPA and SPAWAR under contract N66001-15-C-4065 and by a SICSA Cyber Nexus Research Exchanges grant.}
\email{vzikas@inf.ed.ac.uk}
%\orcid{1234-5678-9012}
%\author{G.K.M. Tobin}
%\authornotemark[1]
%\email{webmaster@marysville-ohio.com}
\affiliation{%
    \institution{University of Edinburgh} 
    %\streetaddress{P.O. Box 1212}
    \city{Edinburgh}
    \state{Scotland}
    %    \postcode{43017-6221}
}


%
% By default, the full list of authors will be used in the page headers. Often, this list is too long, and will overlap
% other information printed in the page headers. This command allows the author to define a more concise list
% of authors' names for this purpose.
%\renewcommand{\shortauthors}{Trovato and Tobin, et al.}

\renewcommand{\A}{{\sf A}}
\renewcommand{\B}{{\sf B}}
\renewcommand{\C}{{\sf C}}
\renewcommand{\D}{{\sf D}}


% As a general rule, do not put math, special symbols or citations
% in the abstract
\begin{abstract}


\end{abstract}


%
% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
% Please copy and paste the code instead of the example below.
%
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10003752.10010124.10010138.10010143</concept_id>
<concept_desc>Theory of computation~Program analysis</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003752.10003777.10003789</concept_id>
<concept_desc>Theory of computation~Cryptographic protocols</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10002978.10002979</concept_id>
<concept_desc>Security and privacy~Cryptography</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Theory of computation~Program analysis}
\ccsdesc[500]{Theory of computation~Cryptographic protocols}
\ccsdesc[300]{Security and privacy~Cryptography}

%
% Keywords. The author(s) should pick words that accurately describe the work being
% presented. Separate the keywords with commas.
\keywords{protocol mixing; linear programming; multiparty computation; program analysis; cryptography}


\begin{comment}
%
% A "teaser" image appears between the author and affiliation information and the body 
% of the document, and typically spans the page. 
\begin{teaserfigure}
    \includegraphics[width=\textwidth]{sampleteaser}
    \caption{Seattle Mariners at Spring Training, 2010.}
    \Description{Enjoying the baseball game from the third-base seats. Ichiro Suzuki preparing to bat.}
    \label{fig:teaser}
\end{teaserfigure}
\end{comment}
%
% This command processes the author and affiliation and title information and builds
% the first part of the formatted document.
\maketitle


\section{Introduction}
\label{sec:introduction}


\section{Background and Problem Statement}
\label{sec:background}

\subsection{Scheduling in MPC}

\ana{Here we need more on MPC before jumping to scheduling. MPC-source, basic assumptions about static loop bounds, etc.}

For this treatment we make the following simplifying assumptions:

\begin{enumerate}
\item All statements in the program execute using the same protocol (sharing). That is, there is no share conversion.
\item All MPC instructions have the same unit cost, 1 unit.
\item There is unlimited bandwidth---i.e., a single MPC-instruction costs as much as $N$ amortized instructions, namely 1 unit.
\item MPC instructions scheduled in parallel benefit from amortization \emph{only if} they are the same instruction. Given our previous assumption, 
2 MUL instructions scheduled in parallel benefit from amortization and cost 1, however a MUL and a MUX instructions scheduled 
in parallel still cost 2. 
\end{enumerate}


\subsection{Scheduling in HPC}
\label{sec:hpc}



\section{\bf Preliminaries}
\label{sec:preliminaries}

We assume arbitrarily nested loops in the MPC-source IR and read-only arrays. We assume that loops range from 0 to some constant N. Arrays are linearized (row-major order as in MOTION) and accesses are via functions of the induction variables of the enclosing loops. We write $i_1,i_2,...i_k$ to denote the loop nest: $i_1$ is the outermost loop, $i_2$, is immediately nested in $i_1$, and so on until $i_k$. As an example, a statement nested in $i_1,i_2,...i_k$ can access array $A[f(i_1,i_2,...i_k)]$. We write $A[i_1,i_2,...i_k]$ interchangeably. \ana{Need to state this more precisely.}

\subsection{Pseudo $\phi$-nodes}

A pseudo $\phi$-node $X_1 = \phi(X_0,X_2)$ in a loop header is evaluated during circuit generation. If it is the 0-th iteration, then the $\phi$-node evaluates to $X_0$, otherwise, it evaluates to $X_2$. 

%\ana{We need to double check that the following captures all cases of def-use edges.}

\subsection{Def-use Edges}

The dependence graph has the following def-use edges:

\begin{itemize}
\item same-level forward $X\rightarrow Y$ where $X$ and $Y$ are in the same loop nest $i_1,i_2,...i_k$. E.g., $\texttt{d} = \mathit{SUM}(\texttt{S}[i,j], \texttt{C}[j])$ to $\texttt{p} = \mathit{MUL}(\texttt{d},\texttt{d})$ in Biometric is a same-level edge. A $\phi$ node can be a source of a same-level forward edge but not a target. 
\item outer-to-inner forward $X\rightarrow Y$ where $X$ is in an outer loop nest, $i_1,i_2,...i_j$, and $Y$ is in an inner one, $i_1,i_2,...i_j,...,i_k$. A $\phi$-node can be a source or a target of an outer-to-inner forward edge. 
\item inner-to-outer forward $X\rightarrow Y$ where $X$ is a $phi$-node in an inner loop nest, $i_1,i_2,...i_k,i_{k+1}$, and $Y$ is in the enclosing loop nest $i_1,i_2,...i_k$. E.g. $\texttt{sum}_0 = \phi(\texttt{sum}_1, 0)$ to $\texttt{c} = \mathit{CMP}(\texttt{sum}_0,\texttt{min}_0)$ is an inner-to-outer forward edge. Note that the source is \emph{always} a $\phi$-node in the immediately enclosing loop. The interpretation of this edge is that the use node $Y$ uses the definition made in the last iteration of the inner loop. 
\item same-level back-edge $X\rightarrow Y$. $Y$ is a phi-node in the header of the loop and $X$ is a definition of the variable in the loop body. E.g., $\texttt{min}_1 = \mathit{MUX}(\texttt{c},\texttt{sum}_1,\texttt{min}_1)$ to $\texttt{min}_0 = \phi(\texttt{min}_1, 10000)$ in Biometric is a same-level back-edge. 
\item inner-to-outer back-edge $X\rightarrow Y$: $X$ and $Y$ are both $\phi$-nodes for some variable. The source $X$ is in a loop nested into $Y$'s loop (not necessarily immediately). 
 
\item mixed forward edge $X\rightarrow Y$. $X$ is a $phi$-node in some loop $i_1,i_2,...i_k,i_{k+1}$ and $Y$ is a node in a loop nested into $i_1,i_2,...i_k$. We transform mixed forward edges as follows. Let $\x_j$ be the variable defined at the phi-node $X$. We add a variable and assignment $\x'_j = \x_j$ immediately after the $i_1,i_2,...i_k$ loop. Then we replace the use of $\x_j$ at $Y$ with $\x'_j$. This transforms a mixed forward edge into an "inner-to-outer" forward edge followed by an outer-to-inner forward edge. Thus Basic Vectorization handles one of "same-level", "inner-to-outer", or "outer-to-inner" def-use edges.
 \end{itemize}

\subsection{Helper Functions}

We define $\mathit{closure}(n)$ where $n$ is a phi-node. Intuitively, it computes the set of nodes (i.e., statements) that form a dependence cycle with $n$. \ana{Cycle(n) is probably a better name.} The closure of $n$ is defined as follows:
\begin{itemize}
\item $n$ is in $\mathit{closure}(n)$
\item $X$ is in $\mathit{closure}(n)$ if there is a same-level path from $n$ to $X$, and $X \rightarrow n$ is a same-level back-edge. 
\item $Y$ is in $\mathit{closure}(n)$ if there is a same-level path from $n$ to $Y$ and there is a same-level path from $Y$ to some $X$ in $\mathit{closure}(n)$.
\end{itemize}

We define the $\mathit{raise\_dim}$ (raise dimensions) and $\mathit{drop\_dim}$ (drop dimension) functions. Raise dimension "lifts" a lower-dimension array (\ana{The right term here is tensor, I am pretty sure!}) into a higher dimension one. This is necessary when a lower-dimensional array is used in a higher dimensional loop and, essentially, is just copying of values. For example, Biometric contains the statement $d = \mathit{SUB}(S[i, j], C[j])$, in the $j$-loop which is nested into the $i$-loop. Here $C$ is a one-dimensional array, however, to vectorize across both loops it is necessary to turn it into a two-dimensional array: $C[i,j]$ becomes $[C[0],C[1],...C[J],C[0],C[1],...C[J], ... C[0],C[1],...C[J]]$, which turns the row into a matrix of $I$ identical rows. (We use capital letters to denote the upper bounds of loops, e.g., $J$ is the upper bound of the $j$-loop and $I$ is the upper bound of the $i$-loop.)

$\mathit{raise\_dim}(A[i_1,...,i_k],i_{k+1})$ is defined as follows. It results in a new {k+1}-dimensional array $A'$ where for every $0\le i_{k+1} < I_{k+1}$, $A'[i_1,...,i_k,i_{k+1}] = A[i_1,...,i_k]$. We add the new dimension at the end arbitrarily, it can be added at any position, e.g., before $i_1$, etc. Adding $n$ dimensions is trivially extended as a composition of $n$ $\mathit{raise\_dim}$ that each adds a single dimension. 

As expected, drop dimension turns a higher-dimensional array into a lower-dimensional one. The key use case is an inner-to-outer def-use edge. The code may define a variable, e.g., $\x$ in an inner loop, say $j$, then use this variable in an enclosing loop, say $i$. Our algorithm may vectorize the computation of $\x$ in the $j$-loop thus producing a vector $\x[j]$ where $\x[1]$ is the value of \x after the 1st iteration and so on. Drop dimension states that the outer loop will use the value of the variable at the last iteration.

$\mathit{drop\_dim}(A[i_1,...,i_k,i_{k+1}])$ produces a k-dimensional array $A'$ where $A'[i_1,...,i_k] = A'[i_1,...,i_k,I_{k+1}-1]$. In our analysis, dimensions are always dropped at the end, and again, one can define dropping $n$ dimensions as a composition of $n$ $\mathit{drop\_dim}$.

\ana{This section is still informal. Needs work to make more precise.}

\section{Vectorization}

\ana{Add back-edges into Phase 1. A back-edge from a non-phi-node in loop $i$ to a phi-node in loop $i$'s header is a same-level edge. The only difference with the handling of normal same-level forward def-use is that the operand index will become $i-1$. A back edge from a phi-node in loop $j$ to a phi-node in loop $i$, where $j$ is nested in $i$ is an inner-to-outer edge and will require dropping dimension. We can show these are the only kinds of back-edges that may occur.}

%\subsection{Algorithm (Still work in progress.)}

\subsection{Basic Vectorization}

\begin{algorithmic} 

\STATE \COMMENT {Phase 1: Raise dimension of scalar variables to corresponding loop nest. We may assume linear traversal of the MPC-source.}

\FOR {each MPC $\mathit{stmt}: X = \mathit{Op}(Y_1,Y_2)$ in loop $i_1,...,i_k$}
\FOR {each $Y_i$}
\STATE {case def-use edge $\mathit{stmt}' (\mbox{def of } Y_i) \rightarrow \mathit{stmt} (\mbox{def of } X)$ of} \\
\STATE \hspace{0.25cm} {same-level $\rightarrow$ add $Y'_i = Y_i$} \\
\STATE \hspace{0.25cm} {outer-to-inner $\rightarrow$ add $Y'_i[i_1,...,i_k] = \mathit{raise\_dim}(Y_i)$} 
\STATE \hspace{0.25cm} {inner-to-outer $\rightarrow$ add $Y'_i[i_1,...,i_k] = \mathit{drop\_dim}(Y_i)$} 
\ENDFOR

\COMMENT {Optimistically vectorize all. $\stackrel{\rightarrow}{i}$ means vectorized dimension.}
\STATE {change to $X[\stackrel{\rightarrow}{i_1},...\stackrel{\rightarrow}{i_k}] = \mathit{Op}(Y'_1[\stackrel{\rightarrow}{i_1},...,\stackrel{\rightarrow}{i_k}],Y'_2[\stackrel{\rightarrow}{i_1},...,\stackrel{\rightarrow}{i_k}])$ }
\ENDFOR

\COMMENT {Phase 2: Recreating FOR loops for cycles; vectorizable statements hoisted up.}

\FOR {each dimension $d$ from highest to 0}
\FOR {each $\phi$-node $n$ in loop $i_1,...,i_d$} 
\STATE {compute $\mathit{closure}(n)$}
\WHILE {there are closure $cl_1$ and $cl_2$ that intersect}
\STATE {merge $cl_1$ and $cl_2$}
\ENDWHILE 
\FOR {each closure $cl$ (after merge)}
\STATE {create FOR $i_d = 0; ...$ loop}  
\STATE {add $\phi$-nodes in $cl$ to header block} 
\STATE {add statements in $cl$ to loop body in some order of dependences} 
\STATE \COMMENT {Dimension is not vectorizable: }
\STATE {change $\stackrel{\rightarrow}{i_d}$ to $i_d$ in all statements in loop}
\STATE {treat FOR loop as monolith node: change def-use edges accordingly. Some edges become same-level.}
\ENDFOR
\ENDFOR
\ENDFOR

\COMMENT {Phase 3:}
\STATE {add SIMD for simdified dimensions}

\end{algorithmic}

\ishaq{We need to think of a way to handle 4th case for def-use, when a nested block B def is followed by another, different, nested block B' use. Note: The handwritten notes say we can break it into 2 edges. One idea to this end is to insert a def' node which is a copy of the original def. The def' should be placed in a block that contains both B and B'.}
\ishaq{THE ABOVE COMMENT IS RESOLVED. After transformation to SSA, there should be an intermediate variable (phi node) that is assigned a value depending on whether control branched or not. Should we put this into the writeup?}

\subsection{Example: Biometric}

\subsubsection{MPC-source} 

Below is the MPC-source resulting from Benjamin's analysis. It gives rise to a corresponding dependence graph. (Not shown.)

\begin{algorithmic}

\STATE \COMMENT {Begin of outer loop $i$.}
\STATE {$\texttt{index}_0 = \phi(\texttt{index}_1, -1)$} 
\STATE {$\texttt{min}_0 = \phi(\texttt{min}_1, 10000)$}

\STATE \COMMENT {Begin of inner loop $j$.}
\STATE {$\texttt{sum}_0 = \phi(\texttt{sum}_1, 0)$}
\STATE {$\texttt{d} = \mathit{SUB}(\texttt{S}[i,j], \texttt{C}[j])$}
\STATE {$\texttt{p} = \mathit{MUL}(\texttt{d},\texttt{d})$}
\STATE {$\texttt{sum}_1 = \texttt{ADD}(\texttt{sum}_0,\texttt{p})$}
\STATE \COMMENT {End of inner loop $j$.}
\STATE {$\texttt{c} = \mathit{CMP}(\texttt{sum}_0,\texttt{min}_0)$}
\STATE {$\texttt{index}_1 = \mathit{MUX}(\texttt{c},\texttt{index}_0,i)$}
\STATE {$\texttt{min}_1 = \mathit{MUX}(\texttt{c},\texttt{min}_0,\texttt{sum}_0)$}
\STATE \COMMENT {End of outer loop $i$.}

\end{algorithmic}

\subsubsection{Phase 1 of Basic Vectorization:}

The transformation preserves the dependence edges. It raises the dimensions of scalars and optimistically vectorizes all operations. The next phase discovers loop-carried dependences and removes affected vectorization. 

\begin{algorithmic}

\STATE \COMMENT {Begin of outer loop $i$.}
\STATE {$\texttt{index}_0[i] = \phi(\texttt{index}_1[i-1], -1)$} 
\STATE {$\texttt{min}_0[i] = \phi(\texttt{min}_1[i-1], 10000)$}

\STATE \COMMENT {Begin of inner loop $j$.}
\STATE {$\texttt{sum}_0[i,j] = \phi(\texttt{sum}_1[i,j-1], [0,0,...])$}
\STATE {$\texttt{C}'[i,j] = \mathit{raise\_dim}(\texttt{C}[j],i)$}
\STATE {$\texttt{d}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}] = \mathit{SUB}(\texttt{S}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}], \texttt{C}'[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}])$}
\STATE {$\texttt{p}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}] = \mathit{MUL}(\texttt{d}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}],\texttt{d}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}])$}
\STATE {$\texttt{sum}_1[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}] = \mathit{ADD}(\texttt{sum}_0[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}],\texttt{p}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}])$}
\STATE \COMMENT {End of inner loop $j$.}
\STATE {$\texttt{sum}'_0[i] = \mathit{drop\_dim}(\texttt{sum}_0[i,j],j)$}
\STATE {$\texttt{c}[\stackrel{\rightarrow}{i}] = \mathit{CMP}(\texttt{sum}'_0[\stackrel{\rightarrow}{i}],\texttt{min}_0[\stackrel{\rightarrow}{i}])$}
\STATE {$\texttt{index}_1[\stackrel{\rightarrow}{i}] = \mathit{MUX}(\texttt{c}[\stackrel{\rightarrow}{i}],\texttt{index}_0[\stackrel{\rightarrow}{i}],[0,1,...N])$}
\STATE {$\texttt{min}_1[\stackrel{\rightarrow}{i}] = \mathit{MUX}(\texttt{c}[\stackrel{\rightarrow}{i}],\texttt{min}_0[\stackrel{\rightarrow}{i}],\texttt{sum}'_0[\stackrel{\rightarrow}{i}])$}
\STATE \COMMENT {End of outer loop $i$.}

\end{algorithmic}

\ishaq{At least for input variables: when raising dimensions, we should keep some meta data around so we can later write code that could use 1 share if it knows the other N shares are just duplicates of it.}

\subsubsection{Phase 2}

This phase analyzes statements from the innermost loop to the outermost. The key point is to discover loop-carried dependencies and re-introduce loops whenever dependencies make this necessary. 

Starting at the inner phi-node $\texttt{sum}_0[i,j] = \phi(\texttt{sum}_1[i,j], [0,0,...])$, the algorithm first computes its closure. The closure amounts to the phi-node itself and $\texttt{sum}_1[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}] = \mathit{ADD}(\texttt{sum}_0[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}],\texttt{p}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}])$, accounting for the loop-carried dependency of the computation of \texttt{sum}. The algorithm replaces this closure with a FOR loop on $j$ removing vectoriaztion on $j$. Note that the SUB and MUL computations remain outside of the loop as they do not depend on phi-nodes that are part of cycles. The algorithm adds same-level edges, one from $\texttt{p}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}] = ...$ to the monolithic FOR-loop node, and one from the FOR-loop node to $\texttt{c}[\stackrel{\rightarrow}{i}] = ...$.

\ishaq{For our radar: Such dependencies will not involve phi nodes only. e.g. $a[i] = a[i] + a[i-1]$}

\begin{algorithmic}

\STATE \COMMENT {Begin of outer loop $i$.}
\STATE {$\texttt{index}_0[i] = \phi(\texttt{index}_1[i-1], -1)$} 
\STATE {$\texttt{min}_0[i] = \phi(\texttt{min}_1[i-1], 10000)$}



\STATE {$\texttt{C}'[i,j] = \mathit{raise\_dim}(\texttt{C}[j],i)$}
\STATE {$\texttt{d}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}] = \mathit{SUB}(\texttt{S}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}], \texttt{C}'[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}])$}
\STATE {$\texttt{p}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}] = \mathit{MUL}(\texttt{d}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}],\texttt{d}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}])$}

\STATE \COMMENT {Begin of inner loop $j$. Loop is now much "shorter"!}
\STATE {$\texttt{sum}_0[i,j] = \phi(\texttt{sum}_1[i,j], [0,0,...])$}
\STATE {FOR j=0; j<=D; j++} \COMMENT{ Will turn into a MOTION loop.}
\STATE \hspace{0.25cm}{$\texttt{sum}_1[\stackrel{\rightarrow}{i},{j}] = \mathit{ADD}(\texttt{sum}_0[\stackrel{\rightarrow}{i},{j}],\texttt{p}[\stackrel{\rightarrow}{i},{j}])$}
\STATE \COMMENT {End of inner loop $j$.}

\STATE {$\texttt{sum}'_0[i] = \mathit{drop\_dim}(\texttt{sum}_0[i,j],j)$}
\STATE {$\texttt{c}[\stackrel{\rightarrow}{i}] = \mathit{CMP}(\texttt{sum}'_0[\stackrel{\rightarrow}{i}],\texttt{min}_0[\stackrel{\rightarrow}{i}])$}
\STATE {$\texttt{index}_1[\stackrel{\rightarrow}{i}] = \mathit{MUX}(\texttt{c}[\stackrel{\rightarrow}{i}],\texttt{index}_0[\stackrel{\rightarrow}{i}],[0,1,...N])$}
\STATE {$\texttt{min}_1[\stackrel{\rightarrow}{i}] = \mathit{MUX}(\texttt{c}[\stackrel{\rightarrow}{i}],\texttt{min}_0[\stackrel{\rightarrow}{i}],\texttt{sum}'_0[\stackrel{\rightarrow}{i}])$}
\STATE \COMMENT {End of outer loop $i$.}

\end{algorithmic}

Next, analysis moves to outer dimension $i$. There are two phi-nodes, $\texttt{min}_0[i] = \phi(\texttt{min}_1[i-1], 10000)$ and $\texttt{index}_0[i] = \phi(\texttt{index}_1[i-1], -1)$.
The closure of the first is 
\[
\begin{array}{l}
\texttt{min}_0[i] = \phi(\texttt{min}_1[i-1], 10000) \\
\texttt{c}[\stackrel{\rightarrow}{i}] = \mathit{CMP}(\texttt{sum}'_0[\stackrel{\rightarrow}{i}],\texttt{min}_0[\stackrel{\rightarrow}{i}]), \\
\texttt{min}_1[\stackrel{\rightarrow}{i}] = \mathit{MUX}(\texttt{c}[\stackrel{\rightarrow}{i}],\texttt{min}_0[\stackrel{\rightarrow}{i}],\texttt{sum}'_0[\stackrel{\rightarrow}{i}])
\end{array}
\]
and the closure of the second one is
\[
\begin{array}{l}
\texttt{index}_0[i] = \phi(\texttt{index}_1[i-1], -1), \\ 
%\texttt{c}[\stackrel{\rightarrow}{i}] = \mathit{CMP}(\texttt{sum}'_1[\stackrel{\rightarrow}{i}],\texttt{min}_0[\stackrel{\rightarrow}{i}]), \\
\texttt{index}_1[\stackrel{\rightarrow}{i}] = \mathit{MUX}(\texttt{c}[\stackrel{\rightarrow}{i}],\texttt{index}_0[\stackrel{\rightarrow}{i}],[0,1,...N]) 
\end{array}
\]

Since the two closures \emph{do not} intersect, we have two distinct FOR-loops on $i$. The first FOR loop (on \texttt{min}) is scheduled first, because of the dependence edge from $\texttt{c}[\stackrel{\rightarrow}{i}] = \mathit{CMP}(\texttt{sum}'_0[\stackrel{\rightarrow}{i}],\texttt{min}_0[\stackrel{\rightarrow}{i}])$ to 
$\texttt{index}_1[\stackrel{\rightarrow}{i}] = \mathit{MUX}(\texttt{c}[\stackrel{\rightarrow}{i}],\texttt{index}_0[\stackrel{\rightarrow}{i}],[0,1,...N])$. We can now rewrite those statements, getting rid of the vectorization on $i$ in the two FOR loops. Notably, the SUB and MUL computations are fully vectorizable and the ADD computation is vectorizable across the $i$-dimension. 

\begin{algorithmic}

\STATE 
\STATE {$\texttt{C}'[i,j] = \mathit{raise\_dim}(\texttt{C}[j],i)$}
\STATE {$\texttt{d}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}] = \mathit{SUB\_SIMD}(\texttt{S}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}], \texttt{C}'[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}])$}
\STATE {$\texttt{p}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}] = \mathit{MUL\_SIMD}(\texttt{d}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}],\texttt{d}[\stackrel{\rightarrow}{i},\stackrel{\rightarrow}{j}])$} \\
\STATE {} 
\STATE {$\texttt{sum}_0[i,j] = \phi(\texttt{sum}_1[i,j-1], [0,0,...])$}
\STATE {FOR j=0; j<=D; j++} \COMMENT{ Turns into a MOTION loop, was $j$-loop.}
\STATE \hspace{0.25cm}{$\texttt{sum}_1[\stackrel{\rightarrow}{i},{j}] = \mathit{ADD\_SIMD}(\texttt{sum}_0[\stackrel{\rightarrow}{i},{j}],\texttt{p}[\stackrel{\rightarrow}{i},{j}])$}
\STATE {} 
\STATE {$\texttt{sum}'_0[i] = \mathit{drop\_dim}(\texttt{sum}_0[i,j],j)$}
\STATE {} 
\STATE {$\texttt{min}_0[i] = \phi(\texttt{min}_1[i-1], 10000)$}
\STATE {FOR i=0; i<=N; i++} \COMMENT{ Turns into a MOTION loop, was $i$-loop.}
\STATE \hspace{0.25cm}{$\texttt{c}[{i}] = \mathit{CMP}(\texttt{sum}'_0[{i}],\texttt{min}_0[{i}])$}
\STATE \hspace{0.25cm}{$\texttt{min}_1[{i}] = \mathit{MUX}(\texttt{c}[{i}],\texttt{min}_0[{i}],\texttt{sum}'_1[{i}])$}
\STATE {}
\STATE {$\texttt{index}_0[i] = \phi(\texttt{index}_1[i-1], -1)$} 
\STATE {FOR i=0; i<=N; i++} \COMMENT{ Turns into a MOTION loop, was $i$-loop.}
\STATE \hspace{0.25cm}{$\texttt{index}_1[{i}] = \mathit{MUX}(\texttt{c}[{i}],\texttt{index}_0[{i}],i)$}

\end{algorithmic}

\subsection{Correctness Argument}

\subsection{Towards Extension of Basic Vectorization}

\subsubsection{Removal of Infeasible Edges}

Array writes limit vectorization as they introduce sometimes infeasible loop-carried dependencies. Consider the following example: \ana{Have to add citation to Aiken's paper}

\begin{algorithmic}
\STATE for i in range(N):
\STATE \hspace{0.25cm} A[i] = B[i] + 10;
\STATE \hspace{0.25cm} B[i] = A[i] * D[i-1];
\STATE \hspace{0.25cm} C[i] = A[i] * D[i-1];
\STATE \hspace{0.25cm} D[i] = B[i] * C[i];
\end{algorithmic}

In Cytron's SSA this code (roughly) translates into 

\begin{algorithmic}
\STATE for i in range(N):
\STATE 1. $\texttt{A}_0$ = $\phi(\texttt{A},\texttt{A}_1)$ 
\STATE 2. $\texttt{B}_0$ = $\phi(\texttt{B},\texttt{B}_1)$ 
\STATE 3. $\texttt{C}_0$ = $\phi(\texttt{C},\texttt{C}_1)$ 
\STATE 4. $\texttt{D}_0$ = $\phi(\texttt{D},\texttt{D}_1)$ 
\STATE 5. $\texttt{A}_1$ = $\texttt{A}_0$ 
\STATE 6. $\texttt{A}_1$[i] = $\texttt{B}_0$[i] + 10;
\STATE 7. $\texttt{B}_1$ = $\texttt{B}_0$ 
\STATE 8. $\texttt{B}_1$[i] = $\texttt{A}_1$[i] * $\texttt{D}_0$[i-1];
\STATE 9. $\texttt{C}_1$ = $\texttt{C}_0$ 
\STATE 10. $\texttt{C}_1$[i] = $\texttt{A}_1$[i] * $\texttt{D}_0$[i-1];
\STATE 11. $\texttt{D}_1$ = $\texttt{D}_0$ 
\STATE 12. $\texttt{D}_1$[i] = $\texttt{B}_1$[i] * $\texttt{C}_1$[i];
\end{algorithmic}

There is a cycle around $\texttt{B}_0$ = $\phi(\texttt{B},\texttt{B}_1)$ that includes statement $\texttt{A}_1$[i] = $\texttt{B}_0$[i] + 10;
and that statement won't be vectorized even though in fact there is no loop-carried dependency from the write of $\texttt{B}_1$[i] at 8 to the 
read of $ ... = \texttt{B}_0$[i] at 6.

The following algorithm removes certain infeasible loop-carried dependencies that are due to array writes. Consider a loop with index $0 \le j < J$
nested at $i,j,k$. Here $i$ represents the enclosing loops of $j$ and $k$ represents the enclosed loops in $j$.

\begin{algorithmic}
\FOR {each array $\texttt{A}$ written in loop $j$} 
\STATE \COMMENT { including enclosed loops in $j$ }
\STATE dep = False
\FOR {each pair def: $\texttt{A}_m[f(i,j,k)] = ... $, and use: $ ... = \texttt{A}_n[f'(i,j,k)]$ in loop $j$}
\IF {$\exists \underline{i}, \underline{j}, \underline{j}', \underline{k}, \underline{k}'$, s.t. $0\! \le\! \underline{i}\! <\! I,\: 0\! \le\! \underline{j}, \underline{j}' \! <\! J,\: 0\! \le\! \underline{k}, \underline{k}' \! <\! K,\: \underline{j}<\underline{j}'$, and $f(\underline{i},\underline{j},\underline{k}) = f'(\underline{i},\underline{j}',\underline{k}')$}
\STATE dep = True
\ENDIF
\ENDFOR
\IF {dep == False}
\STATE remove back edge into $\texttt{A}$'s $\phi$-node in loop $j$.
\ENDIF
\ENDFOR
\end{algorithmic}

\ishaq{Note to self: This algorithm is an instantiation for $j$ loop, the one for $k$ loop will be exactly the same, modulo variable name.}.

Consider a loop $j$ enclosed in some fixed $\underline{i}$. Only if an update (definition) $\texttt{A}_m[f(i,j,k)] = ... $ at some iteration $\underline{j}$ 
references the \emph{same} array element as a use $ ... = \texttt{A}_n[f'(i,j,k)]$ at some later iteration $\underline{j}'$, 
we may have a loop-carried dependence for $\texttt{A}$ due to this def-use pair. (In contrast, Cytron's algorithm inserts a loop-carried dependency every time there is an array update.)
The algorithm above examines all def-use pairs in loop $j$, including defs and uses in nested loops, searching for values $\underline{i}, \underline{j}, \underline{j}', \underline{k}, \underline{k}'$ that satisfy 
$f(\underline{i},\underline{j},\underline{k}) = f'(\underline{i},\underline{j}',\underline{k}')$. If such values exist for some def-use pair, then there is a potential 
loop-carried dependence on $\texttt{A}$; otherwise there is not and we can remove the spurious backward edge thus ``freeing up'' statements for vectorization. %\ana{Double check this!!!}

Consider the earlier example. There is a single loop, $i$. Clearly, there is no pair $\underline{i}$ and $\underline{i}'$, where $\underline{i} < \underline{i}'$ that make $\underline{i} = \underline{i}'$ (due to the def-use pairs of \texttt{A} 6-8 and 6-10).
Therefore, we remove the back edge from 6 to 1. Analogously, we remove the back edges from 8 to 2 and 10 to 3. However, there are many values $\underline{i} < \underline{i'}$ that make $\underline{i} = \underline{i'}-1$ and the back edge from 12 to 4 remains (def-use pairs for \texttt{D}). As a result of removing these spurious edges, Basic Vectorization will find that statement 6 is vectorizable. Statements 8, 10 and 12 will correctly appear in the FOR loop. 

\ana{TODO: We may remove phi-nodes that end up without incoming back-edges. This can free some cycles that we'd waste on bookkeeping arrays.} 

\subsubsection{Array MUX refinement}

\ana{TODO: I think we should implement this.}

Next, the algorithm refines array MUX statements. 
MPC-source after Cytron's SSA may result in statements $\texttt{A}_j = \emph{MUX}(..., \texttt{A}_k, \texttt{A}_l)$, which imply that any index 
of A can be written at this point and therefore there is a loop-carried dependency. In some cases the MUX can be refined to just a single 
index or a pair of indices, e.g., $\texttt{A}_j[i] = \emph{MUX}(c, \texttt{A}_k[i], \texttt{A}_l[i])$. 

%\ana{Clarify why this helps. Still work in progress.}
This is to reduce the dimensionality of simd-ified computation. Technically, $\texttt{A}_j = \emph{MUX}(..., \texttt{A}_k, \texttt{A}_l)$ is 
a simdified operation that can be carried out in parallel "in one round". However, particularly when \texttt{A} is a multi-dimensional array, there is
substantial increase in the size of the arrays (vectors) we send to SIMD operations. Refining to an update to a specific index would reduce 
the size of those vectors. Note that this is a heuristic that handles a common case, but not all cases of array updates. 
\ana{It may actually be handling \_all\_ cases, with the restriction to canonical updates.}


\begin{algorithmic}
\FOR {each $\mathit{stmt}$: $\texttt{A}_j = \emph{MUX}(c, \texttt{A}_k, \texttt{A}_l)$ in the MPC-source seq.}
\STATE $i_1 = \mathit{find\_update}(A_k)$ \COMMENT { Is null when $A_k = \phi(...)$ }
\STATE $i_2 = \mathit{find\_update}(A_l)$ \COMMENT { Is null when $A_l = \phi(...)$ }
\IF {$i_1 == i_2$ or $i_1$ is null or $i_2$ is null} \STATE \COMMENT{ With our restrictions on writes we must have $i_1 = i_2$. } 
\STATE replace $\mathit{stmt}$ with \\
\STATE $\texttt{A}_j = \texttt{A}_k$; $\texttt{A}_j[i_1] = \emph{MUX}(c, \texttt{A}_k[i_1], \texttt{A}_l[i_1])$
%\ELSIF {$i_1 \ncong i_2$}  
%\STATE replace $\mathit{stmt}$ with \\
%\STATE $\texttt{A}_j = \texttt{A}_k$; $\texttt{A}_j[i_1] = \emph{MUX}(c, \texttt{A}_k[i_1], \texttt{A}_l[i_1])$
\ELSE \STATE
\STATE $\mathit{stmt}$ stays as is
\ENDIF
\ENDFOR
\end{algorithmic}

\subsection{Extension of Basic Vectorization with Array Writes}

\subsubsection{Restricting Array Writes}

For now, we restrict array updates to \emph{canonical updates}. Assume (for simplicity) a two-dimensional array $\texttt{A}[I,J]$. A canonical update is the following:
\begin{algorithmic}
\STATE for i in range(I):
\STATE \hspace{0.25cm} for j in range(J):
\STATE \hspace{0.55cm} ... 
\STATE \hspace{0.55cm} A[i,j] = ... 
\STATE \hspace{0.55cm} ... 
\end{algorithmic}

The update $\texttt{A}[i,j]$ can be nested into an inner loop and there may be multiple updates. However, updates such as $\texttt{A}[i-1,j] = ...$ or $\texttt{A}[i-1,j-1] = ...$, etc., are not allowed. This simplifies reasoning about correctness in this early stage of the compiler; we will look to relax this restriction in future work. Reads through an arbitrary formula, such as $\texttt{A}[i-1]$ for example, are allowed, however, we assume the programmer ensures that the formula is within the bounds of the array.

\subsubsection{Changes to Basic Vectorization}

One change to Basic vectorization is the expansion of dimension if the array write or read occurs in a nested loop. That is, if there is an update to $\texttt{A}[i,j]$ that occurs in loop nest $i,j,k$, $\texttt{A}[i,j]$ will be rewritten into $\texttt{A}[i,j,k]$. Similarly, a read $\texttt{A}[f(i,j)]$ will be rewritten into $\texttt{A}[f(i,j),k]$. \ana{This notion of $f(i,j)$ needs a precise definition. For now I'm hoping the hand waving works.}. This can be a preprocessing step or it may be incorporated into the Basic Vectorization algorithm. Basic Vectorization will not expand array accesses at array writes the way it does with scalars now, as they are already expanded. 

\ana{TODO: Another change. What about the A = phi(A1,A2), and A = A1. We have to expand on what happens with those.}

\ana{TODO: Third change. "Mixed" outer -> edge with arrays!}

\subsubsection{Examples with Array Writes}

\paragraph{Example 1} 

After removal of infeasible edges, the Aiken's array write example will be (roughly) as follows:

\begin{algorithmic}
\STATE for i in range(N):
\STATE 1. $\texttt{D}_0$ = $\phi(\texttt{D},\texttt{D}_1)$ 
\STATE 2. $\texttt{A}$[i] = $\texttt{B}$[i] + 10
\STATE 3. $\texttt{B}$[i] = $\texttt{A}$[i] * $\texttt{D}_0$[i-1]
\STATE 4. $\texttt{C}$[i] = $\texttt{A}$[i] * $\texttt{D}_0$[i-1]
\STATE 5. $\texttt{D}_1$ = $\texttt{D}_0$ 
\STATE 6. $\texttt{D}_1$[i] = $\texttt{B}$[i] * $\texttt{C}$[i]
\end{algorithmic}

There are no nested loops, thus, array accesses remain as is. 

After Phase 1 of Basic vectorization we have the following code:
\begin{algorithmic}
\STATE for i in range(N):
\STATE 1. $\texttt{D}_0$ = $\phi(\texttt{D},\texttt{D}_1)$ 
\STATE 2. $\texttt{A}[\stackrel{\rightarrow}{i}] = \texttt{B}[\stackrel{\rightarrow}i] + [10,...]$
\STATE 3. $\texttt{B}[\stackrel{\rightarrow}i] = \texttt{A}[\stackrel{\rightarrow}i] * \texttt{D}_0[\stackrel{\rightarrow}{i-1}]$
\STATE 4. $\texttt{C}[\stackrel{\rightarrow}i] = \texttt{A}[\stackrel{\rightarrow}i] * \texttt{D}_0[\stackrel{\rightarrow}{i-1}]$
\STATE 5. $\texttt{D}_1$ = $\texttt{D}_0$ 
\STATE 6. $\texttt{D}_1[\stackrel{\rightarrow}i] = \texttt{B}[\stackrel{\rightarrow}i] * \texttt{C}[\stackrel{\rightarrow}i]$
\end{algorithmic}

In Phase 2 we get rid of the arrows on statements 3, 4, and 6 as they are not vectorizable and in Phase 3 we add SIMD appropriately:

\begin{algorithmic}
\STATE 1. $\texttt{A}[\stackrel{\rightarrow}{i}] = \mathit{ADD\_SIMD}(\texttt{B}[\stackrel{\rightarrow}i],[10,...])$ \COMMENT{Fully vectorized size N.} 
\STATE FOR i=0; i<N; i++; \COMMENT{ MOTION loop }
\STATE 2. $\texttt{D}_0$ = $\phi(\texttt{D},\texttt{D}_1)$ 
\STATE 3. $\texttt{B}[i] = \mathit{MUL}(\texttt{A}[i], \texttt{D}_0[{i-1}])$
\STATE 4. $\texttt{C}[i] = \mathit{MUL}(\texttt{A}[i], \texttt{D}_0[{i-1}])$
\STATE 5. $\texttt{D}_1$ = $\texttt{D}_0$
\STATE 6. $\texttt{D}_1[i] = \mathit{MUL}(\texttt{B}[i], \texttt{C}[i])$
\end{algorithmic}


\paragraph{Example 2}

Consider MPC-source of Histrogram after removal of infeasible edges and MUX refinement (copied from Repo with some modifications):

\begin{algorithmic}

\STATE res!1 = []
\STATE for i: plaintext in range(0, num\_bins):
\STATE \hspace{0.25cm} res!2 = $\phi$(res!1, res!3)
\STATE  \hspace{0.25cm} ... 
\STATE res!4 = res!2 \COMMENT{Added due to the "mixed" def-use edge.} 
\STATE for i: plaintext in range(0, num\_bins):
%\STATE \hspace{0.25cm}        result!4 = $\phi$(result!2, result!5)
\STATE \hspace{0.25cm}        for j: plaintext in range(0, N):
\STATE \hspace{0.5cm}            res!5 = $\phi$(res!4, res!7)
\STATE \hspace{0.5cm}            !2!3 = (A[j] == i)
\STATE \hspace{0.5cm}            !3!3 = (res!5[i] + B[j])
\STATE \hspace{0.5cm}            res!6 = res!5
\STATE \hspace{0.5cm}            res!6[i] = !3!3
\STATE \hspace{0.5cm}            res!7[i] = MUX(!2!3, res!6[i], res!5[i])

\end{algorithmic}

After Phase 1 of Basic Vectorization:

\begin{algorithmic}
\STATE res!1 = []
\STATE for i: plaintext in range(0, num\_bins):
\STATE \hspace{0.25cm} res!2 = $\phi$(res!1, res!3)
\STATE  \hspace{0.25cm} ... 
\STATE res!4 = res!2 \COMMENT{Added due to the "mixed" def-use edge.} 
\STATE A[$i,j$] = $\mathit{raise\_dim}$(A[$j$],$i$) \COMMENT{Copying row A num\_bin times. Reusing name.} 
\STATE B[$i,j$] = $\mathit{raise\_dim}$(B[$i$],$j$) \COMMENT{Copying column B N times. Reusing name.} 
\STATE res!4[$i,j$] = $\mathit{raise\_dim}$(res!4[$i$],$j$) \COMMENT{Reusing name.} 
\STATE for i: plaintext in range(0, num\_bins):
%\STATE \hspace{0.25cm}        result!4 = $\phi$(result!2, result!5)
\STATE \hspace{0.25cm}        for j: plaintext in range(0, N):
\STATE \hspace{0.5cm}            res!5 = $\phi$(res!4, res!7) \COMMENT{Do nothing. res!4 has been raised to proper dimension.}
\STATE \hspace{0.5cm}            !2!3[$\stackrel{\rightarrow}i,\stackrel{\rightarrow}j$] = $\mathit{EQ}$(A[$\stackrel{\rightarrow}i,\stackrel{\rightarrow}j$], [[0,0...], [1,1...],...[num\_bins-1,num\_bins-1...])
\STATE \hspace{0.5cm}            !3!3[$\stackrel{\rightarrow}i,\stackrel{\rightarrow}j$] = $\mathit{ADD}$(res!5[$\stackrel{\rightarrow}i,\stackrel{\rightarrow}j$],B[$\stackrel{\rightarrow}i,\stackrel{\rightarrow}j$])
\STATE \hspace{0.5cm}            res!6 = res!5 \COMMENT{Do nothing, just copy.}
\STATE \hspace{0.5cm}            res!6[$\stackrel{\rightarrow}i,\stackrel{\rightarrow}j$] = !3!3[$\stackrel{\rightarrow}i,\stackrel{\rightarrow}j$]
\STATE \hspace{0.5cm}            res!7[$\stackrel{\rightarrow}i,\stackrel{\rightarrow}j$] = $\mathit{MUX}$(!2!3[$\stackrel{\rightarrow}i,\stackrel{\rightarrow}j$], res!6[$\stackrel{\rightarrow}i,\stackrel{\rightarrow}j$], res!5[$\stackrel{\rightarrow}i,\stackrel{\rightarrow}j$])
\end{algorithmic}

After Phase 2 and Phase 3. The EQ operation is vectorizable across both dimensions, and the rest of the computation is vectorizable across the $i$-dimension.

\begin{algorithmic}
\STATE ...
\STATE !2!3[$\stackrel{\rightarrow}i,\stackrel{\rightarrow}j$] = $\mathit{EQ\_SIMD}$(A[$\stackrel{\rightarrow}i,\stackrel{\rightarrow}j$], [[0,0...], [1,1...],...[num\_bins-1,num\_bins-1...])
%\STATE \hspace{0.25cm}        result!4 = $\phi$(result!2, result!5)
\STATE FOR j=0; j<N; j++ \COMMENT{MOTION loop}
\STATE \hspace{0.25cm}            res!5 = $\phi$(res!4, res!7) \COMMENT{Do nothing, just copy.}
\STATE \hspace{0.25cm}            !3!3[$\stackrel{\rightarrow}i,j$] = $\mathit{ADD\_SIMD}$(res!5[$\stackrel{\rightarrow}i,j$],B[$\stackrel{\rightarrow}i,j$])
\STATE \hspace{0.25cm}            res!6 = res!5 \COMMENT{Do nothing, just copy.}
\STATE \hspace{0.25cm}            res!6[$\stackrel{\rightarrow}i,j$] = !3!3[$\stackrel{\rightarrow}i,j$]
\STATE \hspace{0.25cm}            res!7[$\stackrel{\rightarrow}i,j$] = $\mathit{MUX\_SIMD}$(!2!3[$\stackrel{\rightarrow}i,j$], res!6[$\stackrel{\rightarrow}i,j$], res!5[$\stackrel{\rightarrow}i,j$])
\end{algorithmic}


\section{Divide-and-Conquer}

\ana{TODO: Now that we have broken FOR loops into smaller chunks, we can add Divide-and-conquer reasoning with Z3 and implement this additional transform.}

\section{Implementation and Evaluation}
\label{sec:implementation}


\section{Future Work}
\label{sec:implementation_and_benchmarks}
%\input{../sections/implementation_and_benchmarks.tex}
%\input{../sections/evaluation.tex}

\section{Conclusions}
\label{sec:conclusion}
%\input{../sections/conclusion.tex}

%\begin{acks}
%    \ishaq{TODO}
%\end{acks}

\printbibliography

% that's all folks
\end{document}


